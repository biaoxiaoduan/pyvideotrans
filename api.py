if __name__ == '__main__':
    print('API ...')
    import json
    import multiprocessing
    import random
    import re
    import shutil
    import threading
    import time
    from datetime import datetime
    from pathlib import Path

    from flask import Flask, request, jsonify, render_template_string, send_from_directory, redirect, url_for
    from waitress import serve
    from werkzeug.utils import secure_filename


    from videotrans.configure import config
    from videotrans.task._dubbing import DubbingSrt
    from videotrans.task._speech2text import SpeechToText
    from videotrans.task._translate_srt import TranslateSrt
    from videotrans.task.job import start_thread
    from videotrans.task.trans_create import TransCreate
    from videotrans.util import tools
    from videotrans import tts as tts_model, translator, recognition

    ###### é…ç½®ä¿¡æ¯
    #### apiæ–‡æ¡£ https://pyvideotrans.com/api-cn
    config.exec_mode='api'
    ROOT_DIR = config.ROOT_DIR
    HOST = "127.0.0.1"
    PORT = 9011
    if Path(ROOT_DIR+'/host.txt').is_file():
        host_str=Path(ROOT_DIR+'/host.txt').read_text(encoding='utf-8').strip()
        host_str=re.sub(r'https?://','',host_str).split(':')
        if len(host_str)>0:
            HOST=host_str[0]
        if len(host_str)==2:
            PORT=int(host_str[1])

    # å­˜å‚¨ç”Ÿæˆçš„æ–‡ä»¶å’Œè¿›åº¦æ—¥å¿—
    API_RESOURCE='apidata'
    TARGET_DIR = ROOT_DIR + f'/{API_RESOURCE}'
    Path(TARGET_DIR).mkdir(parents=True, exist_ok=True)
    # è¿›åº¦æ—¥å¿—
    PROCESS_INFO = TARGET_DIR + '/processinfo'
    if Path(PROCESS_INFO).is_dir():
        shutil.rmtree(PROCESS_INFO)
    Path(PROCESS_INFO).mkdir(parents=True, exist_ok=True)
    # urlå‰ç¼€
    URL_PREFIX = f"http://{HOST}:{PORT}/{API_RESOURCE}"
    config.exit_soft = False
    # åœæ­¢ ç»“æŸ å¤±è´¥çŠ¶æ€
    end_status_list = ['error', 'succeed', 'end', 'stop']
    #æ—¥å¿—çŠ¶æ€
    logs_status_list = ['logs']

    ######################

    app = Flask(__name__, static_folder=TARGET_DIR)

    # æ ¹è·¯å¾„é‡å®šå‘åˆ°ä¸Šä¼ æŸ¥çœ‹é¡µ
    @app.route('/', methods=['GET'])
    def index():
        return redirect('/viewer')

    # ç›´æ¥æä¾› /apidata é™æ€è®¿é—®ï¼Œä»¥ä¾¿é¡µé¢å¯ç›´æ¥è®¿é—®ä¸Šä¼ çš„è§†é¢‘/å­—å¹•
    @app.route(f'/{API_RESOURCE}/<path:subpath>')
    def _serve_apidata(subpath):
        return send_from_directory(TARGET_DIR, subpath)

    # ç®€æ˜“ç½‘é¡µï¼šä¸Šä¼ è§†é¢‘+SRT å¹¶æŸ¥çœ‹æ’­æ”¾å™¨ã€å­—å¹•åˆ—è¡¨å’Œæ—¶é—´è½´
    @app.route('/viewer', methods=['GET'])
    def viewer_home():
        html = """
        <!doctype html>
        <html lang="zh">
        <head>
            <meta charset="utf-8" />
            <meta name="viewport" content="width=device-width, initial-scale=1" />
            <title>å­—å¹•æŸ¥çœ‹å™¨</title>
            <style>
                body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, 'PingFang SC', 'Microsoft YaHei', sans-serif; }
                header { padding: 12px 16px; border-bottom: 1px solid #eee; }
                main { padding: 16px; }
                form { display: flex; gap: 12px; align-items: center; flex-wrap: wrap; }
                .hint { color: #666; font-size: 12px; }
            </style>
        </head>
        <body>
            <header>
                <h3 style="margin:0;">ä¸Šä¼ è§†é¢‘ä¸ SRT å­—å¹•</h3>
                <div class="hint">SRT ç¬¬ä¸€è¡Œè‹¥åŒ…å« [è¯´è¯äºº]ï¼Œå°†è§£æä¸ºè¯´è¯äºº</div>
            </header>
            <main>
                <form action="/upload_viewer" method="post" enctype="multipart/form-data">
                    <label>è§†é¢‘æ–‡ä»¶: <input type="file" name="video" accept="video/*,audio/*" required></label>
                    <label>SRT æ–‡ä»¶: <input type="file" name="srt" accept=".srt" required></label>
                    <button type="submit">ä¸Šä¼ å¹¶æŸ¥çœ‹</button>
                </form>
            </main>
        </body>
        </html>
        """
        return render_template_string(html)

    # FunASR ä¸Šä¼ +è¯†åˆ«ï¼ˆå¸¦è¯´è¯äººæ ‡ç­¾ï¼‰é¡µé¢
    @app.route('/funasr', methods=['GET'])
    def funasr_home():
        html = """
        <!doctype html>
        <html lang=\"zh\">
        <head>
            <meta charset=\"utf-8\" />
            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />
            <title>FunASR è¯´è¯äººæ ‡æ³¨</title>
            <style>
                body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial; }
                header { padding: 12px 16px; border-bottom: 1px solid #eee; }
                main { padding: 16px; }
                form { display: grid; gap: 12px; max-width: 720px; }
                .row { display:flex; gap:12px; align-items:center; }
                .hint { color:#666; font-size:12px; }
                button { padding: 8px 14px; border:1px solid #ddd; background:#fff; border-radius:6px; cursor:pointer; }
            </style>
        </head>
        <body>
            <header>
                <h3 style=\"margin:0;\">FunASR è¯´è¯äººæ ‡æ³¨</h3>
                <div class=\"hint\">ä¸Šä¼ è§†é¢‘ï¼Œä½¿ç”¨ FunASR è¿›è¡Œè¯†åˆ«å¹¶ç”Ÿæˆå« [spkX] çš„ SRT</div>
            </header>
            <main>
                <form action=\"/funasr_run\" method=\"post\" enctype=\"multipart/form-data\">
                    <div class=\"row\"><label>è§†é¢‘æ–‡ä»¶: <input type=\"file\" name=\"video\" accept=\"video/*,audio/*\" required></label></div>
                    <div class=\"row\"><label><input type=\"checkbox\" name=\"enable_spk\" checked> å¯ç”¨è¯´è¯äººè¯†åˆ«</label></div>
                    <div class=\"row\"><button type=\"submit\">å¼€å§‹è¯†åˆ«</button></div>
                </form>
            </main>
        </body>
        </html>
        """
        return html

    @app.route('/funasr_run', methods=['POST'])
    def funasr_run():
        # å¤„ç†ä¸Šä¼ å¹¶æäº¤åˆ°è¯†åˆ«é˜Ÿåˆ—ï¼ˆFunASR + è¯´è¯äººæ ‡ç­¾ï¼‰
        if 'video' not in request.files:
            return jsonify({"code": 1, "msg": "æœªé€‰æ‹©è§†é¢‘æ–‡ä»¶"}), 400
        file = request.files['video']
        if not file or not file.filename.strip():
            return jsonify({"code": 1, "msg": "æœªé€‰æ‹©è§†é¢‘æ–‡ä»¶"}), 400

        # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
        ext = Path(file.filename).suffix
        tmp_name = f"upload_{int(time.time())}_{random.randint(1,9999)}{ext}"
        tmp_path = Path(config.TEMP_DIR) / tmp_name
        file.save(tmp_path.as_posix())

        # è¯†åˆ«é…ç½®ï¼ˆFunASRï¼‰
        from videotrans import recognition
        cfg = {
            "recogn_type": recognition.FUNASR_CN,
            "split_type": 'all',
            "model_name": 'paraformer-zh',
            "is_cuda": False,
            "detect_language": 'auto'
        }

        # è¾“å‡ºä¸ç¼“å­˜ç›®å½•
        obj = tools.format_video(tmp_path.as_posix(), None)
        obj['target_dir'] = TARGET_DIR + f'/{obj["uuid"]}'
        obj['cache_folder'] = config.TEMP_DIR + f'/{obj["uuid"]}'
        Path(obj['target_dir']).mkdir(parents=True, exist_ok=True)
        cfg.update(obj)

        # å°†ä¸Šä¼ çš„è§†é¢‘å‰¯æœ¬æ”¾å…¥ç›®æ ‡ç›®å½•ï¼Œä¾› /view/<task_id> é¡µé¢ä½¿ç”¨
        try:
            import shutil as _shutil
            _shutil.copy2(tmp_path.as_posix(), (Path(obj['target_dir']) / Path(tmp_path).name).as_posix())
        except Exception:
            pass

        # å¯ç”¨è¯´è¯äººè¯†åˆ«ï¼ˆå…¨å±€å‚æ•°ï¼ŒFunASR è¯»å–è¯¥å€¼å†³å®šæ˜¯å¦æ‹¼æ¥ [spkX]ï¼‰
        enable_spk = request.form.get('enable_spk') is not None
        if enable_spk:
            config.params['paraformer_spk'] = True

        config.box_recogn = 'ing'
        trk = SpeechToText(cfg=cfg)
        config.prepare_queue.append(trk)
        tools.set_process(text=f"Currently in queue No.{len(config.prepare_queue)}", uuid=obj['uuid'])
        
        # åœ¨è¯­éŸ³è¯†åˆ«å®Œæˆåï¼Œå°†SRTæ–‡ä»¶é‡å‘½åä¸ºraw.srt
        def rename_srt_to_raw(task_id):
            import time
            max_wait = 300  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿ
            wait_time = 0
            while wait_time < max_wait:
                task_dir = Path(TARGET_DIR) / task_id
                if task_dir.exists():
                    # æŸ¥æ‰¾ç”Ÿæˆçš„SRTæ–‡ä»¶
                    srt_files = list(task_dir.glob("*.srt"))
                    if srt_files:
                        # å°†ç¬¬ä¸€ä¸ªSRTæ–‡ä»¶é‡å‘½åä¸ºraw.srt
                        srt_file = srt_files[0]
                        raw_srt_path = task_dir / "raw.srt"
                        if srt_file != raw_srt_path:
                            srt_file.rename(raw_srt_path)
                            print(f"SRTæ–‡ä»¶å·²é‡å‘½åä¸º: raw.srt")
                        break
                time.sleep(2)
                wait_time += 2
        
        # å¯åŠ¨åå°ä»»åŠ¡é‡å‘½åSRTæ–‡ä»¶
        import threading
        threading.Thread(target=rename_srt_to_raw, args=(obj['uuid'],), daemon=True).start()
        
        # è·³è½¬åˆ°ç»“æœé¡µï¼ˆå®Œæˆåå†è·³è½¬åˆ° /view/<task_id> è¿›è¡Œç¼–è¾‘ï¼‰
        return redirect(url_for('funasr_result', task_id=obj['uuid']))

    @app.route('/funasr_result/<task_id>', methods=['GET'])
    def funasr_result(task_id):
        # ç®€å•ç»“æœä¸çŠ¶æ€è½®è¯¢é¡µ
        html = """
        <!doctype html>
        <html lang=\"zh\">
        <head>
            <meta charset=\"utf-8\" />
            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />
            <title>FunASR ç»“æœ</title>
            <style>
                body { margin:0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial; }
                header { padding:12px 16px; border-bottom:1px solid #eee; }
                main { padding:16px; }
                .hint { color:#666; font-size:12px; }
                .files a { display:block; margin:6px 0; }
                pre { background:#f7f7f7; padding:8px; border-radius:6px; }
            </style>
        </head>
        <body>
            <header>
                <h3 style=\"margin:0;\">FunASR è¯†åˆ«ç»“æœ</h3>
                <div class=\"hint\">ä»»åŠ¡: ((TASK_ID))</div>
            </header>
            <main>
                <div id=\"status\">æŸ¥è¯¢ä¸­...</div>
                <div class=\"files\" id=\"files\"></div>
                <pre id=\"error\" style=\"display:none\"></pre>
            </main>
            <script>
            const taskId = ((TASK_ID_JSON));
            const statusEl = document.getElementById('status');
            const filesEl = document.getElementById('files');
            const errEl = document.getElementById('error');

            async function query() {
                try {
                    const res = await fetch(`/task_status?task_id=${taskId}`);
                    const data = await res.json();
                    if (data.code === -1) { statusEl.textContent = data.msg || 'å¤„ç†ä¸­...'; return; }
                    if (data.code === 0) {
                        statusEl.textContent = 'å®Œæˆ';
                        const urls = (data.data && data.data.url) || [];
                        filesEl.innerHTML = '';
                        urls.forEach(u => { const a = document.createElement('a'); a.href = u; a.textContent = u; filesEl.appendChild(a); });
                        // å®Œæˆåè·³è½¬åˆ° /view/<task_id>
                        setTimeout(() => { location.href = `/view/${taskId}`; }, 800);
                        return true;
                    }
                    errEl.style.display = 'block'; errEl.textContent = data.msg || 'å‡ºé”™äº†';
                    return true;
                } catch (e) { errEl.style.display = 'block'; errEl.textContent = String(e); return true; }
            }
            (async () => {
                const done = await query();
                if (!done) return;
            })();
            setInterval(query, 1500);
            </script>
        </body>
        </html>
        """
        html = html.replace('((TASK_ID))', task_id)
        html = html.replace('((TASK_ID_JSON))', json.dumps(task_id))
        # ä¸ä½¿ç”¨æ¨¡æ¿å¼•æ“ï¼Œç›´æ¥è¿”å›
        return html

    @app.route('/upload_viewer', methods=['POST'])
    def upload_viewer():
        from uuid import uuid4

        if 'video' not in request.files or 'srt' not in request.files:
            return jsonify({"code": 1, "msg": "ç¼ºå°‘æ–‡ä»¶ï¼šéœ€è¦åŒæ—¶ä¸Šä¼ è§†é¢‘å’ŒSRT"}), 400
        video = request.files['video']
        srt = request.files['srt']
        if not video or video.filename.strip() == '':
            return jsonify({"code": 1, "msg": "è§†é¢‘æ–‡ä»¶æœªé€‰æ‹©"}), 400
        if not srt or srt.filename.strip() == '':
            return jsonify({"code": 1, "msg": "SRT æ–‡ä»¶æœªé€‰æ‹©"}), 400

        task_id = uuid4().hex[:10]
        task_dir = Path(TARGET_DIR) / task_id
        task_dir.mkdir(parents=True, exist_ok=True)

        video_name = secure_filename(video.filename)
        srt_name = secure_filename(srt.filename)

        # ä¿å­˜æ–‡ä»¶
        video_path = (task_dir / video_name).as_posix()
        srt_path = (task_dir / srt_name).as_posix()
        video.save(video_path)
        srt.save(srt_path)

        return redirect(url_for('viewer_page', task_id=task_id))

    @app.route('/view/<task_id>', methods=['GET'])
    def viewer_page(task_id):
        # æŸ¥æ‰¾è¯¥ä»»åŠ¡ç›®å½•ä¸‹çš„è§†é¢‘å’Œsrt
        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        all_files = [f.name for f in task_dir.iterdir() if f.is_file()]
        # å…è®¸çš„æ’­æ”¾æ–‡ä»¶åç¼€
        from videotrans.configure import config as _cfg
        exts = set([e.lower() for e in _cfg.VIDEO_EXTS + _cfg.AUDIO_EXITS])
        video_name = ''
        srt_name = ''
        for name in all_files:
            lower = name.lower()
            if lower.endswith('.srt'):
                srt_name = name
            elif any(lower.endswith('.' + e) for e in exts):
                if not video_name:
                    video_name = name

        if not video_name or not srt_name:
            return jsonify({"code": 1, "msg": "ä»»åŠ¡æ–‡ä»¶ç¼ºå¤±ï¼ˆéœ€è¦è§†é¢‘ä¸srtï¼‰"}), 400

        video_url = f'/{API_RESOURCE}/{task_id}/{video_name}'
        # é¡µé¢ï¼šå·¦ä¾§å­—å¹•åˆ—è¡¨ï¼Œå³ä¾§æ’­æ”¾å™¨ä¸æ—¶é—´è½´
        html = """
        <!doctype html>
        <html lang=\"zh\">
        <head>
            <meta charset=\"utf-8\" />
            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />
            <title>å­—å¹•æŸ¥çœ‹å™¨ - ((TASK_ID))</title>
            <style>
                body {{ margin: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, 'PingFang SC', 'Microsoft YaHei', sans-serif; }}
                header {{ padding: 12px 16px; border-bottom: 1px solid #eee; display:flex; gap:12px; align-items:center; }}
                header .task {{ color:#666; font-size:12px; }}
                .container {{ display: grid; grid-template-columns: 360px 1fr; gap: 12px; height: calc(100vh - 60px); padding: 12px; box-sizing: border-box; }}
                .list {{ 
                    border: 1px solid #e5e5e5; 
                    border-radius: 8px; 
                    overflow: auto; 
                    padding: 8px; 
                    background: #fafafa;
                    max-height: 70vh;
                    width: 100%;
                    box-sizing: border-box;
                }}
                .item {{ 
                    padding: 8px 10px; 
                    border-radius: 6px; 
                    cursor: pointer; 
                    margin-bottom: 6px; 
                    border: 1px solid transparent;
                    transition: all 0.2s ease;
                    background: white;
                    width: 100%;
                    box-sizing: border-box;
                }}
                .item:hover {{ 
                    background: #f0f8ff; 
                    border-color: #007AFF;
                    transform: translateY(-1px);
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                }}
                .item.active {{ 
                    background: #e9f3ff; 
                    border-color: #007AFF;
                    box-shadow: 0 2px 8px rgba(0,122,255,0.2);
                }}
                .time {{ 
                    color: #666; 
                    font-size: 11px; 
                    font-weight: 500;
                    margin-bottom: 4px;
                    font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace;
                }}
                .speakerSel {{ 
                    padding: 4px 8px; 
                    font-size: 11px; 
                    border: 1px solid #ddd;
                    border-radius: 4px;
                    background: white;
                    min-width: 80px;
                    flex-shrink: 0;
                }}
                .textEdit {{ 
                    width: 100%; 
                    box-sizing: border-box; 
                    resize: vertical; 
                    min-height: 40px; 
                    font-size: 13px; 
                    line-height: 1.4; 
                    padding: 6px 8px; 
                    border: 1px solid #ddd; 
                    border-radius: 4px;
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                    margin: 0;
                }}
                .textEdit:focus {{
                    outline: none;
                    border-color: #007AFF;
                    box-shadow: 0 0 0 2px rgba(0,122,255,0.1);
                }}
                
                /* æ»šåŠ¨æ¡æ ·å¼ */
                .list::-webkit-scrollbar {{
                    width: 6px;
                }}
                .list::-webkit-scrollbar-track {{
                    background: #f1f1f1;
                    border-radius: 3px;
                }}
                .list::-webkit-scrollbar-thumb {{
                    background: #c1c1c1;
                    border-radius: 3px;
                }}
                .list::-webkit-scrollbar-thumb:hover {{
                    background: #a8a8a8;
                }}
                
                /* å­—å¹•é¡¹ç¼–å· */
                .item::before {{
                    content: attr(data-idx);
                    position: absolute;
                    left: -20px;
                    top: 6px;
                    font-size: 10px;
                    color: #999;
                    font-weight: 500;
                }}
                .item {{
                    position: relative;
                    padding-left: 24px;
                }}
                .player {{ display:flex; flex-direction: column; gap: 8px; }}
                .timeline-wrap {{ border:1px solid #e5e5e5; border-radius:8px; padding:8px; }}
                canvas {{ width: 100%; height: 120px; display:block; cursor: grab; }}
                .timeline-wrap:hover {{ border-color: #007AFF; }}
                canvas:active {{ cursor: grabbing; }}
                .drag-hint {{ 
                    position: absolute; 
                    background: rgba(0,0,0,0.8); 
                    color: white; 
                    padding: 4px 8px; 
                    border-radius: 4px; 
                    font-size: 12px; 
                    pointer-events: none; 
                    z-index: 1000;
                    display: none;
                }}
                /* åˆæˆç­‰å¾…å¼¹çª— */
                .modal-overlay {{
                    position: fixed;
                    top: 0; left: 0; right: 0; bottom: 0;
                    background: rgba(0,0,0,0.4);
                    display: none;
                    align-items: center;
                    justify-content: center;
                    z-index: 2000;
                }}
                .modal {{
                    background: #fff;
                    width: 380px;
                    border-radius: 10px;
                    box-shadow: 0 10px 30px rgba(0,0,0,0.2);
                    padding: 16px 18px;
                    text-align: center;
                }}
                .modal h4 {{ margin: 8px 0 6px; font-size: 16px; }}
                .modal p {{ margin: 6px 0 0; color: #555; font-size: 13px; min-height: 18px; }}
                .spinner {{
                    width: 28px; height: 28px;
                    border: 3px solid #eee; border-top-color: #007AFF;
                    border-radius: 50%;
                    margin: 6px auto 4px;
                    animation: spin 0.8s linear infinite;
                }}
                @keyframes spin {{
                    to {{ transform: rotate(360deg); }}
                }}
            </style>
        </head>
        <body>
            <header>
                <h3 style=\"margin:0;\">å­—å¹•æŸ¥çœ‹å™¨</h3>
                <div class=\"task\">ä»»åŠ¡: {task_id}</div>
                <div style=\"margin-left:auto; display:flex; gap:8px; align-items:center;\">
                    <button id=\"btnTranslateSubtitle\" style=\"padding:6px 12px; border:1px solid #9c27b0; background:#9c27b0; color:#fff; border-radius:6px; cursor:pointer;\">1.ç¿»è¯‘å­—å¹•</button>
                    <button id=\"btnSaveTranslation\" style=\"padding:6px 12px; border:1px solid #17a2b8; background:#17a2b8; color:#fff; border-radius:6px; cursor:pointer; display:none;\">ä¿å­˜ç¿»è¯‘</button>
                    <button id=\"btnVoiceClone\" style=\"padding:6px 12px; border:1px solid #e91e63; background:#e91e63; color:#fff; border-radius:6px; cursor:pointer;\">è¯­éŸ³å…‹éš†</button>
                    <button id=\"btnGenerateAudio\" style=\"padding:6px 12px; border:1px solid #ff9800; background:#ff9800; color:#fff; border-radius:6px; cursor:pointer; display:none;\">ç”ŸæˆéŸ³é¢‘</button>
                    <button id=\"btnSynthesizeAudio\" style=\"padding:6px 12px; border:1px solid #4caf50; background:#4caf50; color:#fff; border-radius:6px; cursor:pointer; display:none;\">åˆæˆéŸ³é¢‘</button>
                    <button id=\"btnSynthesizeVideo\" style=\"padding:6px 12px; border:1px solid #ff6b35; background:#ff6b35; color:#fff; border-radius:6px; cursor:pointer;\">åˆæˆè§†é¢‘</button>
                    <button id=\"btnAddSubtitles\" style=\"padding:6px 12px; border:1px solid #007AFF; background:#007AFF; color:#fff; border-radius:6px; cursor:pointer;\">æ·»åŠ å­—å¹•</button>
                    <button id=\"btnSaveSrt\" style=\"padding:6px 12px; border:1px solid #ddd; background:#fff; border-radius:6px; cursor:pointer;\">ä¸‹è½½SRT(å«spk)</button>
                    <button id="btnSaveJson" style="padding:6px 12px; border:1px solid #ddd; background:#fff; border-radius:6px; cursor:pointer;">ä¸‹è½½JSON</button>
                </div>
            </header>
            <div class=\"container\">
                <div class=\"list\" id=\"subList\"></div>
                <div class=\"player\">
                    <video id=\"video\" src=\"((VIDEO_URL))\" controls crossorigin=\"anonymous\" style=\"width:100%;max-height:60vh;background:#000\"></video>
                    <div class=\"timeline-wrap\" style=\"position: relative;\">
                        <div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 8px;\">
                            <div style=\"font-size: 12px; color: #666;\">
                                ç¼©æ”¾: <span id=\"zoomLevel\">1x</span> | 
                                å¯è§èŒƒå›´: <span id=\"visibleRange\">0s - 0s</span> | 
                                <span id=\"saveStatus\" style=\"color: #28a745;\">å·²ä¿å­˜</span> | 
                                å¿«æ·é”®: R=é‡ç½® F=é€‚åº” â†â†’=å¹³ç§» | æ‹–æ‹½ç©ºç™½åŒºåŸŸæ»‘åŠ¨
                            </div>
                            <div id=\"speakerLegend\" style=\"display: flex; gap: 8px; font-size: 11px;\"></div>
                            <div>
                                <button id=\"zoomIn\" style=\"padding: 2px 8px; margin-right: 4px; font-size: 12px;\">æ”¾å¤§</button>
                                <button id=\"zoomOut\" style=\"padding: 2px 8px; margin-right: 4px; font-size: 12px;\">ç¼©å°</button>
                                <button id=\"zoomReset\" style=\"padding: 2px 8px; margin-right: 8px; font-size: 12px;\">é‡ç½®</button>
                                <button id=\"saveTimeline\" style=\"padding: 2px 8px; font-size: 12px; background: #28a745; color: white; border: none; border-radius: 3px;\">ä¿å­˜</button>
                            </div>
                        </div>
                        <canvas id=\"timeline\" width=\"1200\" height=\"120\"></canvas>
                        <div id=\"dragHint\" class=\"drag-hint\"></div>
                    </div>
                </div>
            </div>
            <!-- åˆæˆè§†é¢‘ç­‰å¾…å¼¹çª— -->
            <div id="synthModal" class="modal-overlay">
              <div class="modal">
                <div class="spinner"></div>
                <h4>æ­£åœ¨åˆæˆè§†é¢‘</h4>
                <p id="synthModalMsg">è¯·ç¨å€™...</p>
              </div>
            </div>

            <script>
            const taskId = ((TASK_ID_JSON));
            const listEl = document.getElementById('subList');
            const videoEl = document.getElementById('video');
            const canvas = document.getElementById('timeline');
            const ctx = canvas.getContext('2d');
            const btnTranslateSubtitle = document.getElementById('btnTranslateSubtitle');
            const btnSaveTranslation = document.getElementById('btnSaveTranslation');
            const btnVoiceClone = document.getElementById('btnVoiceClone');
            const btnGenerateAudio = document.getElementById('btnGenerateAudio');
            const btnSynthesizeAudio = document.getElementById('btnSynthesizeAudio');
            const btnSynthesizeVideo = document.getElementById('btnSynthesizeVideo');
            const btnSaveSrt = document.getElementById('btnSaveSrt');
            const btnAddSubtitles = document.getElementById('btnAddSubtitles');
            const btnSaveJson = document.getElementById('btnSaveJson');
            const dragHint = document.getElementById('dragHint');
            const zoomLevelEl = document.getElementById('zoomLevel');
            const visibleRangeEl = document.getElementById('visibleRange');
            const saveStatusEl = document.getElementById('saveStatus');
            const speakerLegendEl = document.getElementById('speakerLegend');
            const zoomInBtn = document.getElementById('zoomIn');
            const zoomOutBtn = document.getElementById('zoomOut');
            const zoomResetBtn = document.getElementById('zoomReset');
            const saveTimelineBtn = document.getElementById('saveTimeline');
            const synthModal = document.getElementById('synthModal');
            const synthModalMsg = document.getElementById('synthModalMsg');
            let cues = [];
            let videoMs = 0;
            let speakers = [];
            let speakerColors = {}; // å­˜å‚¨è¯´è¯äººå¯¹åº”çš„é¢œè‰²
            const originalVideoUrl = '((VIDEO_URL))';

            function showSynthModal(msg) {
                synthModalMsg.textContent = msg || 'è¯·ç¨å€™...';
                synthModal.style.display = 'flex';
            }
            function hideSynthModal() {
                synthModal.style.display = 'none';
            }

            // æ·»åŠ å­—å¹•å¼¹çª—
            const addSubModal = document.createElement('div');
            addSubModal.className = 'modal-overlay';
            addSubModal.innerHTML = `
              <div class="modal">
                <h4>æ·»åŠ å­—å¹•åˆ°è§†é¢‘</h4>
                <div style="text-align:left;font-size:13px;line-height:1.9;">
                  <label><input type="radio" name="addTarget" value="original" checked> åŸè§†é¢‘ï¼ˆåˆå§‹è½½å…¥çš„ï¼‰</label><br>
                  <label><input type="radio" name="addTarget" value="current"> å½“å‰æ’­æ”¾è§†é¢‘ï¼ˆå¯èƒ½æ˜¯åˆæˆç»“æœï¼‰</label>
                </div>
                <div style="display:flex;gap:8px;justify-content:center;margin-top:8px;flex-wrap:wrap;">
                  <div>
                    <div style="font-size:12px;color:#666;text-align:left;">å­—ä½“å¤§å°(px)</div>
                    <input id="subFontSize" type="number" min="12" max="120" value="72" style="width:120px;padding:6px;">
                  </div>
                  <div>
                    <div style="font-size:12px;color:#666;text-align:left;">è·ç¦»åº•éƒ¨(%)</div>
                    <input id="subBottomPct" type="number" min="0" max="40" value="20" style="width:120px;padding:6px;">
                  </div>
                  <div style="min-width:280px;">
                    <div style="font-size:12px;color:#666;text-align:left;">é€‰æ‹©å­—å¹•æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰</div>
                    <select id="subFileSelect" style="width:280px;padding:6px;">
                      <option value="">ä½¿ç”¨å½“å‰é¡µé¢å­—å¹•ï¼ˆç¿»è¯‘ä¼˜å…ˆï¼‰</option>
                    </select>
                  </div>
                </div>
                <div style="display:flex;gap:8px;justify-content:center;margin-top:12px;">
                  <button id="btnSubCancel" style="padding:6px 12px;">å–æ¶ˆ</button>
                  <button id="btnSubOk" style="padding:6px 12px;background:#007AFF;color:#fff;border:none;border-radius:6px;">ç¡®å®š</button>
                </div>
              </div>`;
            document.body.appendChild(addSubModal);
            
            async function populateSubtitleFiles() {
                try {
                    const res = await fetch(`/viewer_api/${taskId}/list_subtitle_files`);
                    const data = await res.json();
                    const sel = document.getElementById('subFileSelect');
                    if (data && data.code === 0 && Array.isArray(data.files)) {
                        // æ¸…ç©ºä¿ç•™ç¬¬ä¸€ä¸ªé»˜è®¤é€‰é¡¹
                        sel.innerHTML = '<option value="">ä½¿ç”¨å½“å‰é¡µé¢å­—å¹•ï¼ˆç¿»è¯‘ä¼˜å…ˆï¼‰</option>';
                        data.files.forEach(f => {
                            const opt = document.createElement('option');
                            opt.value = f.url; // ä¼ URL
                            opt.textContent = f.name;
                            sel.appendChild(opt);
                        });
                    }
                } catch (e) {
                    console.warn('è·å–å­—å¹•æ–‡ä»¶åˆ—è¡¨å¤±è´¥', e);
                }
            }
            async function showAddSubModal() { await populateSubtitleFiles(); addSubModal.style.display = 'flex'; }
            function hideAddSubModal() { addSubModal.style.display = 'none'; }
            
            addSubModal.addEventListener('click', (e) => { if (e.target === addSubModal) hideAddSubModal(); });
            addSubModal.querySelector('#btnSubCancel').addEventListener('click', hideAddSubModal);
            addSubModal.querySelector('#btnSubOk').addEventListener('click', async () => {
                try {
                    const target = (addSubModal.querySelector('input[name="addTarget"]:checked')||{}).value || 'original';
                    const fontSize = Number(document.getElementById('subFontSize').value) || 72;
                    const bottomPercent = Number(document.getElementById('subBottomPct').value) || 20;
                    const videoUrl = target === 'original' ? originalVideoUrl : (videoEl.currentSrc || videoEl.src);

                    if (!videoUrl) { alert('æœªæ‰¾åˆ°ç›®æ ‡è§†é¢‘'); return; }
                    if (!cues || cues.length === 0) { alert('æ²¡æœ‰å­—å¹•æ•°æ®'); return; }

                    const payload = {
                        video_url: videoUrl,
                        font_size: fontSize,
                        bottom_percent: bottomPercent,
                        subtitles: cues.map((c, index) => ({
                            line: index + 1,
                            start_time: Number(c.start) || 0,
                            end_time: Number(c.end) || 0,
                            // ä¼˜å…ˆä½¿ç”¨ç¿»è¯‘æ–‡æœ¬ï¼Œå…¶æ¬¡å›é€€åˆ°åŸæ–‡
                            text: String((c.translated_text && c.translated_text.trim()) || (c.translation && c.translation.trim()) || c.text || '').trim()
                        })),
                        subtitle_file: (document.getElementById('subFileSelect')||{}).value || ''
                    };

                    showSynthModal('æ­£åœ¨æ·»åŠ å­—å¹•ï¼Œè¯·ç¨å€™...');
                    const res = await fetch(`/viewer_api/${taskId}/add_subtitles`, {
                        method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(payload)
                    });
                    const data = await res.json();
                    if (data && data.code === 0 && data.output_url) {
                        hideAddSubModal();
                        hideSynthModal();
                        videoEl.src = data.output_url;
                        try { videoEl.load(); videoEl.play(); } catch(e){}
                    } else {
                        hideSynthModal();
                        alert(data && data.msg ? data.msg : 'æ·»åŠ å­—å¹•å¤±è´¥');
                    }
                } catch (err) {
                    hideSynthModal();
                    console.error(err);
                    alert('æ·»åŠ å­—å¹•å¤±è´¥');
                }
            });

            function fmtMs(ms) {
                const s = Math.floor(ms/1000); const hh = String(Math.floor(s/3600)).padStart(2,'0');
                const mm = String(Math.floor((s%3600)/60)).padStart(2,'0');
                const ss = String(s%60).padStart(2,'0');
                const mmm = String(ms%1000).padStart(3,'0');
                return `${hh}:${mm}:${ss},${mmm}`;
            }

            // é¢„å®šä¹‰çš„é¢œè‰²è°ƒè‰²æ¿
            const colorPalette = [
                '#4e8cff', // è“è‰²
                '#ff6b6b', // çº¢è‰²
                '#4ecdc4', // é’è‰²
                '#45b7d1', // å¤©è“è‰²
                '#96ceb4', // ç»¿è‰²
                '#feca57', // é»„è‰²
                '#ff9ff3', // ç²‰è‰²
                '#54a0ff', // äº®è“è‰²
                '#5f27cd', // ç´«è‰²
                '#00d2d3', // é’ç»¿è‰²
                '#ff9f43', // æ©™è‰²
                '#10ac84', // æ·±ç»¿è‰²
                '#ee5a24', // æ·±æ©™è‰²
                '#0984e3', // æ·±è“è‰²
                '#6c5ce7', // ç´«ç½—å…°
                '#a29bfe', // æ·¡ç´«è‰²
                '#fd79a8', // ç«ç‘°è‰²
                '#fdcb6e', // æ·¡é»„è‰²
                '#e17055', // çŠç‘šè‰²
                '#74b9ff'  // æµ…è“è‰²
            ];

            // ä¸ºè¯´è¯äººåˆ†é…é¢œè‰²
            function assignSpeakerColor(speaker) {
                if (!speaker || speaker.trim() === '') return '#cddffd'; // é»˜è®¤é¢œè‰²
                
                if (speakerColors[speaker]) {
                    return speakerColors[speaker];
                }
                
                // è·å–å·²ä½¿ç”¨çš„é¢œè‰²
                const usedColors = Object.values(speakerColors);
                let colorIndex = 0;
                
                // æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœªä½¿ç”¨çš„é¢œè‰²
                while (usedColors.includes(colorPalette[colorIndex]) && colorIndex < colorPalette.length - 1) {
                    colorIndex++;
                }
                
                const color = colorPalette[colorIndex];
                speakerColors[speaker] = color;
                return color;
            }

            function renderList() {
                listEl.innerHTML = '';
                cues.forEach((c, idx) => {
                    const item = document.createElement('div');
                    item.className = 'item';
                    item.dataset.idx = idx;
                    item.dataset.start = c.start;
                    item.dataset.end = c.end;
                    const t = document.createElement('div');
                    t.className = 'time';
                    t.textContent = `${c.startraw} â†’ ${c.endraw}`;
                    const tx = document.createElement('div');
                    tx.style.width = '100%';
                    
                    // è¯´è¯äººé€‰æ‹©å™¨è¡Œ
                    const speakerRow = document.createElement('div');
                    speakerRow.style.display = 'flex';
                    speakerRow.style.alignItems = 'center';
                    speakerRow.style.marginBottom = '6px';
                    speakerRow.style.gap = '8px';
                    
                    const sel = document.createElement('select');
                    sel.className = 'speakerSel';
                    const spkSet = new Set(speakers || []);
                    if (c.speaker && !spkSet.has(c.speaker)) spkSet.add(c.speaker);
                    const optionList = Array.from(spkSet);
                    optionList.forEach(s => {
                        const opt = document.createElement('option');
                        opt.value = s; opt.textContent = s; sel.appendChild(opt);
                    });
                    sel.value = c.speaker || '';
                    sel.addEventListener('change', () => { 
                        c.speaker = sel.value; 
                        triggerAutoSave(); // è¯´è¯äººä¿®æ”¹æ—¶ä¹Ÿè§¦å‘è‡ªåŠ¨ä¿å­˜
                    });
                    
                    speakerRow.appendChild(sel);
                    tx.appendChild(speakerRow);
                    
                    // åŸè¯­è¨€æ–‡æœ¬æ¡†
                    const originalWrapper = document.createElement('div');
                    originalWrapper.style.marginBottom = '6px';
                    
                    const originalLabel = document.createElement('div');
                    originalLabel.style.fontSize = '11px';
                    originalLabel.style.fontWeight = '600';
                    originalLabel.style.color = '#495057';
                    originalLabel.style.marginBottom = '4px';
                    originalLabel.innerHTML = 'ğŸ“ åŸè¯­è¨€:';
                    
                    const content = document.createElement('textarea');
                    content.className = 'textEdit';
                    content.value = c.text || '';
                    content.placeholder = 'åŸè¯­è¨€æ–‡æœ¬...';
                    content.style.width = '100%';
                    content.addEventListener('input', () => { 
                        c.text = content.value; 
                        triggerAutoSave(); // æ–‡æœ¬ä¿®æ”¹æ—¶ä¹Ÿè§¦å‘è‡ªåŠ¨ä¿å­˜
                    });
                    
                    originalWrapper.appendChild(originalLabel);
                    originalWrapper.appendChild(content);
                    tx.appendChild(originalWrapper);
                    
                    // ç¿»è¯‘è¯­è¨€æ–‡æœ¬æ¡†
                    const translatedWrapper = document.createElement('div');
                    
                    const translatedLabel = document.createElement('div');
                    translatedLabel.style.fontSize = '11px';
                    translatedLabel.style.fontWeight = '600';
                    translatedLabel.style.color = '#6c757d';
                    translatedLabel.style.marginBottom = '4px';
                    translatedLabel.innerHTML = 'ğŸŒ ç¿»è¯‘:';
                    
                    const translatedInput = document.createElement('textarea');
                    translatedInput.className = 'textEdit';
                    // ä¼˜å…ˆæ˜¾ç¤ºå·²åŠ è½½çš„ç¿»è¯‘æ–‡æœ¬ï¼ŒæŒ‰ä¼˜å…ˆçº§é¡ºåº
                    translatedInput.value = c.translated_text || 
                                          c.translated_text_en || 
                                          c.translated_text_es || 
                                          c.translated_text_fr || 
                                          c.translated_text_ja || 
                                          c.translated_text_zh || 
                                          c.translated_text_pt || 
                                          c.translated_text_th || '';
                    translatedInput.placeholder = 'ç¿»è¯‘æ–‡æœ¬...';
                    translatedInput.style.width = '100%';
                    translatedInput.addEventListener('input', () => { 
                        c.translated_text = translatedInput.value; 
                        saveTranslationText(); // ç¿»è¯‘æ–‡æœ¬ä¿®æ”¹æ—¶è‡ªåŠ¨ä¿å­˜
                    });
                    
                    translatedWrapper.appendChild(translatedLabel);
                    translatedWrapper.appendChild(translatedInput);
                    tx.appendChild(translatedWrapper);
                    
                    item.appendChild(t); item.appendChild(tx);
                    item.addEventListener('click', () => {
                        videoEl.currentTime = (c.start || 0) / 1000;
                    });
                    listEl.appendChild(item);
                });
            }

            // æ‹–æ‹½ç›¸å…³å˜é‡
            let isDragging = false;
            let dragType = null; // 'start', 'end', 'move', 'pan'
            let dragCueIndex = -1;
            let dragStartX = 0;
            let dragStartTime = 0;
            let originalStartTime = 0;
            let originalEndTime = 0;
            let originalPanOffset = 0; // ç”¨äºå¹³ç§»æ‹–æ‹½
            
            // ç¼©æ”¾ç›¸å…³å˜é‡
            let zoomLevel = 1;
            let panOffset = 0; // æ°´å¹³åç§»

            // æ›´æ–°è¯´è¯äººå›¾ä¾‹
            function updateSpeakerLegend() {
                speakerLegendEl.innerHTML = '';
                const uniqueSpeakers = [...new Set(cues.map(c => c.speaker).filter(s => s && s.trim()))];
                
                uniqueSpeakers.forEach(speaker => {
                    const color = assignSpeakerColor(speaker);
                    const legendItem = document.createElement('div');
                    legendItem.style.display = 'flex';
                    legendItem.style.alignItems = 'center';
                    legendItem.style.gap = '4px';
                    
                    const colorBox = document.createElement('div');
                    colorBox.style.width = '12px';
                    colorBox.style.height = '12px';
                    colorBox.style.backgroundColor = color;
                    colorBox.style.borderRadius = '2px';
                    colorBox.style.border = '1px solid #ccc';
                    
                    const speakerLabel = document.createElement('span');
                    speakerLabel.textContent = speaker;
                    speakerLabel.style.color = '#666';
                    
                    legendItem.appendChild(colorBox);
                    legendItem.appendChild(speakerLabel);
                    speakerLegendEl.appendChild(legendItem);
                });
            }

            // æ›´æ–°ç¼©æ”¾å’Œå¹³ç§»æ˜¾ç¤º
            function updateZoomDisplay() {
                zoomLevelEl.textContent = zoomLevel.toFixed(1) + 'x';
                const visibleDuration = videoMs / zoomLevel;
                const startTime = panOffset;
                const endTime = Math.min(videoMs, startTime + visibleDuration);
                visibleRangeEl.textContent = `${fmtMs(startTime)} - ${fmtMs(endTime)}`;
            }

            function drawTimeline(currentMs=0) {
                const w = canvas.clientWidth; const h = canvas.height;
                if (canvas.width !== w) canvas.width = w;
                ctx.clearRect(0,0,canvas.width,canvas.height);
                ctx.fillStyle = '#fafafa';
                ctx.fillRect(0,0,canvas.width,canvas.height);
                
                const pad = 8; const barH = 24; const top = (canvas.height - barH)/2;
                
                // è®¡ç®—å¯è§æ—¶é—´èŒƒå›´
                const visibleDuration = videoMs / zoomLevel;
                const startTime = Math.max(0, panOffset);
                const endTime = Math.min(videoMs, startTime + visibleDuration);
                
                // ç»˜åˆ¶æ—¶é—´åˆ»åº¦
                ctx.fillStyle = '#ddd';
                ctx.font = '10px Arial';
                ctx.textAlign = 'left';
                const tickInterval = Math.max(1000, Math.floor(visibleDuration / 10)); // è‡³å°‘1ç§’é—´éš”
                for (let time = Math.ceil(startTime / tickInterval) * tickInterval; time <= endTime; time += tickInterval) {
                    const x = pad + ((time - startTime) / visibleDuration) * (canvas.width - 2*pad);
                    ctx.fillRect(x, top + barH + 2, 1, 8);
                    ctx.fillText(fmtMs(time), x + 2, top + barH + 12);
                }
                
                cues.forEach((c, i) => {
                    // æ£€æŸ¥å­—å¹•æ˜¯å¦åœ¨å¯è§èŒƒå›´å†…
                    if (c.end < startTime || c.start > endTime) return;
                    
                    const x = pad + ((c.start - startTime) / visibleDuration) * (canvas.width - 2*pad);
                    const wbar = Math.max(2, ((c.end - c.start) / visibleDuration) * (canvas.width - 2*pad));
                    
                    // æ ¹æ®è¯´è¯äººåˆ†é…é¢œè‰²
                    const speakerColor = assignSpeakerColor(c.speaker);
                    const isActive = currentMs >= c.start && currentMs < c.end;
                    
                    // ç»˜åˆ¶å­—å¹•å—èƒŒæ™¯
                    ctx.fillStyle = isActive ? speakerColor : speakerColor + '80'; // æ´»è·ƒæ—¶å®Œå…¨ä¸é€æ˜ï¼Œéæ´»è·ƒæ—¶åŠé€æ˜
                    ctx.fillRect(x, top, wbar, barH);
                    
                    // ç»˜åˆ¶è¯´è¯äººæ ‡ç­¾ï¼ˆå¦‚æœç©ºé—´è¶³å¤Ÿï¼‰
                    if (wbar > 60 && c.speaker) {
                        ctx.fillStyle = '#fff';
                        ctx.font = 'bold 10px Arial';
                        ctx.textAlign = 'left';
                        const speakerText = c.speaker.length > 6 ? c.speaker.substring(0, 6) + '...' : c.speaker;
                        ctx.fillText(speakerText, x + 4, top + 12);
                    }
                    
                    // ç»˜åˆ¶æ‹–æ‹½æ‰‹æŸ„
                    if (wbar > 8) { // åªæœ‰å½“å­—å¹•å—è¶³å¤Ÿå®½æ—¶æ‰æ˜¾ç¤ºæ‰‹æŸ„
                        // å¼€å§‹æ—¶é—´æ‰‹æŸ„
                        ctx.fillStyle = '#2c5aa0';
                        ctx.fillRect(x - 2, top - 2, 4, barH + 4);
                        
                        // ç»“æŸæ—¶é—´æ‰‹æŸ„
                        ctx.fillStyle = '#2c5aa0';
                        ctx.fillRect(x + wbar - 2, top - 2, 4, barH + 4);
                    }
                    
                    // ç»˜åˆ¶å­—å¹•æ–‡æœ¬ï¼ˆå¦‚æœç©ºé—´è¶³å¤Ÿï¼‰
                    if (wbar > 100) {
                        ctx.fillStyle = '#333';
                        ctx.font = '11px Arial';
                        ctx.textAlign = 'center';
                        const text = c.text.substring(0, Math.floor(wbar/10));
                        ctx.fillText(text, x + wbar/2, top + barH/2 + 6);
                    }
                });
                
                // ç»˜åˆ¶å½“å‰æ’­æ”¾ä½ç½®
                if (currentMs >= startTime && currentMs <= endTime) {
                    const xnow = pad + ((currentMs - startTime) / visibleDuration) * (canvas.width - 2*pad);
                ctx.strokeStyle = '#ff3b30';
                    ctx.lineWidth = 2;
                ctx.beginPath();
                ctx.moveTo(xnow, 0); ctx.lineTo(xnow, canvas.height); ctx.stroke();
                    ctx.lineWidth = 1;
                }
                
                // æ›´æ–°æ˜¾ç¤º
                updateZoomDisplay();
                updateSpeakerLegend();
            }

            function updateActive(currentMs) {
                const items = listEl.querySelectorAll('.item');
                items.forEach(el => el.classList.remove('active'));
                for (let i=0;i<cues.length;i++) {
                    const c = cues[i];
                    if (currentMs>=c.start && currentMs<c.end) {
                        const el = listEl.querySelector(`.item[data-idx="${i}"]`);
                        if (el) { el.classList.add('active'); el.scrollIntoView({block:'nearest', behavior:'smooth'}); }
                        break;
                    }
                }
                drawTimeline(currentMs);
            }

            // æ£€æµ‹é¼ æ ‡ä½ç½®å¯¹åº”çš„å­—å¹•å—å’Œæ‹–æ‹½ç±»å‹
            function getCueAtPosition(x, y) {
                const pad = 8; const barH = 24; const top = (canvas.height - barH)/2;
                const tolerance = 6; // æ‹–æ‹½å®¹å·®
                
                // è®¡ç®—å¯è§æ—¶é—´èŒƒå›´
                const visibleDuration = videoMs / zoomLevel;
                const startTime = Math.max(0, panOffset);
                const endTime = Math.min(videoMs, startTime + visibleDuration);
                
                for (let i = 0; i < cues.length; i++) {
                    const c = cues[i];
                    
                    // æ£€æŸ¥å­—å¹•æ˜¯å¦åœ¨å¯è§èŒƒå›´å†…
                    if (c.end < startTime || c.start > endTime) continue;
                    
                    const cueX = pad + ((c.start - startTime) / visibleDuration) * (canvas.width - 2*pad);
                    const cueW = Math.max(2, ((c.end - c.start) / visibleDuration) * (canvas.width - 2*pad));
                    
                    if (y >= top - tolerance && y <= top + barH + tolerance) {
                        if (x >= cueX - tolerance && x <= cueX + tolerance) {
                            return { index: i, type: 'start' };
                        } else if (x >= cueX + cueW - tolerance && x <= cueX + cueW + tolerance) {
                            return { index: i, type: 'end' };
                        } else if (x >= cueX && x <= cueX + cueW) {
                            return { index: i, type: 'move' };
                        }
                    }
                }
                return null;
            }

            // æ˜¾ç¤ºæ‹–æ‹½æç¤º
            function showDragHint(x, y, text) {
                dragHint.textContent = text;
                dragHint.style.display = 'block';
                dragHint.style.left = (x + 10) + 'px';
                dragHint.style.top = (y - 30) + 'px';
            }

            // éšè—æ‹–æ‹½æç¤º
            function hideDragHint() {
                dragHint.style.display = 'none';
            }

            // è‡ªåŠ¨ä¿å­˜å®šæ—¶å™¨
            let saveTimeout = null;
            let isSaving = false;

            // æ›´æ–°ä¿å­˜çŠ¶æ€æ˜¾ç¤º
            function updateSaveStatus(status, color = '#28a745') {
                saveStatusEl.textContent = status;
                saveStatusEl.style.color = color;
            }

            // ä¿å­˜å­—å¹•åˆ°SRTæ–‡ä»¶ï¼ˆé€šç”¨å‡½æ•°ï¼‰
            async function saveSubtitles(showStatus = true) {
                if (isSaving) return;
                
                try {
                    isSaving = true;
                    if (showStatus) {
                        updateSaveStatus('ä¿å­˜ä¸­...', '#ffc107');
                    }
                    
                    // æ”¶é›†æ‰€æœ‰å­—å¹•æ•°æ®ï¼ŒåŒ…æ‹¬æ—¶é—´å’Œæ–‡å­—
                    const payload = { 
                        subtitles: cues.map(c => ({
                            start: Number(c.start)||0,
                            end: Number(c.end)||0,
                            text: String(c.text||'').trim(),
                            speaker: String(c.speaker||'').trim(),
                        })), 
                        srt_with_spk: true 
                    };
                    
                    const res = await fetch(`/viewer_api/${taskId}/export_srt`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });
                    
                    const data = await res.json();
                    if (data && data.code === 0) {
                        if (showStatus) {
                            updateSaveStatus('å·²ä¿å­˜', '#28a745');
                            console.log('å­—å¹•å·²ä¿å­˜');
                        }
                        return true;
                    } else {
                        if (showStatus) {
                            updateSaveStatus('ä¿å­˜å¤±è´¥', '#dc3545');
                        }
                        console.error('ä¿å­˜å¤±è´¥:', data && data.msg ? data.msg : 'æœªçŸ¥é”™è¯¯');
                        return false;
                    }
                } catch (e) {
                    if (showStatus) {
                        updateSaveStatus('ä¿å­˜å¤±è´¥', '#dc3545');
                    }
                    console.error('ä¿å­˜å¤±è´¥:', e);
                    return false;
                } finally {
                    isSaving = false;
                }
            }

            // è‡ªåŠ¨ä¿å­˜å­—å¹•åˆ°SRTæ–‡ä»¶
            async function autoSaveSubtitles() {
                return await saveSubtitles(true);
            }

            // ä¿å­˜ç¿»è¯‘æ–‡æœ¬
            let translationSaveTimeout = null;
            async function saveTranslationText() {
                if (translationSaveTimeout) {
                    clearTimeout(translationSaveTimeout);
                }
                
                translationSaveTimeout = setTimeout(async () => {
                    try {
                        const payload = { 
                            subtitles: cues.map(c => ({
                                start: Number(c.start)||0,
                                end: Number(c.end)||0,
                                text: String(c.text||'').trim(),
                                speaker: String(c.speaker||'').trim(),
                                translated_text: String(c.translated_text||'').trim(),
                            })), 
                            target_language: 'en' // é»˜è®¤è‹±è¯­ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
                        };
                        
                        const res = await fetch(`/viewer_api/${taskId}/save_translation`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(payload)
                        });
                        
                        const data = await res.json();
                        if (data && data.code === 0) {
                            console.log('ç¿»è¯‘æ–‡æœ¬å·²ä¿å­˜');
                        } else {
                            console.error('ä¿å­˜ç¿»è¯‘æ–‡æœ¬å¤±è´¥:', data && data.msg ? data.msg : 'æœªçŸ¥é”™è¯¯');
                        }
                    } catch (e) {
                        console.error('ä¿å­˜ç¿»è¯‘æ–‡æœ¬å¤±è´¥:', e);
                    }
                }, 1000); // 1ç§’åè‡ªåŠ¨ä¿å­˜
            }

            // è§¦å‘è‡ªåŠ¨ä¿å­˜ï¼ˆé˜²æŠ–ï¼‰
            function triggerAutoSave(immediate = false) {
                if (saveTimeout) {
                    clearTimeout(saveTimeout);
                }
                
                if (immediate) {
                    // ç«‹å³ä¿å­˜
                    autoSaveSubtitles();
                } else {
                    // å»¶è¿Ÿä¿å­˜
                    updateSaveStatus('æœ‰æœªä¿å­˜çš„æ›´æ”¹', '#ffc107');
                    saveTimeout = setTimeout(() => {
                        autoSaveSubtitles();
                    }, 1000); // 1ç§’åè‡ªåŠ¨ä¿å­˜
                }
            }

            // æ›´æ–°å­—å¹•æ—¶é—´
            function updateCueTime(cueIndex, newStart, newEnd) {
                if (cueIndex >= 0 && cueIndex < cues.length) {
                    const cue = cues[cueIndex];
                    cue.start = Math.max(0, newStart);
                    cue.end = Math.max(cue.start + 100, newEnd); // æœ€å°100msé—´éš”
                    cue.startraw = fmtMs(cue.start);
                    cue.endraw = fmtMs(cue.end);
                    
                    // æ›´æ–°åˆ—è¡¨æ˜¾ç¤º
                    renderList();
                    drawTimeline(videoEl.currentTime * 1000);
                    
                    // è§¦å‘è‡ªåŠ¨ä¿å­˜
                    triggerAutoSave();
                }
            }

            // å°†å±å¹•åæ ‡è½¬æ¢ä¸ºæ—¶é—´
            function screenToTime(x) {
                const pad = 8;
                const visibleDuration = videoMs / zoomLevel;
                const startTime = Math.max(0, panOffset);
                const ratio = Math.min(1, Math.max(0, (x - pad) / (canvas.width - 2*pad)));
                return startTime + ratio * visibleDuration;
            }

            // é¼ æ ‡æŒ‰ä¸‹äº‹ä»¶
            canvas.addEventListener('mousedown', (e) => {
                const rect = canvas.getBoundingClientRect();
                const x = e.clientX - rect.left;
                const y = e.clientY - rect.top;
                
                const hit = getCueAtPosition(x, y);
                if (hit) {
                    isDragging = true;
                    dragType = hit.type;
                    dragCueIndex = hit.index;
                    dragStartX = x;
                    
                    // è®°å½•åŸå§‹æ—¶é—´
                    const cue = cues[dragCueIndex];
                    originalStartTime = cue.start;
                    originalEndTime = cue.end;
                    
                    // æ”¹å˜é¼ æ ‡æ ·å¼
                    canvas.style.cursor = 'ew-resize';
                    e.preventDefault();
                } else {
                    // ç‚¹å‡»ç©ºç™½åŒºåŸŸï¼Œå®šä½æ’­æ”¾çº¿
                    const ms = screenToTime(x);
                    videoEl.currentTime = ms / 1000;
                    
                    // å¦‚æœæŒ‰ä½é¼ æ ‡ï¼Œåˆ™å¼€å§‹å¹³ç§»æ‹–æ‹½
                    if (e.button === 0) { // å·¦é”®
                        isDragging = true;
                        dragType = 'pan';
                        dragStartX = x;
                        originalPanOffset = panOffset;
                        
                        // æ”¹å˜é¼ æ ‡æ ·å¼
                        canvas.style.cursor = 'grabbing';
                        e.preventDefault();
                    }
                }
            });

            // é¼ æ ‡ç§»åŠ¨äº‹ä»¶
            canvas.addEventListener('mousemove', (e) => {
                const rect = canvas.getBoundingClientRect();
                const x = e.clientX - rect.left;
                const y = e.clientY - rect.top;
                
                if (isDragging) {
                    if (dragType === 'pan') {
                        // å¹³ç§»æ‹–æ‹½
                        const deltaX = x - dragStartX;
                        const visibleDuration = videoMs / zoomLevel;
                        const deltaTime = (deltaX / (canvas.width - 16)) * visibleDuration; // 16 = 2*pad
                        const newPanOffset = originalPanOffset - deltaTime;
                        
                        // é™åˆ¶å¹³ç§»èŒƒå›´
                        const maxPanOffset = Math.max(0, videoMs - videoMs / zoomLevel);
                        panOffset = Math.max(0, Math.min(maxPanOffset, newPanOffset));
                        
                        showDragHint(e.clientX, e.clientY, `å¹³ç§»: ${fmtMs(panOffset)} - ${fmtMs(panOffset + visibleDuration)}`);
                        drawTimeline(videoEl.currentTime * 1000);
                    } else if (dragCueIndex >= 0) {
                        // å­—å¹•æ‹–æ‹½
                        const currentTime = screenToTime(x);
                        let newStart = originalStartTime;
                        let newEnd = originalEndTime;
                        
                        if (dragType === 'start') {
                            newStart = Math.max(0, Math.min(originalEndTime - 100, currentTime));
                            showDragHint(e.clientX, e.clientY, `å¼€å§‹æ—¶é—´: ${fmtMs(newStart)}`);
                        } else if (dragType === 'end') {
                            newEnd = Math.min(videoMs, Math.max(originalStartTime + 100, currentTime));
                            showDragHint(e.clientX, e.clientY, `ç»“æŸæ—¶é—´: ${fmtMs(newEnd)}`);
                        } else if (dragType === 'move') {
                            const duration = originalEndTime - originalStartTime;
                            const deltaTime = currentTime - screenToTime(dragStartX);
                            newStart = Math.max(0, Math.min(videoMs - duration, originalStartTime + deltaTime));
                            newEnd = newStart + duration;
                            showDragHint(e.clientX, e.clientY, `ç§»åŠ¨: ${fmtMs(newStart)} - ${fmtMs(newEnd)}`);
                        }
                        
                        updateCueTime(dragCueIndex, newStart, newEnd);
                    }
                } else {
                    // æ›´æ–°é¼ æ ‡æ ·å¼
                    const hit = getCueAtPosition(x, y);
                    if (hit) {
                        canvas.style.cursor = 'ew-resize';
                        // æ˜¾ç¤ºæ‚¬åœæç¤º
                        const cue = cues[hit.index];
                        let hintText = '';
                        if (hit.type === 'start') {
                            hintText = `æ‹–æ‹½è°ƒæ•´å¼€å§‹æ—¶é—´: ${fmtMs(cue.start)}`;
                        } else if (hit.type === 'end') {
                            hintText = `æ‹–æ‹½è°ƒæ•´ç»“æŸæ—¶é—´: ${fmtMs(cue.end)}`;
                        } else if (hit.type === 'move') {
                            hintText = `æ‹–æ‹½ç§»åŠ¨å­—å¹•å—: ${fmtMs(cue.start)} - ${fmtMs(cue.end)}`;
                        }
                        showDragHint(e.clientX, e.clientY, hintText);
                    } else {
                        canvas.style.cursor = 'grab';
                        hideDragHint();
                    }
                }
            });

            // é¼ æ ‡é‡Šæ”¾äº‹ä»¶
            canvas.addEventListener('mouseup', (e) => {
                if (isDragging) {
                    // å¦‚æœæ­£åœ¨æ‹–æ‹½å­—å¹•ï¼Œç«‹å³è§¦å‘ä¿å­˜
                    if (dragCueIndex >= 0) {
                        triggerAutoSave(true); // ç«‹å³ä¿å­˜
                    }
                    
                    isDragging = false;
                    dragType = null;
                    dragCueIndex = -1;
                    canvas.style.cursor = 'grab';
                    hideDragHint();
                }
            });

            // é¼ æ ‡ç¦»å¼€äº‹ä»¶
            canvas.addEventListener('mouseleave', (e) => {
                if (isDragging) {
                    // å¦‚æœæ­£åœ¨æ‹–æ‹½å­—å¹•ï¼Œç«‹å³è§¦å‘ä¿å­˜
                    if (dragCueIndex >= 0) {
                        triggerAutoSave(true); // ç«‹å³ä¿å­˜
                    }
                    
                    isDragging = false;
                    dragType = null;
                    dragCueIndex = -1;
                    canvas.style.cursor = 'grab';
                }
                hideDragHint();
            });

            // æ»šè½®ç¼©æ”¾äº‹ä»¶
            canvas.addEventListener('wheel', (e) => {
                e.preventDefault();
                
                const rect = canvas.getBoundingClientRect();
                const x = e.clientX - rect.left;
                const mouseTime = screenToTime(x);
                
                const zoomFactor = e.deltaY > 0 ? 0.8 : 1.25;
                const newZoomLevel = Math.max(0.1, Math.min(10, zoomLevel * zoomFactor));
                
                // ä»¥é¼ æ ‡ä½ç½®ä¸ºä¸­å¿ƒè¿›è¡Œç¼©æ”¾
                const zoomRatio = newZoomLevel / zoomLevel;
                const newPanOffset = mouseTime - (mouseTime - panOffset) * zoomRatio;
                
                zoomLevel = newZoomLevel;
                panOffset = Math.max(0, Math.min(videoMs - videoMs / zoomLevel, newPanOffset));
                
                drawTimeline(videoEl.currentTime * 1000);
            });

            // é”®ç›˜å¿«æ·é”®
            document.addEventListener('keydown', (e) => {
                if (e.target.tagName === 'INPUT' || e.target.tagName === 'TEXTAREA') return;
                
                switch(e.key) {
                    case 'r':
                    case 'R':
                        // é‡ç½®ç¼©æ”¾å’Œå¹³ç§»
                        zoomLevel = 1;
                        panOffset = 0;
                        drawTimeline(videoEl.currentTime * 1000);
                        break;
                    case 'f':
                    case 'F':
                        // é€‚åº”çª—å£å¤§å°
                        zoomLevel = 1;
                        panOffset = 0;
                        drawTimeline(videoEl.currentTime * 1000);
                        break;
                    case 'ArrowLeft':
                        // å‘å·¦å¹³ç§»
                        const leftStep = videoMs / zoomLevel / 10;
                        panOffset = Math.max(0, panOffset - leftStep);
                        drawTimeline(videoEl.currentTime * 1000);
                        break;
                    case 'ArrowRight':
                        // å‘å³å¹³ç§»
                        const rightStep = videoMs / zoomLevel / 10;
                        panOffset = Math.min(videoMs - videoMs / zoomLevel, panOffset + rightStep);
                        drawTimeline(videoEl.currentTime * 1000);
                        break;
                }
            });

            // ç¼©æ”¾æ§åˆ¶æŒ‰é’®äº‹ä»¶
            zoomInBtn.addEventListener('click', () => {
                const newZoomLevel = Math.min(10, zoomLevel * 1.25);
                zoomLevel = newZoomLevel;
                drawTimeline(videoEl.currentTime * 1000);
            });

            zoomOutBtn.addEventListener('click', () => {
                const newZoomLevel = Math.max(0.1, zoomLevel * 0.8);
                zoomLevel = newZoomLevel;
                drawTimeline(videoEl.currentTime * 1000);
            });

            zoomResetBtn.addEventListener('click', () => {
                zoomLevel = 1;
                panOffset = 0;
                drawTimeline(videoEl.currentTime * 1000);
            });

            // ä¿å­˜æŒ‰é’®ç‚¹å‡»äº‹ä»¶
            saveTimelineBtn.addEventListener('click', async () => {
                // ç¦ç”¨æŒ‰é’®é˜²æ­¢é‡å¤ç‚¹å‡»
                saveTimelineBtn.disabled = true;
                saveTimelineBtn.textContent = 'ä¿å­˜ä¸­...';
                saveTimelineBtn.style.background = '#6c757d';
                
                try {
                    const success = await saveSubtitles(true);
                    if (success) {
                        // ä¿å­˜æˆåŠŸï¼ŒçŸ­æš‚æ˜¾ç¤ºæˆåŠŸçŠ¶æ€
                        saveTimelineBtn.textContent = 'å·²ä¿å­˜';
                        saveTimelineBtn.style.background = '#28a745';
                        setTimeout(() => {
                            saveTimelineBtn.textContent = 'ä¿å­˜';
                            saveTimelineBtn.style.background = '#28a745';
                            saveTimelineBtn.disabled = false;
                        }, 2000);
                    } else {
                        // ä¿å­˜å¤±è´¥
                        saveTimelineBtn.textContent = 'ä¿å­˜å¤±è´¥';
                        saveTimelineBtn.style.background = '#dc3545';
                        setTimeout(() => {
                            saveTimelineBtn.textContent = 'ä¿å­˜';
                            saveTimelineBtn.style.background = '#28a745';
                            saveTimelineBtn.disabled = false;
                        }, 3000);
                    }
                } catch (e) {
                    console.error('ä¿å­˜å¤±è´¥:', e);
                    saveTimelineBtn.textContent = 'ä¿å­˜å¤±è´¥';
                    saveTimelineBtn.style.background = '#dc3545';
                    setTimeout(() => {
                        saveTimelineBtn.textContent = 'ä¿å­˜';
                        saveTimelineBtn.style.background = '#28a745';
                        saveTimelineBtn.disabled = false;
                    }, 3000);
                }
            });

            window.addEventListener('resize', () => drawTimeline(videoEl.currentTime*1000));

            videoEl.addEventListener('timeupdate', () => updateActive(Math.floor(videoEl.currentTime*1000)));

            fetch(`/viewer_api/${taskId}/subtitles`).then(r=>r.json()).then(data => {
                if (data && data.code === 0) {
                    cues = data.subtitles || [];
                    videoMs = data.video_ms || (cues.length? cues[cues.length-1].end : 0);
                    speakers = (data.speakers || []).filter(Boolean);
                    const translationFiles = data.translation_files || [];
                    
                    renderList();
                    drawTimeline(0);
                    
                    // å¦‚æœæœ‰ç¿»è¯‘æ–‡ä»¶ï¼Œæ˜¾ç¤ºæç¤º
                    if (translationFiles.length > 0) {
                        console.log(`æ£€æµ‹åˆ°ç¿»è¯‘æ–‡ä»¶: ${translationFiles.join(', ')}`);
                        // åœ¨é¡µé¢ä¸Šæ˜¾ç¤ºä¸€ä¸ªé€šçŸ¥
                        const notification = document.createElement('div');
                        notification.style.cssText = `
                            position: fixed; top: 20px; right: 20px; z-index: 1000;
                            background: #28a745; color: white; padding: 10px 15px;
                            border-radius: 5px; font-size: 14px; box-shadow: 0 2px 10px rgba(0,0,0,0.2);
                        `;
                        notification.innerHTML = `âœ… å·²åŠ è½½ç¿»è¯‘æ–‡ä»¶: ${translationFiles.join(', ')}`;
                        document.body.appendChild(notification);
                        
                        // 3ç§’åè‡ªåŠ¨éšè—
                        setTimeout(() => {
                            if (notification.parentNode) {
                                notification.parentNode.removeChild(notification);
                            }
                        }, 3000);
                    }
                }
            });

            async function onSaveSrt() {
                try {
                    updateSaveStatus('ä¿å­˜ä¸­...', '#ffc107');
                    const payload = { subtitles: cues.map(c => ({
                        start: Number(c.start)||0,
                        end: Number(c.end)||0,
                        text: String(c.text||'').trim(),
                        speaker: String(c.speaker||'').trim(),
                    })), srt_with_spk: true };
                    const res = await fetch(`/viewer_api/${taskId}/export_srt`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });
                    const data = await res.json();
                    if (data && data.code === 0 && data.download_url) {
                        updateSaveStatus('å·²ä¿å­˜', '#28a745');
                        window.location.href = data.download_url;
                    } else {
                        updateSaveStatus('ä¿å­˜å¤±è´¥', '#dc3545');
                        alert(data && data.msg ? data.msg : 'ä¿å­˜å¤±è´¥');
                    }
                } catch (e) {
                    console.error(e);
                    updateSaveStatus('ä¿å­˜å¤±è´¥', '#dc3545');
                    alert('ä¿å­˜å¤±è´¥');
                }
            }

            async function onSaveJson() {
                try {
                    const payload = { subtitles: cues.map(c => ({
                        start: Number(c.start)||0,
                        end: Number(c.end)||0,
                        startraw: c.startraw,
                        endraw: c.endraw,
                        text: String(c.text||'').trim(),
                        speaker: String(c.speaker||'').trim(),
                    })) };
                    const res = await fetch(`/viewer_api/${taskId}/export_json`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });
                    const data = await res.json();
                    if (data && data.code === 0 && data.download_url) {
                        window.location.href = data.download_url;
                    } else {
                        alert(data && data.msg ? data.msg : 'ä¿å­˜å¤±è´¥');
                    }
                } catch (e) {
                    console.error(e);
                    alert('ä¿å­˜å¤±è´¥');
                }
            }

            function onAddSubtitles() {
                if (!cues || cues.length === 0) {
                    alert('æ²¡æœ‰å­—å¹•æ•°æ®ï¼Œæ— æ³•æ·»åŠ å­—å¹•');
                    return;
                }
                showAddSubModal();
            }

            async function onGenerateTTS() {
                try {
                    if (!cues || cues.length === 0) {
                        alert('æ²¡æœ‰å­—å¹•æ•°æ®ï¼Œæ— æ³•ç”ŸæˆTTSéŸ³é¢‘');
                        return;
                    }
                    
                    const confirmed = confirm('å¼€å§‹ç”ŸæˆTTSéŸ³é¢‘ï¼Ÿè¿™å°†æ ¹æ®å­—å¹•å†…å®¹ç”Ÿæˆäººå£°éŸ³é¢‘æ–‡ä»¶ã€‚');
                    if (!confirmed) return;
                    
                    // æ˜¾ç¤ºè¿›åº¦æç¤º
                    btnGenerateTTS.textContent = 'ç”Ÿæˆä¸­...';
                    btnGenerateTTS.disabled = true;
                    
                    // å‡†å¤‡TTSè¯·æ±‚æ•°æ®
                    const payload = { 
                        subtitles: cues.map((c, index) => ({
                            line: index + 1,
                            start_time: Number(c.start) || 0,
                            end_time: Number(c.end) || 0,
                            startraw: c.startraw || '',
                            endraw: c.endraw || '',
                            time: `${c.startraw || ''} --> ${c.endraw || ''}`,
                            text: String(c.text || '').trim(),
                            speaker: String(c.speaker || '').trim(),
                        }))
                    };
                    
                    console.log('å‘é€TTSç”Ÿæˆè¯·æ±‚æ•°æ®:', payload);
                    
                    const res = await fetch(`/viewer_api/${taskId}/generate_tts`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });
                    const data = await res.json();
                    
                    if (data && data.code === 0) {
                        alert('TTSéŸ³é¢‘ç”Ÿæˆä»»åŠ¡å·²å¯åŠ¨ï¼Œè¯·ç¨åæŸ¥çœ‹ç»“æœ');
                        // å¯ä»¥è·³è½¬åˆ°ä»»åŠ¡çŠ¶æ€é¡µé¢
                        window.open(`/tts_result/${data.task_id}`, '_blank');
                    } else {
                        alert(data && data.msg ? data.msg : 'TTSç”Ÿæˆå¯åŠ¨å¤±è´¥');
                    }
                } catch (e) {
                    console.error(e);
                    alert('TTSç”Ÿæˆå¯åŠ¨å¤±è´¥');
                } finally {
                    // æ¢å¤æŒ‰é’®çŠ¶æ€
                    btnGenerateTTS.textContent = 'ç”ŸæˆTTSéŸ³é¢‘';
                    btnGenerateTTS.disabled = false;
                }
            }

            async function onSynthesizeVideo() {
                try {
                    if (!cues || cues.length === 0) {
                        alert('æ²¡æœ‰å­—å¹•æ•°æ®ï¼Œæ— æ³•åˆæˆè§†é¢‘');
                        return;
                    }
                    
                    const confirmed = confirm('å¼€å§‹åˆæˆè§†é¢‘ï¼Ÿè¿™å°†ä½¿ç”¨Demucsåˆ†ç¦»åŸè§†é¢‘äººå£°ï¼Œç„¶åä¸TTSéŸ³é¢‘åˆæˆæ–°è§†é¢‘ã€‚');
                    if (!confirmed) return;
                    
                    // æ˜¾ç¤ºè¿›åº¦æç¤º + å¼¹çª—
                    btnSynthesizeVideo.textContent = 'åˆæˆä¸­...';
                    btnSynthesizeVideo.disabled = true;
                    showSynthModal('æ­£åœ¨å¯åŠ¨ä»»åŠ¡...');
                    
                    // å‡†å¤‡è§†é¢‘åˆæˆè¯·æ±‚æ•°æ®
                    const payload = { 
                        subtitles: cues.map((c, index) => ({
                            line: index + 1,
                            start_time: Number(c.start) || 0,
                            end_time: Number(c.end) || 0,
                            startraw: c.startraw || '',
                            endraw: c.endraw || '',
                            time: `${c.startraw || ''} --> ${c.endraw || ''}`,
                            text: String(c.text || '').trim(),
                            speaker: String(c.speaker || '').trim(),
                        }))
                    };
                    
                    console.log('å‘é€è§†é¢‘åˆæˆè¯·æ±‚æ•°æ®:', payload);
                    
                    const res = await fetch(`/viewer_api/${taskId}/synthesize_video`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });
                    const data = await res.json();
                    if (data && data.code === 0 && data.task_id) {
                        const synthTaskId = data.task_id;
                        // è½®è¯¢ä»»åŠ¡çŠ¶æ€ï¼Œå®Œæˆåæ›¿æ¢æ’­æ”¾å™¨è§†é¢‘æº
                        const poll = async () => {
                            try {
                                const r = await fetch(`/task_status?task_id=${synthTaskId}`);
                                const s = await r.json();
                                if (s.code === 0 && s.data && Array.isArray(s.data.url)) {
                                    // æŸ¥æ‰¾ result.mp4
                                    let mp4 = s.data.url.find(u => /\/result\.mp4$/i.test(u));
                                    if (!mp4) {
                                        // å›é€€ä»»æ„ mp4
                                        mp4 = s.data.url.find(u => /\.mp4$/i.test(u));
                                    }
                                    if (mp4) {
                                        hideSynthModal();
                                        videoEl.src = mp4;
                                        try { videoEl.load(); videoEl.play(); } catch (e) {}
                                        return true;
                                    } else {
                                        hideSynthModal();
                                        // æ‰“å¼€ç»“æœé¡µä½œä¸ºå›é€€
                                        window.open(`/synthesis_result/${synthTaskId}`, '_blank');
                                        return true;
                                    }
                                } else if (s.code === -1) {
                                    // å¤„ç†ä¸­
                                    synthModalMsg.textContent = s.msg || 'æ­£åœ¨å¤„ç†ï¼Œè¯·ç¨å€™...';
                                    return false;
                                } else {
                                    synthModalMsg.textContent = (s && s.msg) ? `å¤±è´¥ï¼š${s.msg}` : 'ä»»åŠ¡å¤±è´¥';
                                    return true;
                                }
                            } catch (e) {
                                synthModalMsg.textContent = 'çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œç¨åé‡è¯•...';
                                return false;
                            }
                        };
                        // å¯åŠ¨è½®è¯¢
                        let done = false;
                        showSynthModal('ä»»åŠ¡å·²å¯åŠ¨ï¼Œæ­£åœ¨å¤„ç†ä¸­...');
                        for (let i = 0; i < 360; i++) { // æœ€é•¿çº¦12åˆ†é’Ÿï¼ˆ2s * 360ï¼‰
                            // eslint-disable-next-line no-await-in-loop
                            done = await poll();
                            if (done) break;
                            // eslint-disable-next-line no-await-in-loop
                            await new Promise(r => setTimeout(r, 2000));
                        }
                        if (!done) {
                            hideSynthModal();
                            alert('åˆæˆè¶…æ—¶ï¼Œè¯·ç¨ååœ¨ç»“æœé¡µæŸ¥çœ‹');
                            window.open(`/synthesis_result/${synthTaskId}`, '_blank');
                        }
                    } else {
                        alert(data && data.msg ? data.msg : 'è§†é¢‘åˆæˆå¯åŠ¨å¤±è´¥');
                    }
                } catch (e) {
                    console.error(e);
                    alert('è§†é¢‘åˆæˆå¯åŠ¨å¤±è´¥');
                } finally {
                    // æ¢å¤æŒ‰é’®çŠ¶æ€
                    btnSynthesizeVideo.textContent = 'åˆæˆè§†é¢‘';
                    btnSynthesizeVideo.disabled = false;
                    hideSynthModal();
                }
            }

            async function onTranslateSubtitle() {
                try {
                    if (!cues || cues.length === 0) {
                        alert('æ²¡æœ‰å­—å¹•æ•°æ®ï¼Œæ— æ³•è¿›è¡Œç¿»è¯‘');
                        return;
                    }
                    
                    // åˆ›å»ºè¯­è¨€é€‰æ‹©å¯¹è¯æ¡†
                    const languageOptions = [
                        { code: 'en', name: 'è‹±è¯­' },
                        { code: 'fr', name: 'æ³•è¯­' },
                        { code: 'ja', name: 'æ—¥è¯­' },
                        { code: 'zh-cn', name: 'æ±‰è¯­' },
                        { code: 'es', name: 'è¥¿ç­ç‰™è¯­' },
                        { code: 'pt', name: 'è‘¡è„ç‰™è¯­' },
                        { code: 'th', name: 'æ³°è¯­' }
                    ];
                    
                    // åˆ›å»ºå¯¹è¯æ¡†HTML
                    const dialogHtml = `
                        <div id="translateDialog" style="
                            position: fixed;
                            top: 0;
                            left: 0;
                            width: 100%;
                            height: 100%;
                            background: rgba(0,0,0,0.5);
                            display: flex;
                            justify-content: center;
                            align-items: center;
                            z-index: 1000;
                        ">
                            <div style="
                                background: white;
                                padding: 24px;
                                border-radius: 8px;
                                box-shadow: 0 4px 20px rgba(0,0,0,0.3);
                                min-width: 300px;
                            ">
                                <h3 style="margin: 0 0 16px 0;">é€‰æ‹©ç¿»è¯‘è¯­è¨€</h3>
                                <select id="targetLanguage" style="
                                    width: 100%;
                                    padding: 8px;
                                    border: 1px solid #ddd;
                                    border-radius: 4px;
                                    margin-bottom: 16px;
                                ">
                                    ${languageOptions.map(opt => `<option value="${opt.code}">${opt.name}</option>`).join('')}
                                </select>
                                <div style="display: flex; gap: 8px; justify-content: flex-end;">
                                    <button id="cancelTranslate" style="
                                        padding: 8px 16px;
                                        border: 1px solid #ddd;
                                        background: white;
                                        border-radius: 4px;
                                        cursor: pointer;
                                    ">å–æ¶ˆ</button>
                                    <button id="confirmTranslate" style="
                                        padding: 8px 16px;
                                        border: none;
                                        background: #9c27b0;
                                        color: white;
                                        border-radius: 4px;
                                        cursor: pointer;
                                    ">å¼€å§‹ç¿»è¯‘</button>
                                </div>
                            </div>
                        </div>
                    `;
                    
                    // æ·»åŠ å¯¹è¯æ¡†åˆ°é¡µé¢
                    document.body.insertAdjacentHTML('beforeend', dialogHtml);
                    
                    const dialog = document.getElementById('translateDialog');
                    const cancelBtn = document.getElementById('cancelTranslate');
                    const confirmBtn = document.getElementById('confirmTranslate');
                    const targetLanguageSelect = document.getElementById('targetLanguage');
                    
                    // å–æ¶ˆæŒ‰é’®äº‹ä»¶
                    cancelBtn.addEventListener('click', () => {
                        document.body.removeChild(dialog);
                    });
                    
                    // ç¡®è®¤æŒ‰é’®äº‹ä»¶
                    confirmBtn.addEventListener('click', async () => {
                        const targetLanguage = targetLanguageSelect.value;
                        document.body.removeChild(dialog);
                        
                        // æ˜¾ç¤ºè¿›åº¦æç¤º
                        btnTranslateSubtitle.textContent = 'ç¿»è¯‘ä¸­...';
                        btnTranslateSubtitle.disabled = true;
                        
                        try {
                            // å‡†å¤‡ç¿»è¯‘è¯·æ±‚æ•°æ®
                            const payload = {
                                subtitles: cues.map((c, index) => ({
                                    line: index + 1,
                                    start_time: Number(c.start) || 0,
                                    end_time: Number(c.end) || 0,
                                    startraw: c.startraw || '',
                                    endraw: c.endraw || '',
                                    time: `${c.startraw || ''} --> ${c.endraw || ''}`,
                                    text: String(c.text || '').trim(),
                                    speaker: String(c.speaker || '').trim(),
                                })),
                                target_language: targetLanguage,
                                translate_type: 0  // ä½¿ç”¨Googleç¿»è¯‘
                            };
                            
                            console.log('å‘é€ç¿»è¯‘è¯·æ±‚æ•°æ®:', payload);
                            
                            const res = await fetch(`/viewer_api/${taskId}/translate_subtitles`, {
                                method: 'POST',
                                headers: { 'Content-Type': 'application/json' },
                                body: JSON.stringify(payload)
                            });
                            const data = await res.json();
                            
                            if (data && data.code === 0) {
                                // å°†ç¿»è¯‘ç»“æœæ·»åŠ åˆ°å­—å¹•æ•°æ®ä¸­
                                if (data.translated_subtitles && data.translated_subtitles.length > 0) {
                                    data.translated_subtitles.forEach((translated, index) => {
                                        if (cues[index]) {
                                            cues[index].translated_text = translated.text;
                                        }
                                    });
                                    // é‡æ–°æ¸²æŸ“åˆ—è¡¨
                                    renderList();
                                    // æ£€æŸ¥æ˜¯å¦æœ‰è¯­éŸ³å…‹éš†æ˜ å°„ï¼Œå¦‚æœæœ‰åˆ™æ˜¾ç¤ºç”ŸæˆéŸ³é¢‘æŒ‰é’®
                                    checkVoiceMapping().then(hasMapping => {
                                        if (hasMapping) {
                                            btnGenerateAudio.style.display = 'inline-block';
                                        }
                                    });
                                    
                                    // æ£€æŸ¥æ˜¯å¦æœ‰å·²ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶ï¼Œå¦‚æœæœ‰åˆ™æ˜¾ç¤ºåˆæˆéŸ³é¢‘æŒ‰é’®
                                    checkGeneratedAudio().then(hasAudio => {
                                        if (hasAudio) {
                                            btnSynthesizeAudio.style.display = 'inline-block';
                                        }
                                    });
                                    alert(`ç¿»è¯‘å®Œæˆï¼å·²ç”Ÿæˆç¿»è¯‘æ–‡ä»¶ï¼š${data.srt_file}ã€‚æ‚¨å¯ä»¥ç¼–è¾‘ç¿»è¯‘ç»“æœï¼Œä¿®æ”¹ä¼šè‡ªåŠ¨ä¿å­˜ã€‚`);
                                } else {
                                    alert('ç¿»è¯‘å¤±è´¥ï¼šæ²¡æœ‰è¿”å›ç¿»è¯‘ç»“æœ');
                                }
                            } else {
                                alert(data && data.msg ? data.msg : 'ç¿»è¯‘å¤±è´¥');
                            }
                        } catch (e) {
                            console.error(e);
                            alert('ç¿»è¯‘å¤±è´¥');
                        } finally {
                            // æ¢å¤æŒ‰é’®çŠ¶æ€
                            btnTranslateSubtitle.textContent = 'ç¿»è¯‘å­—å¹•';
                            btnTranslateSubtitle.disabled = false;
                        }
                    });
                    
                } catch (e) {
                    console.error(e);
                    alert('ç¿»è¯‘å¯åŠ¨å¤±è´¥');
                }
            }

            // ä¿å­˜ç¿»è¯‘ç»“æœåŠŸèƒ½
            async function onSaveTranslation() {
                try {
                    if (!cues || cues.length === 0) {
                        alert('æ²¡æœ‰å­—å¹•æ•°æ®');
                        return;
                    }
                    
                    // æ£€æŸ¥æ˜¯å¦æœ‰ç¿»è¯‘å†…å®¹
                    const hasTranslation = cues.some(c => c.translated_text && c.translated_text.trim());
                    if (!hasTranslation) {
                        alert('æ²¡æœ‰ç¿»è¯‘å†…å®¹éœ€è¦ä¿å­˜');
                        return;
                    }
                    
                    btnSaveTranslation.textContent = 'ä¿å­˜ä¸­...';
                    btnSaveTranslation.disabled = true;
                    
                    // å‡†å¤‡ä¿å­˜æ•°æ®
                    const saveData = {
                        subtitles: cues.map((c, index) => ({
                            line: index + 1,
                            start_time: Number(c.start) || 0,
                            end_time: Number(c.end) || 0,
                            startraw: c.startraw || '',
                            endraw: c.endraw || '',
                            time: `${c.startraw || ''} --> ${c.endraw || ''}`,
                            text: String(c.text || '').trim(),
                            translated_text: String(c.translated_text || '').trim(),
                            speaker: String(c.speaker || '').trim(),
                        }))
                    };
                    
                    const res = await fetch(`/viewer_api/${taskId}/save_translation`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(saveData)
                    });
                    const data = await res.json();
                    
                    if (data && data.code === 0) {
                        alert('ç¿»è¯‘ç»“æœä¿å­˜æˆåŠŸï¼');
                        btnSaveTranslation.style.display = 'none';
                    } else {
                        alert(data && data.msg ? data.msg : 'ä¿å­˜å¤±è´¥');
                    }
                } catch (e) {
                    console.error(e);
                    alert('ä¿å­˜å¤±è´¥');
                } finally {
                    btnSaveTranslation.textContent = 'ä¿å­˜ç¿»è¯‘';
                    btnSaveTranslation.disabled = false;
                }
            }

            // è¯­éŸ³å…‹éš†åŠŸèƒ½
            async function onVoiceClone() {
                try {
                    if (!cues || cues.length === 0) {
                        alert('æ²¡æœ‰å­—å¹•æ•°æ®');
                        return;
                    }
                    
                    // æ£€æŸ¥æ˜¯å¦æœ‰è¯´è¯äººä¿¡æ¯
                    const speakers = [...new Set(cues.map(c => c.speaker).filter(s => s && s.trim()))];
                    if (speakers.length === 0) {
                        alert('æ²¡æœ‰æ£€æµ‹åˆ°è¯´è¯äººä¿¡æ¯ï¼Œæ— æ³•è¿›è¡Œè¯­éŸ³å…‹éš†');
                        return;
                    }
                    
                    // æ˜¾ç¤ºè¯´è¯äººä¿¡æ¯ç¡®è®¤å¯¹è¯æ¡†
                    const speakerList = speakers.map(s => `<li>${s}</li>`).join('');
                    const confirmMessage = `æ£€æµ‹åˆ°ä»¥ä¸‹è¯´è¯äººï¼Œå°†ä¸ºä»–ä»¬åˆ›å»ºè¯­éŸ³å…‹éš†ï¼š\n\n${speakers.join(', ')}\n\næ˜¯å¦ç»§ç»­ï¼Ÿ`;
                    
                    if (!confirm(confirmMessage)) {
                        return;
                    }
                    
                    btnVoiceClone.textContent = 'è¯­éŸ³å…‹éš†ä¸­...';
                    btnVoiceClone.disabled = true;
                    
                    // å‡†å¤‡è¯­éŸ³å…‹éš†è¯·æ±‚æ•°æ®
                    const payload = {
                        speakers: speakers,
                        subtitles: cues.map((c, index) => ({
                            line: index + 1,
                            start_time: Number(c.start) || 0,
                            end_time: Number(c.end) || 0,
                            startraw: c.startraw || '',
                            endraw: c.endraw || '',
                            time: `${c.startraw || ''} --> ${c.endraw || ''}`,
                            text: String(c.text || '').trim(),
                            speaker: String(c.speaker || '').trim(),
                        }))
                    };
                    
                    console.log('å‘é€è¯­éŸ³å…‹éš†è¯·æ±‚æ•°æ®:', payload);
                    
                    const res = await fetch(`/viewer_api/${taskId}/voice_clone`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });
                    const data = await res.json();
                    
                    if (data && data.code === 0) {
                        if (data.voice_clones && data.voice_clones.length > 0) {
                            alert(`è¯­éŸ³å…‹éš†å®Œæˆï¼æˆåŠŸä¸º ${data.voice_clones.length} ä¸ªè¯´è¯äººåˆ›å»ºäº†è¯­éŸ³å…‹éš†ã€‚`);
                            console.log('è¯­éŸ³å…‹éš†ç»“æœ:', data.voice_clones);
                            // æ˜¾ç¤ºç”ŸæˆéŸ³é¢‘æŒ‰é’®
                            btnGenerateAudio.style.display = 'inline-block';
                        } else {
                            alert('è¯­éŸ³å…‹éš†å¤±è´¥ï¼šæ²¡æœ‰è¿”å›å…‹éš†ç»“æœ');
                        }
                    } else {
                        alert(data && data.msg ? data.msg : 'è¯­éŸ³å…‹éš†å¤±è´¥');
                    }
                } catch (e) {
                    console.error(e);
                    alert('è¯­éŸ³å…‹éš†å¤±è´¥');
                } finally {
                    btnVoiceClone.textContent = 'è¯­éŸ³å…‹éš†';
                    btnVoiceClone.disabled = false;
                }
            }

            // åˆæˆéŸ³é¢‘åŠŸèƒ½ - ç›´æ¥åˆæˆå·²ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
            async function onSynthesizeAudio() {
                try {
                    if (!cues || cues.length === 0) {
                        alert('æ²¡æœ‰å­—å¹•æ•°æ®');
                        return;
                    }
                    
                    // æ£€æŸ¥æ˜¯å¦æœ‰ç¿»è¯‘å­—å¹•
                    const hasTranslation = cues.some(cue => (cue.translated_text && cue.translated_text.trim()) || (cue.translation && cue.translation.trim()));
                    if (!hasTranslation) {
                        alert('è¯·å…ˆç¿»è¯‘å­—å¹•');
                        return;
                    }
                    
                    // ç¡®è®¤åˆæˆéŸ³é¢‘
                    const confirmMessage = `å³å°†åˆæˆ ${cues.length} æ¡å­—å¹•çš„éŸ³é¢‘æ–‡ä»¶ã€‚\n\næ˜¯å¦ç»§ç»­ï¼Ÿ`;
                    if (!confirm(confirmMessage)) {
                        return;
                    }
                    
                    btnSynthesizeAudio.textContent = 'åˆæˆéŸ³é¢‘ä¸­...';
                    btnSynthesizeAudio.disabled = true;
                    
                    console.log('å¼€å§‹åˆæˆéŸ³é¢‘...');
                    
                    const res = await fetch(`/viewer_api/${taskId}/synthesize_audio`, {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({
                            subtitles: cues.map((c, index) => ({
                                line: index + 1,
                                start_time: Number(c.start) || 0,
                                end_time: Number(c.end) || 0,
                                text: c.translated_text || c.translation || c.text,
                                speaker: c.speaker || 'speaker_0'
                            }))
                        })
                    });
                    
                    const data = await res.json();
                    if (data.code === 0) {
                        alert(`éŸ³é¢‘åˆæˆæˆåŠŸï¼\\nè¾“å‡ºæ–‡ä»¶: ${data.output_file}`);
                        console.log('åˆæˆç»“æœ:', data);
                    } else {
                        alert(`éŸ³é¢‘åˆæˆå¤±è´¥: ${data.msg}`);
                    }
                } catch (e) {
                    console.error(e);
                    alert('éŸ³é¢‘åˆæˆå¤±è´¥');
                } finally {
                    btnSynthesizeAudio.textContent = 'åˆæˆéŸ³é¢‘';
                    btnSynthesizeAudio.disabled = false;
                }
            }

            // ç”ŸæˆéŸ³é¢‘åŠŸèƒ½
            async function onGenerateAudio() {
                try {
                    if (!cues || cues.length === 0) {
                        alert('æ²¡æœ‰å­—å¹•æ•°æ®');
                        return;
                    }
                    
                    // æ£€æŸ¥æ˜¯å¦æœ‰ç¿»è¯‘å†…å®¹
                    const hasTranslation = cues.some(c => c.translated_text && c.translated_text.trim());
                    if (!hasTranslation) {
                        alert('æ²¡æœ‰ç¿»è¯‘å†…å®¹ï¼Œè¯·å…ˆè¿›è¡Œå­—å¹•ç¿»è¯‘');
                        return;
                    }
                    
                    // æ£€æŸ¥æ˜¯å¦æœ‰è¯­éŸ³å…‹éš†æ˜ å°„
                    const hasVoiceMapping = await checkVoiceMapping();
                    if (!hasVoiceMapping) {
                        alert('æ²¡æœ‰æ‰¾åˆ°è¯­éŸ³å…‹éš†æ˜ å°„ï¼Œè¯·å…ˆè¿›è¡Œè¯­éŸ³å…‹éš†');
                        return;
                    }
                    
                    // ç¡®è®¤ç”ŸæˆéŸ³é¢‘
                    const confirmMessage = `å³å°†ä¸º ${cues.length} æ¡ç¿»è¯‘å­—å¹•ç”ŸæˆéŸ³é¢‘ï¼Œä½¿ç”¨è¯­éŸ³å…‹éš†æŠ€æœ¯ã€‚\n\næ˜¯å¦ç»§ç»­ï¼Ÿ`;
                    if (!confirm(confirmMessage)) {
                        return;
                    }
                    
                    btnGenerateAudio.textContent = 'ç”ŸæˆéŸ³é¢‘ä¸­...';
                    btnGenerateAudio.disabled = true;
                    
                    // å‡†å¤‡ç”ŸæˆéŸ³é¢‘è¯·æ±‚æ•°æ®
                    const payload = {
                        subtitles: cues.map((c, index) => ({
                            line: index + 1,
                            start_time: Number(c.start) || 0,
                            end_time: Number(c.end) || 0,
                            startraw: c.startraw || '',
                            endraw: c.endraw || '',
                            time: `${c.startraw || ''} --> ${c.endraw || ''}`,
                            text: String(c.text || '').trim(),
                            translated_text: String(c.translated_text || '').trim(),
                            speaker: String(c.speaker || '').trim(),
                        }))
                    };
                    
                    console.log('å‘é€ç”ŸæˆéŸ³é¢‘è¯·æ±‚æ•°æ®:', payload);
                    
                    const res = await fetch(`/viewer_api/${taskId}/generate_audio`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });
                    const data = await res.json();
                    
                    if (data && data.code === 0) {
                        alert(`éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼\n\nç”Ÿæˆçš„æ–‡ä»¶ï¼š\n${data.audio_file}\n\næ€»æ—¶é•¿ï¼š${data.duration || 'æœªçŸ¥'}`);
                        console.log('éŸ³é¢‘ç”Ÿæˆç»“æœ:', data);
                    } else {
                        alert(data && data.msg ? data.msg : 'éŸ³é¢‘ç”Ÿæˆå¤±è´¥');
                    }
                } catch (e) {
                    console.error(e);
                    alert('éŸ³é¢‘ç”Ÿæˆå¤±è´¥');
                } finally {
                    btnGenerateAudio.textContent = 'ç”ŸæˆéŸ³é¢‘';
                    btnGenerateAudio.disabled = false;
                }
            }

            // æ£€æŸ¥è¯­éŸ³å…‹éš†æ˜ å°„æ˜¯å¦å­˜åœ¨
            async function checkVoiceMapping() {
                try {
                    const res = await fetch(`/viewer_api/${taskId}/check_voice_mapping`);
                    const data = await res.json();
                    return data && data.code === 0 && data.has_mapping;
                } catch (e) {
                    console.error('æ£€æŸ¥è¯­éŸ³æ˜ å°„å¤±è´¥:', e);
                    return false;
                }
            }
            
            // æ£€æŸ¥æ˜¯å¦æœ‰å·²ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
            async function checkGeneratedAudio() {
                try {
                    const res = await fetch(`/viewer_api/${taskId}/check_generated_audio`);
                    const data = await res.json();
                    return data && data.code === 0 && data.has_audio;
                } catch (e) {
                    console.error('æ£€æŸ¥å·²ç”ŸæˆéŸ³é¢‘å¤±è´¥:', e);
                    return false;
                }
            }

            btnTranslateSubtitle.addEventListener('click', onTranslateSubtitle);
            btnSaveTranslation.addEventListener('click', onSaveTranslation);
            btnVoiceClone.addEventListener('click', onVoiceClone);
            btnGenerateAudio.addEventListener('click', onGenerateAudio);
            btnSynthesizeAudio.addEventListener('click', onSynthesizeAudio);
            btnSynthesizeVideo.addEventListener('click', onSynthesizeVideo);
            btnAddSubtitles.addEventListener('click', onAddSubtitles);
            btnSaveSrt.addEventListener('click', onSaveSrt);
            btnSaveJson.addEventListener('click', onSaveJson);
            </script>
        </body>
        </html>
        """
        html = html.replace('((VIDEO_URL))', video_url)
        html = html.replace('((TASK_ID))', task_id)
        html = html.replace('((TASK_ID_JSON))', json.dumps(task_id))
        # å°†æ¨¡æ¿ä¸­ä¸ºè§„é¿ Python/Jinja å†²çªè€Œä½¿ç”¨çš„åŒèŠ±æ‹¬å·æ¢å¤ä¸ºå•èŠ±æ‹¬å·
        html = html.replace('{{', '{').replace('}}', '}')
        return html

    @app.route('/viewer_api/<task_id>/subtitles', methods=['GET'])
    def viewer_subtitles(task_id):
        # è¿”å›è§£æåçš„å­—å¹• JSONï¼Œä»¥åŠè§†é¢‘æ€»æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        # æŒ‘é€‰æ–‡ä»¶
        from videotrans.util import help_srt, help_ffmpeg
        files = [f for f in task_dir.iterdir() if f.is_file()]
        srt_path = None
        video_path = None
        from videotrans.configure import config as _cfg
        exts = set([e.lower() for e in _cfg.VIDEO_EXTS + _cfg.AUDIO_EXITS])
        
        # ä¼˜å…ˆé€‰æ‹©raw.srtæ–‡ä»¶
        srt_files = [f for f in files if f.name.lower().endswith('.srt')]
        print(f"æ‰¾åˆ°çš„SRTæ–‡ä»¶: {[f.name for f in srt_files]}")
        
        # é¦–å…ˆæŸ¥æ‰¾raw.srtæ–‡ä»¶
        raw_srt_path = task_dir / "raw.srt"
        if raw_srt_path.exists():
            srt_path = raw_srt_path
            print(f"é€‰æ‹©SRTæ–‡ä»¶: raw.srt")
        else:
            # å¦‚æœæ²¡æœ‰raw.srtï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªSRTæ–‡ä»¶
            if srt_files:
                srt_path = srt_files[0]
                print(f"é€‰æ‹©ç¬¬ä¸€ä¸ªSRTæ–‡ä»¶: {srt_path.name}")
            else:
                srt_path = None
            
        for f in files:
            lower = f.name.lower()
            if any(lower.endswith('.' + e) for e in exts):
                if video_path is None:
                    video_path = f
        if not srt_path or not video_path:
            return jsonify({"code": 1, "msg": "ä»»åŠ¡æ–‡ä»¶ç¼ºå¤±ï¼ˆéœ€è¦è§†é¢‘ä¸srtï¼‰"}), 400

        # è§£æå­—å¹•ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ä¸å˜ï¼‰
        print(f"å¼€å§‹è§£æSRTæ–‡ä»¶: {srt_path}")
        subs = help_srt.get_subtitle_from_srt(srt_path.as_posix())
        print(f"è§£æåˆ° {len(subs)} æ¡å­—å¹•")
        
        # æå–è¯´è¯äººå¹¶æ¸…ç†æ–‡æœ¬ï¼ˆæŒ‰é¦–è¡Œ [xxx] è§£æï¼‰
        import re as _re
        parsed = []
        spk_set = set()
        for it in subs:
            text = it.get('text', '') or ''
            speaker = ''
            if text:
                first_line, *rest = text.split('\n')
                m = _re.match(r'^\s*\[([^\]]+)\]\s*(.*)$', first_line)
                if m:
                    speaker = m.group(1).strip()
                    first_line = m.group(2).strip()
                text = '\n'.join([first_line] + rest).strip()
            if speaker:
                spk_set.add(speaker)
            parsed.append({
                'line': int(it.get('line', len(parsed)+1)),
                'start': int(it.get('start_time')) if 'start_time' in it else 0,
                'end': int(it.get('end_time')) if 'end_time' in it else 0,
                'startraw': it.get('startraw') or it.get('time', '').split(' --> ')[0] if it.get('time') else help_srt.ms_to_time_string(ms=int(it.get('start_time',0))),
                'endraw': it.get('endraw') or it.get('time', '').split(' --> ')[-1] if it.get('time') else help_srt.ms_to_time_string(ms=int(it.get('end_time',0))),
                'text': text,
                'speaker': speaker,
                'duration': (int(it.get('end_time', 0)) - int(it.get('start_time', 0))) if ('end_time' in it and 'start_time' in it) else 0,
            })

        # æ£€æµ‹å¹¶åŠ è½½ç¿»è¯‘æ–‡ä»¶ï¼ˆä¸å½±å“åŸæœ‰é€»è¾‘ï¼‰
        translation_files = {}
        for f in files:
            if f.name.startswith('translated_') and f.name.endswith('.srt'):
                # æå–è¯­è¨€ä»£ç 
                lang_code = f.name.replace('translated_', '').replace('.srt', '')
                try:
                    # è§£æç¿»è¯‘æ–‡ä»¶
                    translated_srt = help_srt.get_subtitle_from_srt(f.as_posix())
                    translation_files[lang_code] = translated_srt
                    print(f"æ£€æµ‹åˆ°ç¿»è¯‘æ–‡ä»¶: {f.name}, è¯­è¨€: {lang_code}")
                except Exception as e:
                    print(f"è§£æç¿»è¯‘æ–‡ä»¶ {f.name} å¤±è´¥: {e}")

        # å°†ç¿»è¯‘å†…å®¹å¡«å……åˆ°å­—å¹•é¡¹ä¸­
        for subtitle_item in parsed:
            for lang_code, translated_srt in translation_files.items():
                # æŸ¥æ‰¾å¯¹åº”çš„ç¿»è¯‘æ–‡æœ¬ï¼ˆé€šè¿‡æ—¶é—´åŒ¹é…ï¼‰
                for trans_item in translated_srt:
                    if (abs(trans_item.get('start_time', 0) - subtitle_item.get('start', 0)) < 100 and
                        abs(trans_item.get('end_time', 0) - subtitle_item.get('end', 0)) < 100):
                        subtitle_item[f'translated_text_{lang_code}'] = trans_item.get('text', '')
                        break

        # è§†é¢‘æ€»æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
        try:
            video_ms = int(help_ffmpeg.get_video_duration(video_path.as_posix()) or 0)
        except Exception:
            video_ms = parsed[-1]['end'] if parsed else 0

        print(f"è§£æå®Œæˆï¼Œå…± {len(parsed)} æ¡å­—å¹•")
        print(f"è¯´è¯äºº: {sorted(list(spk_set))}")
        print(f"ç¿»è¯‘æ–‡ä»¶: {list(translation_files.keys())}")
        
        return jsonify({
            "code": 0, 
            "msg": "ok", 
            "subtitles": parsed, 
            "video_ms": video_ms, 
            "speakers": sorted(list(spk_set)),
            "translation_files": list(translation_files.keys())
        })

    @app.route('/viewer_api/<task_id>/export_srt', methods=['POST'])
    def viewer_export_srt(task_id):
        # å°†å‰ç«¯ç¼–è¾‘åçš„å­—å¹•å¯¼å‡ºä¸º SRT æ–‡ä»¶ï¼Œå¹¶è¿”å›ä¸‹è½½é“¾æ¥
        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        data = request.get_json(silent=True) or {}
        items = data.get('subtitles', [])
        if not isinstance(items, list) or len(items) < 1:
            return jsonify({"code": 1, "msg": "æ— æœ‰æ•ˆå­—å¹•"}), 400

        # ç»„è£…ä¸º help_srt.get_srt_from_list æ¥å—çš„ç»“æ„
        from videotrans.util import help_srt
        srt_list = []
        for i, it in enumerate(items, start=1):
            start = int(it.get('start', 0))
            end = int(it.get('end', 0))
            speaker = (it.get('speaker') or '').strip()
            text = (it.get('text') or '').strip()
            # æ ¹æ®å…¥å‚å†³å®šæ˜¯å¦åœ¨æ–‡æœ¬é¦–è¡Œæ¢å¤ [spk] å‰ç¼€
            if data.get('srt_with_spk') and speaker:
                if '\n' in text:
                    first, *rest = text.split('\n')
                    text = f"[{speaker}] " + first.strip()
                    if rest:
                        text += "\n" + "\n".join(rest)
                else:
                    text = f"[{speaker}] " + text
            srt_list.append({
                'line': i,
                'start_time': start,
                'end_time': end,
                'text': text,
            })

        try:
            srt_str = help_srt.get_srt_from_list(srt_list)
        except Exception as e:
            return jsonify({"code": 2, "msg": f"ç”ŸæˆSRTå¤±è´¥: {str(e)}"}), 500

        # ä¿å­˜åˆ°raw.srtæ–‡ä»¶
        raw_srt_path = task_dir / "raw.srt"
        raw_srt_path.write_text(srt_str, encoding='utf-8')
        download_url = f'/{API_RESOURCE}/{task_id}/raw.srt'
        print(f"å­—å¹•å·²ä¿å­˜åˆ°: raw.srt")

        return jsonify({"code": 0, "msg": "ok", "download_url": download_url})

    @app.route('/viewer_api/<task_id>/export_json', methods=['POST'])
    def viewer_export_json(task_id):
        # å¯¼å‡º JSONï¼ŒåŒ…å«æ—¶é—´èŒƒå›´ã€spk ä¸æ–‡å­—å†…å®¹
        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        data = request.get_json(silent=True) or {}
        items = data.get('subtitles', [])
        if not isinstance(items, list) or len(items) < 1:
            return jsonify({"code": 1, "msg": "æ— æœ‰æ•ˆå­—å¹•"}), 400

        # è§„èŒƒåŒ–å­—æ®µ
        out_items = []
        for it in items:
            out_items.append({
                'start': int(it.get('start', 0)),
                'end': int(it.get('end', 0)),
                'startraw': it.get('startraw') or '',
                'endraw': it.get('endraw') or '',
                'speaker': (it.get('speaker') or '').strip(),
                'text': (it.get('text') or '').strip(),
            })

        out_name = f'edited_{int(time.time())}.json'
        out_path = (task_dir / out_name).as_posix()
        Path(out_path).write_text(json.dumps({'subtitles': out_items}, ensure_ascii=False, indent=2), encoding='utf-8')
        download_url = f'/{API_RESOURCE}/{task_id}/{out_name}'
        return jsonify({"code": 0, "msg": "ok", "download_url": download_url})

    @app.route('/viewer_api/<task_id>/export_json_full', methods=['POST'])
    def viewer_export_json_full(task_id):
        # å°†å‰ç«¯ç¼–è¾‘åçš„å­—å¹•å¯¼å‡ºä¸º JSON æ–‡ä»¶ï¼Œå¹¶è¿”å›ä¸‹è½½é“¾æ¥
        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        data = request.get_json(silent=True) or {}
        items = data.get('subtitles', [])
        if not isinstance(items, list) or len(items) < 1:
            return jsonify({"code": 1, "msg": "æ— æœ‰æ•ˆå­—å¹•"}), 400

        # ç»„è£…ä¸º JSON æ ¼å¼
        json_data = {
            "subtitles": items,
            "video_ms": data.get('video_ms', 0),
            "speakers": data.get('speakers', [])
        }

        try:
            json_str = json.dumps(json_data, ensure_ascii=False)
        except Exception as e:
            return jsonify({"code": 2, "msg": f"ç”ŸæˆJSONå¤±è´¥: {str(e)}"}), 500

        out_name = f'edited_{int(time.time())}.json'
        out_path = (task_dir / out_name).as_posix()
        Path(out_path).write_text(json_str, encoding='utf-8')

        download_url = f'/{API_RESOURCE}/{task_id}/{out_name}'
        return jsonify({"code": 0, "msg": "ok", "download_url": download_url})

    @app.route('/viewer_api/<task_id>/synthesize_video', methods=['POST'])
    def viewer_synthesize_video(task_id):
        """è§†é¢‘åˆæˆæ¥å£ - ä½¿ç”¨ aucsåˆ†ç¦»äººå£°å¹¶ä¸TTSéŸ³é¢‘åˆæˆè§†é¢‘"""
        data = request.json
        if not data or 'subtitles' not in data:
            return jsonify({"code": 1, "msg": "ç¼ºå°‘å­—å¹•æ•°æ®"}), 400

        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        try:
            # æŸ¥æ‰¾åŸå§‹è§†é¢‘æ–‡ä»¶
            files = [f for f in task_dir.iterdir() if f.is_file()]
            video_path = None
            from videotrans.configure import config as _cfg
            exts = set([e.lower() for e in _cfg.VIDEO_EXTS + _cfg.AUDIO_EXITS])
            for f in files:
                lower = f.name.lower()
                if any(lower.endswith(f'.{ext}') for ext in exts):
                    video_path = f
                    break
            
            if not video_path:
                return jsonify({"code": 1, "msg": "æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶"}), 400

            # åˆ›å»ºæ–°çš„è§†é¢‘åˆæˆä»»åŠ¡
            synthesis_task_id = f"synthesis_{task_id}_{int(time.time())}"
            synthesis_dir = Path(TARGET_DIR) / synthesis_task_id
            synthesis_dir.mkdir(parents=True, exist_ok=True)

            # å¯åŠ¨è§†é¢‘åˆæˆä»»åŠ¡
            threading.Thread(target=start_video_synthesis_task, args=(
                synthesis_task_id, 
                str(video_path),
                data['subtitles']
            )).start()

            return jsonify({
                "code": 0,
                "msg": "è§†é¢‘åˆæˆä»»åŠ¡å·²å¯åŠ¨",
                "task_id": synthesis_task_id
            })

        except Exception as e:
            return jsonify({"code": 1, "msg": f"å¯åŠ¨è§†é¢‘åˆæˆå¤±è´¥: {str(e)}"}), 500

    @app.route('/viewer_api/<task_id>/generate_tts', methods=['POST'])
    def viewer_generate_tts(task_id):
        """TTSéŸ³é¢‘ç”Ÿæˆæ¥å£ - æ ¹æ®å­—å¹•å†…å®¹ç”Ÿæˆäººå£°éŸ³é¢‘"""
        data = request.json
        if not data or 'subtitles' not in data:
            return jsonify({"code": 1, "msg": "ç¼ºå°‘å­—å¹•æ•°æ®"}), 400

        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        try:
            # åˆ›å»ºæ–°çš„TTSä»»åŠ¡
            tts_task_id = f"tts_{task_id}_{int(time.time())}"
            tts_dir = Path(TARGET_DIR) / tts_task_id
            tts_dir.mkdir(parents=True, exist_ok=True)

            # å¯åŠ¨TTSç”Ÿæˆä»»åŠ¡
            threading.Thread(target=start_tts_generation_task, args=(
                tts_task_id, 
                data['subtitles']
            )).start()

            return jsonify({
                "code": 0,
                "msg": "TTSç”Ÿæˆä»»åŠ¡å·²å¯åŠ¨",
                "task_id": tts_task_id
            })

        except Exception as e:
            return jsonify({"code": 1, "msg": f"å¯åŠ¨TTSç”Ÿæˆå¤±è´¥: {str(e)}"}), 500

    @app.route('/viewer_api/<task_id>/voice_dubbing', methods=['POST'])
    def viewer_voice_dubbing(task_id):
        """æ™ºèƒ½é…éŸ³æ¥å£ - æ ¹æ®å­—å¹•å’Œè¯´è¯äººä¿¡æ¯è¿›è¡Œå¤šè§’è‰²é…éŸ³"""
        data = request.json
        if not data or 'subtitles' not in data:
            return jsonify({"code": 1, "msg": "ç¼ºå°‘å­—å¹•æ•°æ®"}), 400

        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        try:
            # æŸ¥æ‰¾åŸå§‹è§†é¢‘æ–‡ä»¶
            files = [f for f in task_dir.iterdir() if f.is_file()]
            video_path = None
            from videotrans.configure import config as _cfg
            exts = set([e.lower() for e in _cfg.VIDEO_EXTS + _cfg.AUDIO_EXITS])
            for f in files:
                lower = f.name.lower()
                if any(lower.endswith(f'.{ext}') for ext in exts):
                    video_path = f
                    break
            
            if not video_path:
                return jsonify({"code": 1, "msg": "æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶"}), 400

            # åˆ›å»ºæ–°çš„é…éŸ³ä»»åŠ¡
            dubbing_task_id = f"dubbing_{task_id}_{int(time.time())}"
            dubbing_dir = Path(TARGET_DIR) / dubbing_task_id
            dubbing_dir.mkdir(parents=True, exist_ok=True)

            # å¤åˆ¶åŸå§‹è§†é¢‘åˆ°é…éŸ³ä»»åŠ¡ç›®å½•
            import shutil
            target_video = dubbing_dir / video_path.name
            shutil.copy2(video_path, target_video)

            # ç”ŸæˆSRTæ–‡ä»¶ - å‰ç«¯å·²æä¾›å®Œæ•´æ ¼å¼çš„æ•°æ®
            subtitles = data['subtitles']
            
            # éªŒè¯æ•°æ®æ ¼å¼ï¼ˆå‰ç«¯åº”è¯¥å·²ç»æä¾›äº†å®Œæ•´æ ¼å¼ï¼‰
            print(f"æ”¶åˆ°å­—å¹•æ•°æ®: {len(subtitles)} æ¡")
            if subtitles:
                print(f"ç¬¬ä¸€æ¡å­—å¹•ç¤ºä¾‹: {subtitles[0]}")
            
            # ç›´æ¥ä½¿ç”¨å‰ç«¯æä¾›çš„å®Œæ•´æ ¼å¼æ•°æ®ç”ŸæˆSRT
            srt_content = tools.get_srt_from_list(subtitles)
            srt_file = dubbing_dir / f"subtitles_{int(time.time())}.srt"
            
            # ç¡®ä¿SRTæ–‡ä»¶ä½¿ç”¨UTF-8ç¼–ç ï¼Œå¹¶å¤„ç†å¯èƒ½çš„ç¼–ç é—®é¢˜
            try:
                srt_file.write_text(srt_content, encoding='utf-8')
                # éªŒè¯æ–‡ä»¶å¯ä»¥æ­£ç¡®è¯»å–
                with open(srt_file, 'r', encoding='utf-8') as f:
                    test_content = f.read()
                print(f"SRTæ–‡ä»¶ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(test_content)} å­—ç¬¦")
            except UnicodeEncodeError:
                # å¦‚æœUTF-8ç¼–ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
                print("UTF-8ç¼–ç å¤±è´¥ï¼Œå°è¯•GBKç¼–ç ")
                srt_file.write_text(srt_content, encoding='gbk')
            except Exception as e:
                print(f"SRTæ–‡ä»¶ç”Ÿæˆå¤±è´¥: {str(e)}")
                # æœ€åå°è¯•ï¼Œä½¿ç”¨é”™è¯¯å¤„ç†
                srt_file.write_text(srt_content, encoding='utf-8', errors='replace')
                print("å·²ä½¿ç”¨é”™è¯¯æ›¿æ¢æ¨¡å¼ç”ŸæˆSRTæ–‡ä»¶")

            # å¯åŠ¨äººå£°åˆ†ç¦»å’Œé…éŸ³ä»»åŠ¡
            threading.Thread(target=start_voice_dubbing_task, args=(
                dubbing_task_id, 
                str(target_video), 
                str(srt_file),
                subtitles
            )).start()

            return jsonify({
                "code": 0,
                "msg": "é…éŸ³ä»»åŠ¡å·²å¯åŠ¨",
                "task_id": dubbing_task_id
            })

        except Exception as e:
            return jsonify({"code": 1, "msg": f"å¯åŠ¨é…éŸ³å¤±è´¥: {str(e)}"}), 500

    @app.route('/viewer_api/<task_id>/translate_subtitles', methods=['POST'])
    def viewer_translate_subtitles(task_id):
        """ç¿»è¯‘å­—å¹•æ¥å£ - å°†å­—å¹•ç¿»è¯‘ä¸ºæŒ‡å®šè¯­è¨€"""
        data = request.json
        if not data or 'subtitles' not in data or 'target_language' not in data:
            return jsonify({"code": 1, "msg": "ç¼ºå°‘å­—å¹•æ•°æ®æˆ–ç›®æ ‡è¯­è¨€"}), 400

        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        try:
            from videotrans import translator
            from videotrans.configure import config as _config
            
            # è®¾ç½®ç¿»è¯‘çŠ¶æ€ï¼Œç¡®ä¿ç¿»è¯‘å™¨ä¸ä¼šæå‰é€€å‡º
            original_status = _config.current_status
            original_box_trans = _config.box_trans
            _config.current_status = 'ing'
            _config.box_trans = 'ing'
            
            try:
                # è·å–ç¿»è¯‘å‚æ•°
                subtitles = data['subtitles']
                target_language = data['target_language']
                translate_type = data.get('translate_type', 0)  # é»˜è®¤ä½¿ç”¨Googleç¿»è¯‘
                
                # å‡†å¤‡ç¿»è¯‘æ•°æ® - ç¿»è¯‘å™¨æœŸæœ›çš„æ˜¯åŒ…å«å­—å…¸çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸æœ‰textå­—æ®µ
                text_list = []
                for subtitle in subtitles:
                    text = subtitle.get('text', '').strip()
                    if text:
                        text_list.append({'text': text})
                
                if not text_list:
                    return jsonify({"code": 1, "msg": "æ²¡æœ‰å¯ç¿»è¯‘çš„æ–‡æœ¬å†…å®¹"}), 400
                
                print(f"å¼€å§‹ç¿»è¯‘ {len(text_list)} æ¡å­—å¹•åˆ° {target_language}")
                print(f"ç¿»è¯‘æ•°æ®ç¤ºä¾‹: {text_list[:2] if text_list else 'None'}")
                
                # è°ƒç”¨ç¿»è¯‘åŠŸèƒ½
                translated_texts = translator.run(
                    translate_type=translate_type,
                    text_list=text_list,
                    target_code=target_language,
                    source_code='zh-cn'  # å‡è®¾æºè¯­è¨€æ˜¯ä¸­æ–‡
                )
                
                print(f"ç¿»è¯‘ç»“æœç±»å‹: {type(translated_texts)}")
                print(f"ç¿»è¯‘ç»“æœé•¿åº¦: {len(translated_texts) if translated_texts else 0}")
                print(f"ç¿»è¯‘ç»“æœç¤ºä¾‹: {translated_texts[:2] if translated_texts else 'None'}")
                
                if not translated_texts:
                    return jsonify({"code": 1, "msg": "ç¿»è¯‘å¤±è´¥"}), 500
                
                # ç¿»è¯‘å™¨è¿”å›çš„æ˜¯ä¿®æ”¹åçš„text_listï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ç¿»è¯‘åçš„textå­—æ®µ
                # æ„å»ºè¿”å›ç»“æœ
                translated_subtitles = []
                for i, subtitle in enumerate(subtitles):
                    translated_subtitle = subtitle.copy()
                    # ä»ç¿»è¯‘ç»“æœä¸­è·å–å¯¹åº”çš„ç¿»è¯‘æ–‡æœ¬
                    if i < len(translated_texts) and isinstance(translated_texts[i], dict):
                        translated_subtitle['text'] = translated_texts[i].get('text', subtitle['text'])
                    else:
                        translated_subtitle['text'] = subtitle['text']
                    translated_subtitles.append(translated_subtitle)
                
                # ç”Ÿæˆå¸¦è¯­è¨€åç¼€çš„SRTæ–‡ä»¶
                from videotrans.util import help_srt
                import time
                
                # åˆ›å»ºç¿»è¯‘åçš„SRTå†…å®¹ï¼ˆæºå¸¦åŸå§‹æ—¶é—´ï¼Œå•ä½æ¯«ç§’ï¼‰
                srt_list = []
                for i, subtitle in enumerate(translated_subtitles):
                    # å‰ç«¯ä¼ å…¥çš„æ˜¯ start_time/end_timeï¼ˆæ¯«ç§’ï¼‰ï¼›ä¿æŒæ¯«ç§’ä¸å˜
                    st = int(subtitle.get('start_time', subtitle.get('start', 0)) or 0)
                    et = int(subtitle.get('end_time', subtitle.get('end', 0)) or 0)
                    srt_list.append({
                        'line': i + 1,
                        'start_time': st,
                        'end_time': et,
                        'text': subtitle.get('text', ''),
                    })
                
                srt_str = help_srt.get_srt_from_list(srt_list)
                
                # ç”Ÿæˆå¸¦è¯­è¨€åç¼€çš„æ–‡ä»¶å
                language_suffix = target_language.lower()
                srt_filename = f'translated_{language_suffix}.srt'
                srt_path = task_dir / srt_filename
                srt_path.write_text(srt_str, encoding='utf-8')
                
                return jsonify({
                    "code": 0,
                    "msg": "ç¿»è¯‘å®Œæˆ",
                    "translated_subtitles": translated_subtitles,
                    "srt_file": srt_filename
                })
                
            finally:
                # æ¢å¤åŸå§‹çŠ¶æ€
                _config.current_status = original_status
                _config.box_trans = original_box_trans
            
        except Exception as e:
            print(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return jsonify({"code": 1, "msg": f"ç¿»è¯‘å¤±è´¥: {str(e)}"}), 500

    @app.route('/viewer_api/<task_id>/save_translation', methods=['POST'])
    def viewer_save_translation(task_id):
        """ä¿å­˜ç¿»è¯‘ç»“æœæ¥å£"""
        data = request.json
        if not data or 'subtitles' not in data or 'target_language' not in data:
            return jsonify({"code": 1, "msg": "ç¼ºå°‘å­—å¹•æ•°æ®æˆ–ç›®æ ‡è¯­è¨€"}), 400

        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        try:
            from videotrans.util import help_srt
            
            subtitles = data['subtitles']
            target_language = data['target_language']
            
            # åˆ›å»ºç¿»è¯‘åçš„SRTå†…å®¹ï¼ˆæºå¸¦æ—¶é—´ï¼Œå•ä½æ¯«ç§’ï¼‰
            srt_list = []
            for i, subtitle in enumerate(subtitles):
                st = int(subtitle.get('start_time', subtitle.get('start', 0)) or 0)
                et = int(subtitle.get('end_time', subtitle.get('end', 0)) or 0)
                srt_list.append({
                    'line': i + 1,
                    'start_time': st,
                    'end_time': et,
                    'text': subtitle.get('translated_text', ''),
                })
            
            srt_str = help_srt.get_srt_from_list(srt_list)
            
            # ç”Ÿæˆå¸¦è¯­è¨€åç¼€çš„æ–‡ä»¶å
            language_suffix = target_language.lower()
            srt_filename = f'translated_{language_suffix}.srt'
            srt_path = task_dir / srt_filename
            srt_path.write_text(srt_str, encoding='utf-8')
            print(f"ç¿»è¯‘æ–‡ä»¶å·²ä¿å­˜åˆ°: {srt_filename}")
            
            return jsonify({
                "code": 0,
                "msg": "ç¿»è¯‘ä¿å­˜æˆåŠŸ",
                "srt_file": srt_filename
            })
            
        except Exception as e:
            print(f"ä¿å­˜ç¿»è¯‘å¤±è´¥: {str(e)}")
            return jsonify({"code": 1, "msg": f"ä¿å­˜ç¿»è¯‘å¤±è´¥: {str(e)}"}), 500
            
            # åŒæ—¶ä¿å­˜JSONæ ¼å¼çš„ç¿»è¯‘ç»“æœ
            translation_data = {
                "task_id": task_id,
                "original_subtitles": subtitles,
                "translation_timestamp": datetime.now().isoformat()
            }
            translation_json_path = task_dir / f"{task_id}_translation.json"
            with open(translation_json_path, 'w', encoding='utf-8') as f:
                json.dump(translation_data, f, ensure_ascii=False, indent=2)
            
            print(f"ç¿»è¯‘ç»“æœå·²ä¿å­˜: {translated_srt_path}")
            print(f"ç¿»è¯‘æ•°æ®å·²ä¿å­˜: {translation_json_path}")
            
            return jsonify({
                "code": 0,
                "msg": "ç¿»è¯‘ç»“æœä¿å­˜æˆåŠŸ",
                "srt_file": str(translated_srt_path),
                "json_file": str(translation_json_path)
            })
            
        except Exception as e:
            print(f"ä¿å­˜ç¿»è¯‘ç»“æœå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return jsonify({"code": 1, "msg": f"ä¿å­˜å¤±è´¥: {str(e)}"}), 500

    @app.route('/viewer_api/<task_id>/voice_clone', methods=['POST'])
    def viewer_voice_clone(task_id):
        """è¯­éŸ³å…‹éš†æ¥å£ - ä½¿ç”¨ElevenLabs instant cloneåŠŸèƒ½"""
        data = request.json
        if not data or 'speakers' not in data or 'subtitles' not in data:
            return jsonify({"code": 1, "msg": "ç¼ºå°‘è¯´è¯äººæˆ–å­—å¹•æ•°æ®"}), 400

        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        try:
            speakers = data['speakers']
            subtitles = data['subtitles']
            
            # æ£€æŸ¥ElevenLabs APIå¯†é’¥
            if not config.params.get('elevenlabstts_key'):
                return jsonify({"code": 1, "msg": "æœªé…ç½®ElevenLabs APIå¯†é’¥"}), 400
            
            print(f"å¼€å§‹ä¸º {len(speakers)} ä¸ªè¯´è¯äººè¿›è¡Œè¯­éŸ³å…‹éš†: {speakers}")
            
            # é¦–å…ˆåˆ é™¤æ‰€æœ‰ç°æœ‰çš„è‡ªå®šä¹‰è¯­éŸ³ï¼Œé¿å…è¾¾åˆ°é™åˆ¶
            print("æ­£åœ¨åˆ é™¤ç°æœ‰çš„è‡ªå®šä¹‰è¯­éŸ³...")
            delete_success = delete_all_custom_voices()
            if not delete_success:
                print("è­¦å‘Šï¼šåˆ é™¤ç°æœ‰è¯­éŸ³å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•åˆ›å»ºæ–°è¯­éŸ³")
            
            # åˆ›å»ºè¯­éŸ³å…‹éš†ç»“æœå­˜å‚¨
            voice_clones = []
            voice_mapping = {}
            
            # ä¸ºæ¯ä¸ªè¯´è¯äººåˆ›å»ºè¯­éŸ³å…‹éš†
            for speaker in speakers:
                try:
                    print(f"æ­£åœ¨ä¸ºè¯´è¯äºº '{speaker}' åˆ›å»ºè¯­éŸ³å…‹éš†...")
                    
                    # è·å–è¯¥è¯´è¯äººçš„æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
                    speaker_segments = [s for s in subtitles if s.get('speaker', '').strip() == speaker]
                    if not speaker_segments:
                        print(f"è¯´è¯äºº '{speaker}' æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘ç‰‡æ®µ")
                        continue
                    
                    # æå–è¯¥è¯´è¯äººçš„éŸ³é¢‘ç‰‡æ®µ
                    speaker_audio_path = extract_speaker_audio(task_dir, speaker, speaker_segments)
                    if not speaker_audio_path:
                        print(f"æ— æ³•æå–è¯´è¯äºº '{speaker}' çš„éŸ³é¢‘")
                        continue
                    
                    # è°ƒç”¨ElevenLabs instant clone API
                    clone_result = create_voice_clone(speaker, speaker_audio_path)
                    if clone_result:
                        voice_clone_info = {
                            "speaker": speaker,
                            "voice_id": clone_result.get('voice_id'),
                            "voice_name": clone_result.get('name'),
                            "audio_segments_count": len(speaker_segments),
                            "audio_file": str(speaker_audio_path)
                        }
                        voice_clones.append(voice_clone_info)
                        voice_mapping[speaker] = clone_result.get('voice_id')
                        print(f"è¯´è¯äºº '{speaker}' è¯­éŸ³å…‹éš†æˆåŠŸï¼Œvoice_id: {clone_result.get('voice_id')}")
                    else:
                        print(f"è¯´è¯äºº '{speaker}' è¯­éŸ³å…‹éš†å¤±è´¥")
                        
                except Exception as e:
                    print(f"ä¸ºè¯´è¯äºº '{speaker}' åˆ›å»ºè¯­éŸ³å…‹éš†æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            # ä¿å­˜è¯­éŸ³å…‹éš†æ˜ å°„å…³ç³»
            if voice_mapping:
                mapping_file = task_dir / f"{task_id}_voice_mapping.json"
                mapping_data = {
                    "task_id": task_id,
                    "voice_mapping": voice_mapping,
                    "voice_clones": voice_clones,
                    "created_at": datetime.now().isoformat()
                }
                with open(mapping_file, 'w', encoding='utf-8') as f:
                    json.dump(mapping_data, f, ensure_ascii=False, indent=2)
                print(f"è¯­éŸ³å…‹éš†æ˜ å°„å…³ç³»å·²ä¿å­˜: {mapping_file}")
            
            return jsonify({
                "code": 0,
                "msg": f"è¯­éŸ³å…‹éš†å®Œæˆï¼ŒæˆåŠŸä¸º {len(voice_clones)} ä¸ªè¯´è¯äººåˆ›å»ºäº†è¯­éŸ³å…‹éš†",
                "voice_clones": voice_clones,
                "voice_mapping": voice_mapping
            })
            
        except Exception as e:
            print(f"è¯­éŸ³å…‹éš†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return jsonify({"code": 1, "msg": f"è¯­éŸ³å…‹éš†å¤±è´¥: {str(e)}"}), 500

    def extract_speaker_audio(task_dir, speaker, speaker_segments):
        """æå–æŒ‡å®šè¯´è¯äººçš„éŸ³é¢‘ç‰‡æ®µ - æ–°æµç¨‹ï¼šå…ˆåˆ‡åˆ†å†Demucs"""
        try:
            from videotrans.util import tools
            
            # åˆ›å»ºè¯´è¯äººéŸ³é¢‘ç›®å½•
            speaker_dir = task_dir / "speaker_audio"
            speaker_dir.mkdir(exist_ok=True)
            
            # è·å–è§†é¢‘æ–‡ä»¶è·¯å¾„
            video_files = list(task_dir.glob("*.mp4")) + list(task_dir.glob("*.avi")) + list(task_dir.glob("*.mov"))
            if not video_files:
                print("æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
                return None
            
            video_path = video_files[0]
            print(f"ä½¿ç”¨è§†é¢‘æ–‡ä»¶: {video_path}")
            
            # ç¬¬ä¸€æ­¥ï¼šæ ¹æ®SRTæ—¶é—´å’Œè¯´è¯äººåˆ‡åˆ†éŸ³é¢‘ï¼Œç”Ÿæˆ _spk[i] æ–‡ä»¶
            speaker_audio_path = speaker_dir / f"spk{speaker.replace('spk', '')}.wav"
            if not speaker_audio_path.exists():
                print(f"æ­£åœ¨åˆ‡åˆ†è¯´è¯äºº '{speaker}' çš„éŸ³é¢‘ç‰‡æ®µ...")
                print(f"è¯´è¯äººç‰‡æ®µæ•°é‡: {len(speaker_segments)}")
                if speaker_segments:
                    print(f"ç¬¬ä¸€ä¸ªç‰‡æ®µç¤ºä¾‹: {speaker_segments[0]}")
                
                # åˆå¹¶è¯¥è¯´è¯äººçš„æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
                segment_files = []
                for i, segment in enumerate(speaker_segments):
                    # æ”¯æŒå¤šç§å­—æ®µåæ ¼å¼
                    start_time = (segment.get('start_time', segment.get('start', 0))) / 1000  # è½¬æ¢ä¸ºç§’
                    end_time = (segment.get('end_time', segment.get('end', 0))) / 1000
                    duration = end_time - start_time
                    
                    print(f"ç‰‡æ®µ {i}: start={start_time}s, end={end_time}s, duration={duration}s")
                    
                    if duration > 0:
                        segment_file = speaker_dir / f"{speaker}_segment_{i}.wav"
                        tools.runffmpeg([
                            '-y', '-i', str(video_path),
                            '-ss', str(start_time), '-t', str(duration),
                            '-vn', '-acodec', 'pcm_s16le', '-ar', '44100', '-ac', '2',
                            str(segment_file)
                        ])
                        segment_files.append(str(segment_file))
                
                # åˆå¹¶æ‰€æœ‰ç‰‡æ®µä¸º _spk[i] æ–‡ä»¶
                if segment_files:
                    concat_file = speaker_dir / f"{speaker}_concat.txt"
                    with open(concat_file, 'w') as f:
                        for seg_file in segment_files:
                            f.write(f"file '{seg_file}'\n")
                    
                    tools.runffmpeg([
                        '-y', '-f', 'concat', '-safe', '0', '-i', str(concat_file),
                        '-acodec', 'pcm_s16le', '-ar', '44100', '-ac', '2',
                        str(speaker_audio_path)
                    ])
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    for seg_file in segment_files:
                        Path(seg_file).unlink(missing_ok=True)
                    concat_file.unlink(missing_ok=True)
                    
                    print(f"è¯´è¯äºº '{speaker}' éŸ³é¢‘åˆ‡åˆ†å®Œæˆ: {speaker_audio_path}")
                else:
                    print(f"è¯´è¯äºº '{speaker}' æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘ç‰‡æ®µ")
                    return None
            
            # ç¬¬äºŒæ­¥ï¼šå¯¹ _spk[i] æ–‡ä»¶ç”¨Demucså»èƒŒæ™¯éŸ³ï¼Œç”Ÿæˆ _vocal_spk[i] æ–‡ä»¶
            vocal_audio_path = speaker_dir / f"vocal_spk{speaker.replace('spk', '')}.wav"
            if not vocal_audio_path.exists():
                print(f"æ­£åœ¨ä½¿ç”¨Demucsåˆ†ç¦»äººå£°: {vocal_audio_path}")
                
                # ä½¿ç”¨Demucsåˆ†ç¦»äººå£°
                success = separate_voice_background_demucs(str(speaker_audio_path), str(speaker_dir))
                
                if success:
                    # Demucsç”Ÿæˆçš„æ–‡ä»¶åæ˜¯background.wavå’Œvocal.wav
                    demucs_vocal_path = speaker_dir / "vocal.wav"
                    if demucs_vocal_path.exists():
                        # å¤åˆ¶åˆ°æˆ‘ä»¬æœŸæœ›çš„æ–‡ä»¶å _vocal_spk[i]
                        import shutil
                        shutil.copy2(demucs_vocal_path, vocal_audio_path)
                        print(f"Demucsäººå£°åˆ†ç¦»æˆåŠŸ: {vocal_audio_path}")
                    else:
                        print("Demucsäººå£°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘")
                        import shutil
                        shutil.copy2(speaker_audio_path, vocal_audio_path)
                else:
                    print("Demucsåˆ†ç¦»å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘")
                    import shutil
                    shutil.copy2(speaker_audio_path, vocal_audio_path)
            
            # è¿”å›vocalæ–‡ä»¶è·¯å¾„ç”¨äºå£°éŸ³å…‹éš†
            return vocal_audio_path if vocal_audio_path.exists() else None
            
        except Exception as e:
            print(f"æå–è¯´è¯äººéŸ³é¢‘å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def delete_all_custom_voices():
        """åˆ é™¤æ‰€æœ‰è‡ªå®šä¹‰è¯­éŸ³"""
        try:
            from elevenlabs import ElevenLabs
            import httpx
            
            # è·å–APIå¯†é’¥
            api_key = config.params.get('elevenlabstts_key')
            if not api_key:
                raise Exception("ElevenLabs APIå¯†é’¥æœªé…ç½®")
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            client = ElevenLabs(api_key=api_key, httpx_client=httpx.Client())
            
            # è·å–æ‰€æœ‰è¯­éŸ³
            voices = client.voices.get_all()
            custom_voices = [voice for voice in voices.voices if voice.category == 'cloned']
            
            print(f"æ‰¾åˆ° {len(custom_voices)} ä¸ªè‡ªå®šä¹‰è¯­éŸ³ï¼Œå¼€å§‹åˆ é™¤...")
            
            deleted_count = 0
            for voice in custom_voices:
                try:
                    client.voices.delete(voice.voice_id)
                    print(f"å·²åˆ é™¤è¯­éŸ³: {voice.name} (ID: {voice.voice_id})")
                    deleted_count += 1
                except Exception as e:
                    print(f"åˆ é™¤è¯­éŸ³å¤±è´¥ {voice.name}: {str(e)}")
            
            print(f"æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªè‡ªå®šä¹‰è¯­éŸ³")
            return True
            
        except Exception as e:
            print(f"åˆ é™¤è‡ªå®šä¹‰è¯­éŸ³å¤±è´¥: {str(e)}")
            return False

    def create_voice_clone(speaker, audio_path):
        """ä½¿ç”¨ElevenLabs instant clone APIåˆ›å»ºè¯­éŸ³å…‹éš†"""
        try:
            from elevenlabs import ElevenLabs
            import httpx
            from io import BytesIO
            
            # åˆ›å»ºElevenLabså®¢æˆ·ç«¯
            client = ElevenLabs(
                api_key=config.params['elevenlabstts_key'],
                httpx_client=httpx.Client()
            )
            
            # è¯»å–éŸ³é¢‘æ–‡ä»¶
            with open(audio_path, 'rb') as f:
                audio_data = f.read()
            
            # åˆ›å»ºè¯­éŸ³å…‹éš†
            voice_name = f"{speaker}_clone_{int(time.time())}"
            
            # ä½¿ç”¨instant voice cloning API
            voice = client.voices.ivc.create(
                name=voice_name,
                files=[BytesIO(audio_data)]
            )
            
            return {
                "voice_id": voice.voice_id,
                "name": voice_name,
                "speaker": speaker
            }
            
        except Exception as e:
            print(f"åˆ›å»ºè¯­éŸ³å…‹éš†å¤±è´¥: {str(e)}")
            return None

    @app.route('/viewer_api/<task_id>/check_generated_audio', methods=['GET'])
    def viewer_check_generated_audio(task_id):
        """æ£€æŸ¥æ˜¯å¦æœ‰å·²ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶"""
        try:
            # æ£€æŸ¥ä»»åŠ¡ç›®å½•
            task_dir = Path(TARGET_DIR) / task_id
            if not task_dir.exists():
                return jsonify({"code": 1, "msg": "ä»»åŠ¡ç›®å½•ä¸å­˜åœ¨", "has_audio": False})
            
            # æ£€æŸ¥éŸ³é¢‘ç›®å½•
            audio_dir = task_dir / "generated_audio"
            if not audio_dir.exists():
                return jsonify({"code": 0, "msg": "æ²¡æœ‰éŸ³é¢‘ç›®å½•", "has_audio": False})
            
            # æŸ¥æ‰¾éŸ³é¢‘æ–‡ä»¶
            audio_files = list(audio_dir.glob("segment_*.wav"))
            has_audio = len(audio_files) > 0
            
            return jsonify({
                "code": 0,
                "msg": "æ£€æŸ¥å®Œæˆ",
                "has_audio": has_audio,
                "audio_count": len(audio_files)
            })
            
        except Exception as e:
            return jsonify({"code": 1, "msg": f"æ£€æŸ¥å¤±è´¥: {str(e)}", "has_audio": False})

    @app.route('/viewer_api/<task_id>/check_voice_mapping', methods=['GET'])
    def viewer_check_voice_mapping(task_id):
        """æ£€æŸ¥è¯­éŸ³å…‹éš†æ˜ å°„æ˜¯å¦å­˜åœ¨"""
        try:
            task_dir = Path(TARGET_DIR) / task_id
            if not task_dir.exists():
                return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404
            
            mapping_file = task_dir / f"{task_id}_voice_mapping.json"
            has_mapping = mapping_file.exists()
            
            return jsonify({
                "code": 0,
                "has_mapping": has_mapping,
                "mapping_file": str(mapping_file) if has_mapping else None
            })
            
        except Exception as e:
            return jsonify({"code": 1, "msg": f"æ£€æŸ¥å¤±è´¥: {str(e)}"}), 500

    @app.route('/viewer_api/<task_id>/synthesize_audio', methods=['POST'])
    def viewer_synthesize_audio(task_id):
        """åˆæˆéŸ³é¢‘æ¥å£ - ç›´æ¥åˆæˆå·²ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶"""
        data = request.json
        if not data or 'subtitles' not in data:
            return jsonify({"code": 1, "msg": "ç¼ºå°‘å­—å¹•æ•°æ®"}), 400
        
        try:
            subtitles = data['subtitles']
            if not subtitles:
                return jsonify({"code": 1, "msg": "å­—å¹•æ•°æ®ä¸ºç©º"}), 400
            
            # æ£€æŸ¥ä»»åŠ¡ç›®å½•
            task_dir = Path(TARGET_DIR) / task_id
            if not task_dir.exists():
                return jsonify({"code": 1, "msg": "ä»»åŠ¡ç›®å½•ä¸å­˜åœ¨"}), 400
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·²ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
            audio_dir = task_dir / "generated_audio"
            if not audio_dir.exists():
                return jsonify({"code": 1, "msg": "æ²¡æœ‰æ‰¾åˆ°å·²ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶"}), 400
            
            # æŸ¥æ‰¾æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µæ–‡ä»¶
            audio_files = []
            print(f"æ¥æ”¶åˆ°çš„å­—å¹•æ•°æ®: {len(subtitles)} æ¡")
            print(f"ç¬¬ä¸€æ¡å­—å¹•æ•°æ®: {subtitles[0] if subtitles else 'None'}")
            
            for i, subtitle in enumerate(subtitles):
                # æ£€æŸ¥å¿…éœ€å­—æ®µï¼Œæ”¯æŒä¸¤ç§å­—æ®µå
                start_time = subtitle.get('start_time')
                if start_time is None:
                    start_time = subtitle.get('start')
                    
                end_time = subtitle.get('end_time')
                if end_time is None:
                    end_time = subtitle.get('end')
                
                if start_time is None or end_time is None:
                    print(f"è­¦å‘Šï¼šå­—å¹• {i+1} ç¼ºå°‘æ—¶é—´å­—æ®µ: {subtitle}")
                    continue
                    
                segment_file = audio_dir / f"segment_{i+1:04d}.wav"
                if segment_file.exists():
                    audio_files.append({
                        'start_time': start_time,
                        'end_time': end_time,
                        'file': str(segment_file)
                    })
                else:
                    print(f"è­¦å‘Šï¼šéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {segment_file}")
            
            if not audio_files:
                return jsonify({"code": 1, "msg": "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶"}), 400
            
            print(f"æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œå¼€å§‹åˆæˆ...")
            
            # è®¡ç®—æ€»æ—¶é•¿
            total_duration = max(segment['end_time'] for segment in audio_files)
            
            # åˆæˆå®Œæ•´éŸ³é¢‘
            final_audio_file = audio_dir / f"{task_id}_synthesized_audio.wav"
            success = synthesize_final_audio(audio_files, final_audio_file, total_duration)
            
            if not success:
                return jsonify({"code": 1, "msg": "éŸ³é¢‘åˆæˆå¤±è´¥"}), 500
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç”ŸæˆæˆåŠŸ
            if not final_audio_file.exists():
                return jsonify({"code": 1, "msg": "åˆæˆæ–‡ä»¶æœªç”Ÿæˆ"}), 500
            
            file_size = final_audio_file.stat().st_size
            print(f"éŸ³é¢‘åˆæˆæˆåŠŸ: {final_audio_file} (å¤§å°: {file_size / 1024:.1f} KB)")
            
            return jsonify({
                "code": 0,
                "msg": "éŸ³é¢‘åˆæˆæˆåŠŸ",
                "output_file": str(final_audio_file),
                "file_size": file_size,
                "segments_count": len(audio_files)
            })
            
        except Exception as e:
            print(f"åˆæˆéŸ³é¢‘å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return jsonify({"code": 1, "msg": f"åˆæˆéŸ³é¢‘å¤±è´¥: {str(e)}"}), 500

    @app.route('/viewer_api/<task_id>/generate_audio', methods=['POST'])
    def viewer_generate_audio(task_id):
        """ç”ŸæˆéŸ³é¢‘æ¥å£ - åŸºäºç¿»è¯‘å­—å¹•å’Œè¯­éŸ³å…‹éš†æ˜ å°„"""
        data = request.json
        if not data or 'subtitles' not in data:
            return jsonify({"code": 1, "msg": "ç¼ºå°‘å­—å¹•æ•°æ®"}), 400

        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        try:
            subtitles = data['subtitles']
            
            # æ£€æŸ¥è¯­éŸ³å…‹éš†æ˜ å°„æ–‡ä»¶
            mapping_file = task_dir / f"{task_id}_voice_mapping.json"
            if not mapping_file.exists():
                return jsonify({"code": 1, "msg": "æœªæ‰¾åˆ°è¯­éŸ³å…‹éš†æ˜ å°„æ–‡ä»¶ï¼Œè¯·å…ˆè¿›è¡Œè¯­éŸ³å…‹éš†"}), 400
            
            # è¯»å–è¯­éŸ³å…‹éš†æ˜ å°„
            with open(mapping_file, 'r', encoding='utf-8') as f:
                mapping_data = json.load(f)
            
            voice_mapping = mapping_data.get('voice_mapping', {})
            if not voice_mapping:
                return jsonify({"code": 1, "msg": "è¯­éŸ³å…‹éš†æ˜ å°„ä¸ºç©º"}), 400
            
            print(f"å¼€å§‹ç”ŸæˆéŸ³é¢‘ï¼Œå…± {len(subtitles)} æ¡å­—å¹•")
            print(f"è¯­éŸ³æ˜ å°„: {voice_mapping}")
            
            # åˆ›å»ºéŸ³é¢‘ç”Ÿæˆç›®å½•
            audio_dir = task_dir / "generated_audio"
            audio_dir.mkdir(exist_ok=True)
            
            # ä¸ºæ¯æ¡å­—å¹•ç”ŸæˆTTSéŸ³é¢‘
            generated_audio_files = []
            total_duration = 0
            
            for i, subtitle in enumerate(subtitles):
                try:
                    speaker = subtitle.get('speaker', '').strip()
                    translated_text = subtitle.get('translated_text', '').strip()
                    start_time = subtitle.get('start_time', 0)
                    end_time = subtitle.get('end_time', 0)
                    duration = end_time - start_time
                    
                    if not translated_text:
                        print(f"å­—å¹• {i+1} æ²¡æœ‰ç¿»è¯‘å†…å®¹ï¼Œè·³è¿‡")
                        continue
                    
                    if not speaker or speaker not in voice_mapping:
                        print(f"å­—å¹• {i+1} è¯´è¯äºº '{speaker}' æ²¡æœ‰å¯¹åº”çš„è¯­éŸ³å…‹éš†ï¼Œè·³è¿‡")
                        continue
                    
                    voice_id = voice_mapping[speaker]
                    print(f"ä¸ºå­—å¹• {i+1} ç”ŸæˆTTS: è¯´è¯äºº={speaker}, voice_id={voice_id}")
                    
                    # ç”ŸæˆTTSéŸ³é¢‘
                    audio_file = audio_dir / f"segment_{i+1:04d}.wav"
                    success = generate_tts_audio(translated_text, voice_id, audio_file)
                    
                    if success:
                        generated_audio_files.append({
                            "file": str(audio_file),
                            "start_time": start_time,
                            "end_time": end_time,
                            "duration": duration,
                            "speaker": speaker,
                            "text": translated_text
                        })
                        total_duration = max(total_duration, end_time)
                        print(f"å­—å¹• {i+1} TTSç”ŸæˆæˆåŠŸ: {audio_file}")
                    else:
                        print(f"å­—å¹• {i+1} TTSç”Ÿæˆå¤±è´¥")
                        
                except Exception as e:
                    print(f"å¤„ç†å­—å¹• {i+1} æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            if not generated_audio_files:
                return jsonify({"code": 1, "msg": "æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•éŸ³é¢‘ç‰‡æ®µ"}), 500
            
            # åˆæˆå®Œæ•´éŸ³é¢‘
            final_audio_file = audio_dir / f"{task_id}_final_audio.wav"
            success = synthesize_final_audio(generated_audio_files, final_audio_file, total_duration, regen_opts={"voice_mapping": voice_mapping})
            
            if not success:
                return jsonify({"code": 1, "msg": "éŸ³é¢‘åˆæˆå¤±è´¥"}), 500
            
            print(f"éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {final_audio_file}")
            print(f"æ€»æ—¶é•¿: {total_duration/1000:.2f}ç§’")
            
            return jsonify({
                "code": 0,
                "msg": f"éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(generated_audio_files)} ä¸ªéŸ³é¢‘ç‰‡æ®µ",
                "audio_file": str(final_audio_file),
                "duration": f"{total_duration/1000:.2f}ç§’",
                "segments_count": len(generated_audio_files),
                "generated_segments": generated_audio_files
            })
            
        except Exception as e:
            print(f"ç”ŸæˆéŸ³é¢‘å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return jsonify({"code": 1, "msg": f"ç”ŸæˆéŸ³é¢‘å¤±è´¥: {str(e)}"}), 500

    @app.route('/viewer_api/<task_id>/add_subtitles', methods=['POST'])
    def viewer_add_subtitles(task_id):
        """ä¸ºæŒ‡å®šè§†é¢‘çƒ§å½•å­—å¹•ï¼ˆASSï¼‰ï¼Œæ”¯æŒå­—ä½“å¤§å°ä¸åº•éƒ¨è·ç¦»ç™¾åˆ†æ¯”è®¾ç½®ã€‚

        è¯·æ±‚ä½“: {
            video_url: string ç›®æ ‡è§†é¢‘URLï¼ˆåŸè§†é¢‘æˆ–å½“å‰æ’­æ”¾çš„è§†é¢‘ï¼‰
            font_size: int å­—ä½“å¤§å°ï¼ˆåƒç´ ï¼‰
            bottom_percent: int è·ç¦»åº•éƒ¨ç™¾åˆ†æ¯”ï¼ˆ0-40ï¼‰
            subtitles: [{start_time:int(ms), end_time:int(ms), text:str}, ...]
        }
        è¿”å›: {code:0, output_url:string}
        """
        try:
            data = request.get_json(silent=True) or {}
            video_url = data.get('video_url', '')
            font_size = int(data.get('font_size', 72))
            bottom_percent = max(0, min(40, int(data.get('bottom_percent', 20))))
            items = data.get('subtitles', [])
            subtitle_file_url = (data.get('subtitle_file') or '').strip()

            if not video_url:
                return jsonify({"code": 1, "msg": "ç¼ºå°‘ video_url"}), 400
            if not subtitle_file_url and (not isinstance(items, list) or len(items) < 1):
                return jsonify({"code": 1, "msg": "ç¼ºå°‘å­—å¹•æ•°æ®"}), 400

            # å°† video_url æ˜ å°„åˆ°æœ¬åœ°è·¯å¾„
            # å…è®¸ full url æˆ– '/apidata/...'
            src_path = None
            try:
                # æˆªå– '/apidata/' ä¹‹åçš„ç›¸å¯¹è·¯å¾„
                marker = f'/{API_RESOURCE}/'
                if marker in video_url:
                    rel = video_url.split(marker, 1)[1]
                    src_path = Path(TARGET_DIR) / rel
                else:
                    # å°è¯•å½“ä½œç›¸å¯¹è·¯å¾„
                    if video_url.startswith('/'):
                        src_path = Path(TARGET_DIR) / video_url.lstrip('/').split(f'{API_RESOURCE}/')[-1]
                    else:
                        src_path = Path(video_url)
            except Exception:
                pass

            if not src_path or not src_path.exists():
                return jsonify({"code": 1, "msg": "ç›®æ ‡è§†é¢‘ä¸å­˜åœ¨æˆ–ä¸å¯è®¿é—®"}), 400

            # æ¢æµ‹åˆ†è¾¨ç‡
            import subprocess
            probe = subprocess.run([
                'ffprobe', '-v', 'error', '-select_streams', 'v:0', '-show_entries', 'stream=width,height',
                '-of', 'csv=s=x:p=0', str(src_path)
            ], capture_output=True, text=True)
            if probe.returncode != 0 or 'x' not in probe.stdout:
                return jsonify({"code": 1, "msg": "æ— æ³•æ¢æµ‹è§†é¢‘åˆ†è¾¨ç‡"}), 500
            w, h = [int(x) for x in probe.stdout.strip().split('x')]

            # è¾“å‡ºæ–‡ä»¶ï¼ˆå†™å…¥å½“å‰ä»»åŠ¡ç›®å½•ï¼‰
            out_path = Path(TARGET_DIR) / task_id / f"subtitled_{int(time.time())}.mp4"
            from videotrans.util import tools
            margin_lr = int(w * 0.1)  # å·¦å³å„10%ï¼Œæ€»80%æœ‰æ•ˆå®½åº¦
            margin_v = int(h * (bottom_percent / 100.0))

            if subtitle_file_url:
                # ä½¿ç”¨å·²æœ‰å­—å¹•æ–‡ä»¶ã€‚å¦‚æœæ˜¯ .ass ç›´æ¥çƒ§å½•ï¼›å¦‚æœæ˜¯ .srt/.vttï¼Œåˆ™å…ˆè½¬æ¢ä¸º ASSï¼ˆåº”ç”¨æ ·å¼ï¼‰ï¼Œå†çƒ§å½•ã€‚
                marker = f'/{API_RESOURCE}/'
                if marker in subtitle_file_url:
                    rel = subtitle_file_url.split(marker, 1)[1]
                    sub_src = Path(TARGET_DIR) / rel
                else:
                    sub_src = Path(subtitle_file_url)
                if not sub_src.exists():
                    return jsonify({"code": 1, "msg": "å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨"}), 400

                if sub_src.suffix.lower() == '.ass':
                    # å¼ºåˆ¶æ ·å¼ä»¥å®ç° 80% å®½åº¦ä¸å±…ä¸­ã€è‡ªåŠ¨æ¢è¡Œ
                    force_style = f"WrapStyle=2,Alignment=2,MarginL={margin_lr},MarginR={margin_lr},MarginV={margin_v}"
                    vf = f"subtitles=filename={sub_src.as_posix()}:force_style='{force_style}'"
                    cmd = ['-y', '-i', str(src_path), '-vf', vf, '-loglevel', 'info', '-c:v', 'libx264', '-preset', 'fast', '-crf', '18', '-c:a', 'copy', str(out_path)]
                    print("[AddSubtitles] FFmpeg command:", 'ffmpeg', *cmd)
                    try:
                        from videotrans.util import tools as _t
                        _t.set_process(text=f"FFmpeg: ffmpeg {' '.join(cmd)}", uuid=task_id)
                    except Exception:
                        pass
                    tools.runffmpeg(cmd)
                else:
                    # è§£æ SRT/VTT -> itemsï¼Œç„¶åèµ°ç»Ÿä¸€çš„ ASS ç”Ÿæˆé€»è¾‘
                    try:
                        items = parse_srt_file_to_items(sub_src)
                    except Exception:
                        items = []
                    if not items:
                        return jsonify({"code": 1, "msg": "æ— æ³•è§£æå­—å¹•æ–‡ä»¶"}), 400
                    # ä¸‹é¢ä¸æ— æ–‡ä»¶åˆ†æ”¯ç›¸åŒï¼šæ ¹æ® items ç”Ÿæˆ ASSï¼Œå¹¶èµ° FFmpeg çƒ§å½•
                    ass_path = Path(TARGET_DIR) / task_id / f"subtitles_{int(time.time())}.ass"
                    ass_path.parent.mkdir(parents=True, exist_ok=True)
                    def fmt_time(ms: int) -> str:
                        ms = max(0, int(ms))
                        cs = int((ms % 1000) / 10)
                        s = ms // 1000
                        hh = s // 3600
                        mm = (s % 3600) // 60
                        ss = s % 60
                        return f"{hh}:{mm:02d}:{ss:02d}.{cs:02d}"
                    def wrap_text_for_ass(t: str, max_chars: int) -> str:
                        """æŒ‰æœ€å¤§å­—ç¬¦æ•°ç²—ç•¥æ¢è¡Œï¼Œå°½é‡æŒ‰ç©ºæ ¼æ–­è¡Œï¼›æ— ç©ºæ ¼åˆ™æŒ‰å­—ç¬¦æ•°æ–­è¡Œã€‚"""
                        t = (t or '').replace('\r', '')
                        lines = []
                        for raw_line in t.split('\n'):
                            s = raw_line.strip()
                            if not s:
                                lines.append('')
                                continue
                            words = s.split(' ')
                            if len(words) > 1:
                                cur = ''
                                for w2 in words:
                                    if cur == '':
                                        nxt = w2
                                    else:
                                        nxt = cur + ' ' + w2
                                    if len(nxt) <= max_chars:
                                        cur = nxt
                                    else:
                                        if cur:
                                            lines.append(cur)
                                        cur = w2
                                if cur:
                                    lines.append(cur)
                            else:
                                # æ— ç©ºæ ¼ï¼ŒæŒ‰å­—ç¬¦æ•°ç¡¬åˆ‡
                                s2 = s
                                while len(s2) > max_chars:
                                    lines.append(s2[:max_chars])
                                    s2 = s2[max_chars:]
                                if s2:
                                    lines.append(s2)
                        return '\\N'.join(lines)

                    def esc_text(t: str) -> str:
                        # å…ˆæ¢è¡Œï¼Œå†åšè½¬ä¹‰ï¼›ä¿ç•™ \N ä½œä¸ºæ¢è¡Œ
                        t2 = t or ''
                        max_text_width = int(w * 0.8)
                        est_char_w = max(1, int(font_size * 0.6))
                        max_chars = max(8, int(max_text_width / est_char_w))
                        t2 = wrap_text_for_ass(t2, max_chars)
                        placeholder = '<<__ASS_NL__>>'
                        t2 = t2.replace('\\N', placeholder)
                        t2 = t2.replace('\\', '\\\\').replace('{', '(').replace('}', ')')
                        t2 = t2.replace(placeholder, '\\N')
                        return t2
                    ass_lines = []
                    ass_lines.append('[Script Info]')
                    ass_lines.append('ScriptType: v4.00+')
                    ass_lines.append(f'PlayResX: {w}')
                    ass_lines.append(f'PlayResY: {h}')
                    ass_lines.append('WrapStyle: 2')
                    ass_lines.append('ScaledBorderAndShadow: yes')
                    ass_lines.append('')
                    ass_lines.append('[V4+ Styles]')
                    ass_lines.append('Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, '
                                      'Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, '
                                      'Shadow, Alignment, MarginL, MarginR, MarginV, Encoding')
                    ass_lines.append(
                        f"Style: Default,Arial,{font_size},&H00FFFFFF,&H000000FF,&H00000000,&H64000000,-1,0,0,0,100,100,0,0,1,3,0,2,{margin_lr},{margin_lr},{margin_v},0"
                    )
                    ass_lines.append('')
                    ass_lines.append('[Events]')
                    ass_lines.append('Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text')
                    for it in items:
                        st = fmt_time(int(it.get('start_time', 0)))
                        et = fmt_time(int(it.get('end_time', 0)))
                        txt = esc_text(str(it.get('text', '')))
                        ass_lines.append(f"Dialogue: 0,{st},{et},Default,,0000,0000,0000,,{txt}")
                    ass_path.write_text('\n'.join(ass_lines), encoding='utf-8')
                    vf = f"subtitles=filename={ass_path.as_posix()}"
                    cmd = ['-y', '-i', str(src_path), '-vf', vf, '-loglevel', 'info', '-c:v', 'libx264', '-preset', 'fast', '-crf', '18', '-c:a', 'copy', str(out_path)]
                    print("[AddSubtitles] FFmpeg command:", 'ffmpeg', *cmd)
                    try:
                        from videotrans.util import tools as _t
                        _t.set_process(text=f"FFmpeg: ffmpeg {' '.join(cmd)}", uuid=task_id)
                    except Exception:
                        pass
                    tools.runffmpeg(cmd)
            else:
                # ç”Ÿæˆ ASS æ–‡ä»¶åçƒ§å½•
                ass_path = Path(TARGET_DIR) / task_id / f"subtitles_{int(time.time())}.ass"
                ass_path.parent.mkdir(parents=True, exist_ok=True)

                def fmt_time(ms: int) -> str:
                    ms = max(0, int(ms))
                    cs = int((ms % 1000) / 10)  # centiseconds
                    s = ms // 1000
                    hh = s // 3600
                    mm = (s % 3600) // 60
                    ss = s % 60
                    return f"{hh}:{mm:02d}:{ss:02d}.{cs:02d}"

                def wrap_text_for_ass(t: str, max_chars: int) -> str:
                    t = (t or '').replace('\r', '')
                    lines = []
                    for raw_line in t.split('\n'):
                        s = raw_line.strip()
                        if not s:
                            lines.append('')
                            continue
                        words = s.split(' ')
                        if len(words) > 1:
                            cur = ''
                            for w2 in words:
                                if cur == '':
                                    nxt = w2
                                else:
                                    nxt = cur + ' ' + w2
                                if len(nxt) <= max_chars:
                                    cur = nxt
                                else:
                                    if cur:
                                        lines.append(cur)
                                    cur = w2
                            if cur:
                                lines.append(cur)
                        else:
                            s2 = s
                            while len(s2) > max_chars:
                                lines.append(s2[:max_chars])
                                s2 = s2[max_chars:]
                            if s2:
                                lines.append(s2)
                    return '\\N'.join(lines)

                def esc_text(t: str) -> str:
                    # é¢„æ¢è¡Œå†è½¬ä¹‰ï¼›ä¿ç•™ \N ä½œä¸ºæ¢è¡Œ
                    max_text_width = int(w * 0.8)
                    est_char_w = max(1, int(font_size * 0.6))
                    max_chars = max(8, int(max_text_width / est_char_w))
                    t2 = wrap_text_for_ass(t or '', max_chars)
                    placeholder = '<<__ASS_NL__>>'
                    t2 = t2.replace('\\N', placeholder)
                    t2 = t2.replace('\\', '\\\\').replace('{', '(').replace('}', ')')
                    t2 = t2.replace(placeholder, '\\N')
                    return t2

                ass_lines = []
                ass_lines.append('[Script Info]')
                ass_lines.append('ScriptType: v4.00+')
                ass_lines.append(f'PlayResX: {w}')
                ass_lines.append(f'PlayResY: {h}')
                ass_lines.append('WrapStyle: 2')
                ass_lines.append('ScaledBorderAndShadow: yes')
                ass_lines.append('')
                ass_lines.append('[V4+ Styles]')
                ass_lines.append('Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, '
                                  'Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, '
                                  'Shadow, Alignment, MarginL, MarginR, MarginV, Encoding')
                ass_lines.append(
                    f"Style: Default,Arial,{font_size},&H00FFFFFF,&H000000FF,&H00000000,&H64000000,-1,0,0,0,100,100,0,0,1,3,0,2,{margin_lr},{margin_lr},{margin_v},0"
                )
                ass_lines.append('')
                ass_lines.append('[Events]')
                ass_lines.append('Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text')
                for it in items:
                    st = fmt_time(int(it.get('start_time', 0)))
                    et = fmt_time(int(it.get('end_time', 0)))
                    txt = esc_text(str(it.get('text', '')))
                    ass_lines.append(f"Dialogue: 0,{st},{et},Default,,0000,0000,0000,,{txt}")

                ass_path.write_text('\n'.join(ass_lines), encoding='utf-8')

                vf = f"subtitles=filename={ass_path.as_posix()}"
                cmd = ['-y', '-i', str(src_path), '-vf', vf, '-loglevel', 'info', '-c:v', 'libx264', '-preset', 'fast', '-crf', '18', '-c:a', 'copy', str(out_path)]
                # æ‰“å°ä¸è®°å½• FFmpeg å‘½ä»¤ï¼Œä¾¿äºæ’æŸ¥
                print("[AddSubtitles] FFmpeg command:", 'ffmpeg', *cmd)
                try:
                    from videotrans.util import tools as _t
                    _t.set_process(text=f"FFmpeg: ffmpeg {' '.join(cmd)}", uuid=task_id)
                except Exception:
                    pass
                try:
                    tools.runffmpeg(cmd)
                except Exception:
                    print('[AddSubtitles] FFmpeg failed. Fallback to OpenCV burn (items).')
                    ok3 = burn_subtitles_with_opencv(
                        str(src_path), items, str(out_path),
                        font_size=font_size, bottom_percent=bottom_percent
                    )
                    if not ok3:
                        raise

            if not out_path.exists():
                return jsonify({"code": 1, "msg": "å­—å¹•çƒ§å½•å¤±è´¥"}), 500

            return jsonify({
                "code": 0,
                "msg": "ok",
                "output_url": f'/{API_RESOURCE}/{task_id}/{out_path.name}'
            })

        except Exception as e:
            print(f"æ·»åŠ å­—å¹•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return jsonify({"code": 1, "msg": f"æ·»åŠ å­—å¹•å¤±è´¥: {str(e)}"}), 500

    @app.route('/viewer_api/<task_id>/list_subtitle_files', methods=['GET'])
    def viewer_list_subtitle_files(task_id):
        """åˆ—å‡ºä»»åŠ¡ç›®å½•ä¸‹å¯ç”¨çš„å­—å¹•æ–‡ä»¶ï¼ˆsrt/ass/vtt/jsonï¼‰ã€‚"""
        try:
            task_dir = Path(TARGET_DIR) / task_id
            if not task_dir.exists():
                return jsonify({"code": 1, "msg": "ä»»åŠ¡ä¸å­˜åœ¨", "files": []}), 404

            exts = {'.srt', '.ass', '.vtt', '.json'}
            files = []
            for f in sorted(task_dir.iterdir()):
                if f.is_file() and f.suffix.lower() in exts:
                    files.append({
                        'name': f.name,
                        'url': f'/{API_RESOURCE}/{task_id}/{f.name}'
                    })
            return jsonify({"code": 0, "files": files})
        except Exception as e:
            return jsonify({"code": 1, "msg": f"åˆ—å‡ºå¤±è´¥: {str(e)}", "files": []}), 500

    def parse_srt_file_to_items(srt_path):
        """å°† SRT æ–‡ä»¶è§£æä¸º items åˆ—è¡¨: [{start_time,end_time,text}]"""
        try:
            content = Path(srt_path).read_text(encoding='utf-8')
        except Exception:
            content = Path(srt_path).read_text(encoding='latin-1')

        import re
        blocks = re.split(r'\n\s*\n', content.strip())
        items = []
        def t2ms(t):
            # 00:00:00,000 æˆ– 00:00:00.000
            t = t.replace('.', ',')
            h, m, s_ms = t.split(':')
            s, ms = s_ms.split(',')
            return (int(h)*3600 + int(m)*60 + int(s))*1000 + int(ms)
        for b in blocks:
            lines = [ln for ln in b.splitlines() if ln.strip()]
            if len(lines) < 2:
                continue
            # æ‰¾åˆ°æ—¶é—´è¡Œ
            time_idx = None
            for i, ln in enumerate(lines[:3]):
                if '-->' in ln:
                    time_idx = i
                    break
            if time_idx is None:
                continue
            time_line = lines[time_idx]
            text_lines = lines[time_idx+1:]
            l, r = [t.strip() for t in time_line.split('-->')]
            st = t2ms(l)
            et = t2ms(r)
            text = '\n'.join(text_lines)
            items.append({'start_time': st, 'end_time': et, 'text': text})
        return items

    def _find_font_path_candidates():
        return [
            '/System/Library/Fonts/Supplemental/Arial.ttf',
            '/System/Library/Fonts/Supplemental/Arial Unicode.ttf',
            '/Library/Fonts/Arial.ttf',
            '/Library/Fonts/Arial Unicode.ttf',
            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',
            'C:/Windows/Fonts/arial.ttf',
        ]

    def burn_subtitles_with_opencv(video_path, items, output_path, font_size=72, bottom_percent=20, width_ratio=0.8):
        """ä½¿ç”¨ OpenCV+Pillow å°†ç»™å®šå­—å¹•äº‹ä»¶çƒ§å½•åˆ°è§†é¢‘ã€‚

        items: list of {start_time(ms), end_time(ms), text}
        è¾“å‡ºå…ˆç”Ÿæˆæ— éŸ³é¢‘è§†é¢‘ï¼Œå†ç”¨ ffmpeg å°†åŸè§†é¢‘éŸ³é¢‘å¤ç”¨åˆ°è¾“å‡ºã€‚
        """
        try:
            import cv2
            import numpy as np
            from PIL import Image, ImageDraw, ImageFont
        except Exception as e:
            print(f'ç¼ºå°‘ä¾èµ–: {e}. éœ€è¦å®‰è£… opencv-python ä¸ pillow')
            return False

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print('æ— æ³•æ‰“å¼€è§†é¢‘:', video_path)
            return False

        fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        out_noaudio = Path(output_path).with_suffix('.noaudio.mp4')
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        writer = cv2.VideoWriter(out_noaudio.as_posix(), fourcc, fps, (width, height))
        if not writer.isOpened():
            print('æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘:', out_noaudio)
            cap.release()
            return False

        # å­—ä½“
        font_path = None
        for p in _find_font_path_candidates():
            if Path(p).exists():
                font_path = p
                break
        try:
            font = ImageFont.truetype(font_path or 'Arial', max(12, int(font_size)))
        except Exception:
            font = ImageFont.load_default()

        max_text_width = int(width * width_ratio)
        margin_v = int(height * (bottom_percent / 100.0))

        def wrap_text(txt, draw):
            # æŒ‰å®½åº¦æ¢è¡Œï¼ˆé€å­—ç¬¦ï¼Œå…¼å®¹ä¸­è¥¿æ–‡ï¼‰
            parts = txt.replace('\r', '').split('\n')
            lines = []
            for block in parts:
                line = ''
                for ch in block:
                    test = line + ch
                    w, _ = draw.textsize(test, font=font)
                    if w <= max_text_width:
                        line = test
                    else:
                        if line:
                            lines.append(line)
                        line = ch
                if line:
                    lines.append(line)
            return lines

        items_sorted = sorted(items, key=lambda x: x.get('start_time', 0))
        idx = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            cur_ms = int(idx * 1000.0 / fps)

            # å½“å‰å­—å¹•
            txt = ''
            for it in items_sorted:
                if it.get('start_time', 0) <= cur_ms < it.get('end_time', 0):
                    txt = it.get('text', '')
                if it.get('start_time', 0) > cur_ms:
                    break

            if txt:
                img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                draw = ImageDraw.Draw(img)
                lines = wrap_text(txt, draw)
                # æ–‡æœ¬å—é«˜åº¦ä¼°è®¡
                bbox = font.getbbox('Hg')
                lh = bbox[3] - bbox[1]
                total_h = int(len(lines) * lh * 1.2)
                y0 = height - margin_v - total_h
                for i2, line in enumerate(lines):
                    w_text, _ = draw.textsize(line, font=font)
                    x = int((width - w_text) / 2)
                    y = int(y0 + i2 * lh * 1.2)
                    draw.text((x, y), line, font=font, fill=(255,255,255,255), stroke_width=3, stroke_fill=(0,0,0,255))
                frame = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)

            writer.write(frame)
            idx += 1

        writer.release()
        cap.release()

        # å¤ç”¨åŸè§†é¢‘éŸ³é¢‘
        try:
            from videotrans.util import tools as _t
            mux_cmd = [
                '-y', '-i', out_noaudio.as_posix(), '-i', video_path,
                '-c:v', 'copy', '-map', '0:v:0', '-map', '1:a:0?', '-c:a', 'aac', '-b:a', '128k', '-shortest', output_path
            ]
            print('[AddSubtitles][OpenCV] FFmpeg mux audio:', 'ffmpeg', *mux_cmd)
            _t.runffmpeg(mux_cmd)
        except Exception as e:
            print('[AddSubtitles][OpenCV] å¤ç”¨éŸ³é¢‘å¤±è´¥:', e)
            try:
                Path(output_path).unlink(missing_ok=True)
            except Exception:
                pass
            out_noaudio.replace(output_path)

        try:
            out_noaudio.unlink(missing_ok=True)
        except Exception:
            pass
        return Path(output_path).exists()

    def generate_tts_audio(text, voice_id, output_file, speaking_rate=None):
        """ä½¿ç”¨ElevenLabsç”ŸæˆTTSéŸ³é¢‘ï¼Œæ”¯æŒå¯é€‰è¯­é€Ÿspeaking_rateï¼ˆå€ç‡ï¼‰ã€‚"""
        try:
            from elevenlabs import ElevenLabs
            import httpx
            
            # åˆ›å»ºElevenLabså®¢æˆ·ç«¯
            client = ElevenLabs(
                api_key=config.params['elevenlabstts_key'],
                httpx_client=httpx.Client()
            )
            
            kwargs = {
                'voice_id': voice_id,
                'text': text,
                'model_id': "eleven_flash_v2_5"
            }
            # å°è¯•ä¼ å…¥è¯­é€Ÿè®¾ç½®ï¼ˆè‹¥SDK/æ¨¡å‹ä¸æ”¯æŒåˆ™ä¼šè¢«å¿½ç•¥æˆ–æŠ›é”™ï¼‰
            if speaking_rate and speaking_rate > 0:
                try:
                    kwargs['voice_settings'] = {"speaking_rate": float(speaking_rate)}
                except Exception:
                    pass
            
            # ç”ŸæˆTTSéŸ³é¢‘
            audio = client.text_to_speech.convert(**kwargs)
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            with open(output_file, 'wb') as f:
                for chunk in audio:
                    f.write(chunk)
            
            return True
            
        except Exception as e:
            print(f"TTSç”Ÿæˆå¤±è´¥: {str(e)}")
            return False

    def adjust_audio_length_and_volume(audio_file, target_duration_ms, volume_boost=1.8):
        """è°ƒæ•´éŸ³é¢‘é•¿åº¦ä¸éŸ³é‡ï¼Œå¹¶å¼ºåˆ¶åŒ¹é…SRTç›®æ ‡æ—¶é•¿ã€‚

        - è‡ªåŠ¨è®¡ç®—å˜é€Ÿæ¯”å¹¶ç”¨ atempo è°ƒæ•´ï¼ˆæ”¯æŒçº§è” atempo ä»¥è¶…å‡º 0.5~2.0 èŒƒå›´ï¼‰ã€‚
        - æå‡éŸ³é‡ï¼ˆé»˜è®¤ 1.8ï¼‰ã€‚
        - é€šè¿‡ apad + -t ç²¾ç¡®ä¿®å‰ª/è¡¥é½è‡³ç›®æ ‡æ—¶é•¿ã€‚
        """
        try:
            from videotrans.util import tools
            from pathlib import Path as _Path
            import subprocess

            audio_path = _Path(audio_file)
            temp1 = audio_path.parent / f"temp_speedvol_{audio_path.name}"
            temp2 = audio_path.parent / f"temp_exact_{audio_path.name}"

            # è·å–åŸå§‹éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
            probe = subprocess.run([
                'ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
                '-of', 'csv=p=0', str(audio_path)
            ], capture_output=True, text=True)
            if probe.returncode != 0 or not probe.stdout.strip():
                print(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿: {audio_path}")
                return audio_path

            original_duration = float(probe.stdout.strip())
            target_duration = max(0.01, float(target_duration_ms) / 1000.0)
            print(f"åŸå§‹æ—¶é•¿: {original_duration:.3f}s, ç›®æ ‡æ—¶é•¿: {target_duration:.3f}s")

            # è®¡ç®—é€Ÿåº¦è°ƒæ•´æ¯”ä¾‹ï¼š>1 åŠ é€Ÿï¼ˆç¼©çŸ­ï¼‰ï¼Œ<1 å‡é€Ÿï¼ˆæ‹‰é•¿ï¼‰ã€‚é™åˆ¶åœ¨ Â±20% å†…æ›´è‡ªç„¶
            raw_ratio = original_duration / target_duration if target_duration > 0 else 1.0
            speed_ratio = max(0.8, min(1.2, raw_ratio))

            # æ„å»º atempo çº§è”é“¾ï¼Œä¿è¯æ¯æ®µå¤„äº [0.5, 2.0]
            def build_atempo_chain(ratio: float) -> str:
                chain = []
                r = ratio
                # å¤„ç†æç«¯å€¼ï¼Œåˆ†æ®µé€¼è¿‘
                while r > 2.0:
                    chain.append('atempo=2.0')
                    r /= 2.0
                while r < 0.5:
                    chain.append('atempo=0.5')
                    r /= 0.5
                # æœ€åä¸€æ®µï¼ˆå¤„äº0.5~2.0ï¼‰
                chain.append(f'atempo={r:.5f}')
                return ','.join(chain)

            if abs(speed_ratio - 1.0) < 0.01:
                print("æ—¶é•¿å·®å¼‚å¾ˆå°ï¼Œä»…æå‡éŸ³é‡")
                tools.runffmpeg([
                    '-y', '-i', str(audio_path),
                    '-af', f'volume={volume_boost}',
                    '-ar', '44100', '-ac', '2', str(temp1)
                ])
            else:
                atempo_chain = build_atempo_chain(speed_ratio)
                print(f"ä½¿ç”¨å—é™å˜é€Ÿé“¾(Â±20%): {atempo_chain} (åŸå§‹å»ºè®®æ¯”ç‡={raw_ratio:.3f})")
                tools.runffmpeg([
                    '-y', '-i', str(audio_path),
                    '-af', f'{atempo_chain},volume={volume_boost}',
                    '-ar', '44100', '-ac', '2', str(temp1)
                ])

            # ç¬¬äºŒæ­¥ï¼šç”¨ apad + -t ç²¾ç¡®åˆ°ç›®æ ‡é•¿åº¦
            tools.runffmpeg([
                '-y', '-i', str(temp1),
                '-af', 'apad', '-t', f'{target_duration:.6f}',
                '-ar', '44100', '-ac', '2', str(temp2)
            ])

            # æ ¡éªŒè¾“å‡ºæ—¶é•¿ï¼Œå¿…è¦æ—¶å†ç²¾ä¿®å‰ª/è¡¥é½
            probe2 = subprocess.run([
                'ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
                '-of', 'csv=p=0', str(temp2)
            ], capture_output=True, text=True)
            try:
                out_dur = float((probe2.stdout or '0').strip())
            except Exception:
                out_dur = 0.0
            if out_dur <= 0 or abs(out_dur - target_duration) > 0.01:
                # å†é€šè¿‡ atrim ç²¾å‡†ä¿®æ­£
                print(f"è¾“å‡ºæ—¶é•¿åå·® {out_dur:.3f}sï¼Œç›®æ ‡ {target_duration:.3f}sï¼Œæ‰§è¡Œç²¾ä¿®...")
                tmp_final = audio_path.parent / f"tmp_final_{audio_path.name}"
                tools.runffmpeg([
                    '-y', '-i', str(temp2),
                    '-af', f'atrim=0:{target_duration:.6f},asetpts=N/SR/TB',
                    '-ar', '44100', '-ac', '2', str(tmp_final)
                ])
                tmp_final.replace(audio_path)
            else:
                # æ›¿æ¢åŸæ–‡ä»¶
                temp2.replace(audio_path)
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try: temp1.unlink(missing_ok=True)
            except Exception: pass
            print(f"éŸ³é¢‘è°ƒæ•´å®Œæˆ: {audio_path}")
            return audio_path

        except Exception as e:
            print(f"éŸ³é¢‘è°ƒæ•´å¤±è´¥: {str(e)}")
            return audio_file

    def synthesize_final_audio(audio_segments, output_file, total_duration, regen_opts=None):
        """åˆæˆæœ€ç»ˆéŸ³é¢‘æ–‡ä»¶"""
        try:
            from videotrans.util import tools
            import subprocess
            from pathlib import Path as _Path

            regen_opts = regen_opts or {}
            voice_mapping = regen_opts.get('voice_mapping') or {}

            def _get_dur_sec(p: _Path) -> float:
                r = subprocess.run([
                    'ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
                    '-of', 'csv=p=0', str(p)
                ], capture_output=True, text=True)
                try:
                    return float((r.stdout or '0').strip())
                except Exception:
                    return 0.0
            
            # åˆ›å»ºé™éŸ³æ–‡ä»¶ä½œä¸ºåŸºç¡€ - ä¿®å¤FFmpegå‚æ•°
            silence_file = output_file.parent / "silence.wav"
            tools.runffmpeg([
                '-y', '-f', 'lavfi', '-i', 'anullsrc',
                '-t', str(total_duration/1000),  # ä½¿ç”¨-tå‚æ•°æŒ‡å®šæ—¶é•¿
                '-ar', '44100', '-ac', '2', str(silence_file)
            ])
            
            # ä¸ºæ¯ä¸ªéŸ³é¢‘ç‰‡æ®µåˆ›å»ºè¦†ç›–å‘½ä»¤ï¼Œåªå¤„ç†å­˜åœ¨çš„æ–‡ä»¶
            filter_complex = []
            inputs = ['-i', str(silence_file)]  # æ·»åŠ  -i å‰ç¼€
            valid_segments = []
            
            for i, segment in enumerate(audio_segments):
                start_time = segment['start_time'] / 1000  # è½¬æ¢ä¸ºç§’
                end_time = segment['end_time'] / 1000
                # å…¼å®¹ç¼ºå¤± duration çš„åœºæ™¯ï¼Œå›é€€ä¸º end-start
                target_duration = int(segment.get('duration', segment['end_time'] - segment['start_time']))  # æ¯«ç§’
                audio_file = segment['file']
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not Path(audio_file).exists():
                    print(f"è­¦å‘Šï¼šéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {audio_file}")
                    continue
                
                # è®¡ç®—ä¸ç›®æ ‡çš„æ¯”ä¾‹
                orig_sec = _get_dur_sec(Path(audio_file))
                tgt_sec = max(0.01, target_duration/1000.0)
                ratio = (orig_sec / tgt_sec) if tgt_sec > 0 else 1.0
                print(f"ç‰‡æ®µ {i+1} åŸå§‹={orig_sec:.3f}s ç›®æ ‡={tgt_sec:.3f}s æ¯”ä¾‹={ratio:.3f}")

                adjusted_path = Path(audio_file)
                need_regen = (ratio < 0.8 or ratio > 1.2) and bool(voice_mapping) and ('text' in segment) and ('speaker' in segment) and segment.get('speaker') in voice_mapping

                if need_regen:
                    # è¶…è¿‡Â±20%ï¼Œä¼˜å…ˆå°è¯•é€šè¿‡ ElevenLabs ä»¥ä¸åŒè¯­é€Ÿé‡ç”Ÿæˆ
                    speaker = segment.get('speaker')
                    text = segment.get('text', '')
                    voice_id = voice_mapping.get(speaker)
                    if voice_id and text:
                        speaking_rate = max(0.5, min(2.0, (tgt_sec / orig_sec) if orig_sec > 0 else 1.0))
                        regen_file = Path(audio_file).parent / f"regen_{Path(audio_file).name}"
                        print(f"è¶…å‡º20%ï¼Œå°è¯•ä»¥è¯­é€Ÿ {speaking_rate:.3f} é‡ç”Ÿæˆ ElevenLabs ç‰‡æ®µ...")
                        ok = generate_tts_audio(text, voice_id, regen_file, speaking_rate=speaking_rate)
                        if ok and regen_file.exists():
                            new_ratio = (_get_dur_sec(regen_file) / tgt_sec) if tgt_sec > 0 else 1.0
                            print(f"é‡ç”Ÿæˆç»“æœæ—¶é•¿æ¯”: {new_ratio:.3f}")
                            adjusted_path = regen_file
                        else:
                            print("é‡ç”Ÿæˆå¤±è´¥ï¼Œé€€å›åˆ°20%èŒƒå›´å†…çš„å˜é€Ÿå¤„ç†")
                            adjusted_path = adjust_audio_length_and_volume(adjusted_path, target_duration, volume_boost=1.8)
                    else:
                        adjusted_path = adjust_audio_length_and_volume(adjusted_path, target_duration, volume_boost=1.8)
                else:
                    # åœ¨Â±20%å†…ï¼ˆæˆ–é‡ç”Ÿæˆä¸å¯ç”¨ï¼‰ï¼Œç”¨æœ¬åœ°å˜é€Ÿ+å¢ç›Šå¯¹é½
                    adjusted_path = adjust_audio_length_and_volume(adjusted_path, target_duration, volume_boost=1.8)
                
                # æ·»åŠ è¾“å…¥æ–‡ä»¶
                inputs.extend(['-i', str(adjusted_path)])
                
                # è®°å½•æœ‰æ•ˆçš„ç‰‡æ®µç´¢å¼•ï¼ˆä»1å¼€å§‹ï¼Œå› ä¸º0æ˜¯é™éŸ³æ–‡ä»¶ï¼‰
                current_index = len(valid_segments) + 1
                valid_segments.append({
                    'index': current_index,
                    'start_time': start_time,
                    'file': str(adjusted_path)
                })
                
                # æ·»åŠ è¦†ç›–æ»¤é•œ
                filter_complex.append(f"[{current_index}:a]adelay={int(start_time*1000)}|{int(start_time*1000)}[a{current_index}]")
            
            if not valid_segments:
                print("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘ç‰‡æ®µï¼Œæ— æ³•åˆæˆ")
                return False
            
            # åˆå¹¶æ‰€æœ‰éŸ³é¢‘
            mix_inputs = "[0:a]"
            for segment in valid_segments:
                mix_inputs += f"[a{segment['index']}]"
            mix_inputs += f"amix=inputs={len(valid_segments)+1}:duration=longest[out]"
            
            filter_complex.append(mix_inputs)
            
            # æ„å»ºFFmpegå‘½ä»¤
            cmd = ['-y'] + inputs + [
                '-filter_complex', ';'.join(filter_complex),
                '-map', '[out]',
                '-ar', '44100', '-ac', '2', '-b:a', '128k',
                str(output_file)
            ]
            
            tools.runffmpeg(cmd)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            silence_file.unlink(missing_ok=True)
            
            return output_file.exists()
            
        except Exception as e:
            print(f"éŸ³é¢‘åˆæˆå¤±è´¥: {str(e)}")
            return False

    def start_video_synthesis_task(task_id, video_path, subtitles):
        """å¯åŠ¨è§†é¢‘åˆæˆä»»åŠ¡çš„åå°å¤„ç†å‡½æ•°

        æ–°æµç¨‹ï¼ˆç‚¹å‡»â€œåˆæˆè§†é¢‘â€ï¼‰ï¼š
        1) å°†è¾“å…¥è§†é¢‘éŸ³è§†é¢‘åˆ†ç¦»ï¼Œç”Ÿæˆ task_dir/video_only.mp4 ä¸ task_dir/audio_only.wav
        2) å¯¹ audio_only.wav è¿›è¡Œ Demucs åˆ†ç¦»ï¼Œä¿ç•™èƒŒæ™¯éŸ³ä¸º task_dir/audio_background.wav
        3) ä» åŸä»»åŠ¡ç›®å½•/generated_audio ä¸­æŸ¥æ‰¾å¸¦ final åç¼€çš„å·²åˆæˆéŸ³é¢‘ï¼Œä¸èƒŒæ™¯éŸ³æ··åˆç”Ÿæˆ task_dir/final_audio.wav
        4) ä½¿ç”¨ video_only.mp4 + final_audio.wav åˆæˆ task_dir/result.mp4
        """
        try:
            from videotrans.util import tools
            import subprocess
            import shutil

            print(f"å¼€å§‹è§†é¢‘åˆæˆä»»åŠ¡: {task_id}")
            tools.set_process(text='[0/4] åˆå§‹åŒ–ä»»åŠ¡...', uuid=task_id)

            # ä»»åŠ¡ç›®å½•ï¼ˆç”¨äºè¾“å‡ºç»“æœå±•ç¤ºï¼‰
            task_dir = Path(TARGET_DIR) / task_id
            cache_dir = Path(config.TEMP_DIR) / task_id
            task_dir.mkdir(parents=True, exist_ok=True)
            cache_dir.mkdir(parents=True, exist_ok=True)

            src_task_dir = Path(video_path).parent  # åŸå§‹ä»»åŠ¡ç›®å½•ï¼ˆç”¨äºæŸ¥æ‰¾ generated_audioï¼‰

            # Step 1: éŸ³è§†é¢‘åˆ†ç¦»
            print("[1/4] æ­£åœ¨åˆ†ç¦»éŸ³è§†é¢‘...")
            tools.set_process(text='[1/4] æ­£åœ¨åˆ†ç¦»éŸ³è§†é¢‘...', uuid=task_id)
            video_only_path = task_dir / "video_only.mp4"
            audio_only_path = task_dir / "audio_only.wav"

            # æå–æ— å£°è§†é¢‘
            tools.runffmpeg([
                '-y', '-i', str(video_path),
                '-c:v', 'copy', '-an', str(video_only_path)
            ])

            # æå–éŸ³é¢‘ï¼ˆåŒå£°é“ã€44100Hzã€s16ï¼‰
            tools.runffmpeg([
                '-y', '-i', str(video_path),
                '-vn', '-ac', '2', '-ar', '44100', '-sample_fmt', 's16', str(audio_only_path)
            ])

            if not video_only_path.exists() or not audio_only_path.exists():
                print("åˆ†ç¦»éŸ³è§†é¢‘å¤±è´¥ï¼šæœªç”Ÿæˆ video_only æˆ– audio_only")
                return

            print(f"å·²ç”Ÿæˆ: {video_only_path.name}, {audio_only_path.name}")

            # Step 2: Demucs åˆ†ç¦»ä¿ç•™èƒŒæ™¯éŸ³
            print("[2/4] æ­£åœ¨ä½¿ç”¨ Demucs åˆ†ç¦»èƒŒæ™¯éŸ³...")
            tools.set_process(text='[2/4] æ­£åœ¨åˆ†ç¦»èƒŒæ™¯éŸ³...', uuid=task_id)
            # åœ¨ä»»åŠ¡ç›®å½•ä¸‹ç”Ÿæˆ background.wav / vocal.wavï¼Œç„¶åé‡å‘½åèƒŒæ™¯éŸ³ä¸º audio_background.wav
            demucs_ok = separate_voice_background_demucs(str(audio_only_path), str(task_dir))
            bgm_source = task_dir / "background.wav"
            audio_background_path = task_dir / "audio_background.wav"
            if demucs_ok and bgm_source.exists():
                shutil.copy2(bgm_source, audio_background_path)
                print(f"èƒŒæ™¯éŸ³ç”ŸæˆæˆåŠŸ: {audio_background_path}")
            else:
                # å¤±è´¥æ—¶æŒ‰æ–‡æ¡£å›é€€ä½¿ç”¨åŸéŸ³é¢‘ä½œä¸ºèƒŒæ™¯éŸ³
                shutil.copy2(audio_only_path, audio_background_path)
                print("Demucs åˆ†ç¦»å¤±è´¥æˆ–è¾“å‡ºç¼ºå¤±ï¼Œä½¿ç”¨åŸéŸ³é¢‘ä½œä¸ºèƒŒæ™¯éŸ³")

            # Step 3: å¯»æ‰¾ generated_audio ä¸­çš„ final éŸ³é¢‘å¹¶æ··åˆ
            print("[3/4] æ­£åœ¨æŸ¥æ‰¾ generated_audio ä¸­çš„ final éŸ³é¢‘...")
            tools.set_process(text='[3/4] æ­£åœ¨æ··åˆäººå£°ä¸èƒŒæ™¯...', uuid=task_id)
            gen_dir = src_task_dir / "generated_audio"
            if not gen_dir.exists():
                print(f"æœªæ‰¾åˆ°ç›®å½•: {gen_dir}")
                return

            # ä¼˜å…ˆåŒ¹é…åŒ…å« "final" å…³é”®å­—çš„ wavï¼Œå…¶æ¬¡ m4a/mp3
            candidates = []
            for pat in ["*final*.wav", "*final*.m4a", "*final*.mp3", "*_final_audio.wav", "*_synthesized_audio.wav"]:
                candidates.extend(sorted(gen_dir.glob(pat)))

            # å»é‡å¹¶æŒ‰ä¿®æ”¹æ—¶é—´å€’åºï¼Œé€‰æ‹©æœ€æ–°çš„
            uniq = []
            seen = set()
            for p in candidates:
                if p.as_posix() not in seen:
                    seen.add(p.as_posix())
                    uniq.append(p)
            if not uniq:
                print("æœªæ‰¾åˆ°å¸¦ final åç¼€çš„å·²åˆæˆéŸ³é¢‘ï¼Œè¯·å…ˆç”ŸæˆåˆæˆéŸ³é¢‘")
                return

            uniq.sort(key=lambda p: p.stat().st_mtime, reverse=True)
            tts_final_path = uniq[0]
            print(f"ä½¿ç”¨å·²åˆæˆéŸ³é¢‘: {tts_final_path}")

            final_audio_path = task_dir / "final_audio.wav"
            ok_mix = mix_audio_files(str(audio_background_path), str(tts_final_path), str(final_audio_path))
            if not ok_mix or not final_audio_path.exists():
                print("æ··åˆèƒŒæ™¯éŸ³ä¸å·²åˆæˆéŸ³é¢‘å¤±è´¥")
                return
            print(f"å·²ç”Ÿæˆæœ€ç»ˆéŸ³é¢‘: {final_audio_path}")

            # Step 4: åˆæˆæœ€ç»ˆè§†é¢‘
            print("[4/4] æ­£åœ¨åˆæˆæœ€ç»ˆè§†é¢‘ result.mp4 ...")
            tools.set_process(text='[4/4] æ­£åœ¨åˆæˆè§†é¢‘...', uuid=task_id)
            result_video_path = task_dir / "result.mp4"
            ok_video = combine_audio_with_video_simple(str(final_audio_path), str(video_only_path), str(result_video_path))
            if ok_video:
                print(f"è§†é¢‘åˆæˆå®Œæˆ: {result_video_path}")
                tools.set_process(text='åˆæˆå®Œæˆ', type='succeed', uuid=task_id)

                # ä¿å­˜ä»»åŠ¡ç»“æœä¿¡æ¯ï¼ˆç”¨äºç»“æœé¡µå±•ç¤ºï¼‰
                result_info = {
                    "task_id": task_id,
                    "status": "completed",
                    "output_file": str(result_video_path),
                    "download_url": f'/{API_RESOURCE}/{task_id}/{result_video_path.name}'
                }
                result_file = task_dir / "result.json"
                with open(result_file, 'w', encoding='utf-8') as f:
                    json.dump(result_info, f, ensure_ascii=False, indent=2)
            else:
                print("è§†é¢‘åˆæˆå¤±è´¥ï¼šæœªç”Ÿæˆ result.mp4")
                tools.set_process(text='è§†é¢‘åˆæˆå¤±è´¥ï¼šæœªç”Ÿæˆ result.mp4', type='error', uuid=task_id)

        except Exception as e:
            print(f"è§†é¢‘åˆæˆä»»åŠ¡å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            try:
                tools.set_process(text=f'åˆæˆå¤±è´¥ï¼š{str(e)}', type='error', uuid=task_id)
            except Exception:
                pass

    def mix_audio_files(bgm_path, tts_path, output_path):
        """æ··åˆèƒŒæ™¯éŸ³ä¹å’ŒTTSéŸ³é¢‘"""
        try:
            import subprocess
            
            # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
            bgm_file = Path(bgm_path)
            tts_file = Path(tts_path)
            
            if not bgm_file.exists():
                print(f"èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ä¸å­˜åœ¨: {bgm_path}")
                return False
                
            if not tts_file.exists():
                print(f"TTSéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {tts_path}")
                return False
            
            print(f"èƒŒæ™¯éŸ³ä¹æ–‡ä»¶å¤§å°: {bgm_file.stat().st_size / 1024:.1f} KB")
            print(f"TTSéŸ³é¢‘æ–‡ä»¶å¤§å°: {tts_file.stat().st_size / 1024:.1f} KB")
            
            # è°ƒæ•´å¢ç›Šï¼Œæå‡æ•´ä½“å“åº¦ï¼šæå‡TTSä¸BGMéŸ³é‡ï¼Œå¹¶å…³é—­amixçš„normalizeé¿å…æ€»ä½“è¢«å‹ä½
            cmd = [
                'ffmpeg', '-y',
                '-i', str(bgm_path),  # èƒŒæ™¯éŸ³ä¹
                '-i', str(tts_path),  # TTSéŸ³é¢‘
                '-filter_complex',
                '[0:a]volume=0.5[bgm];[1:a]volume=1.4[tts];' \
                '[bgm][tts]amix=inputs=2:duration=longest:dropout_transition=0:normalize=0[mixed]',
                '-map', '[mixed]',
                '-c:a', 'pcm_s16le',  # ä½¿ç”¨PCMæ ¼å¼ç¡®ä¿è´¨é‡
                '-ar', '44100',       # é‡‡æ ·ç‡
                str(output_path)
            ]
            
            print(f"æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            
            output_file = Path(output_path)
            if output_file.exists():
                print(f"éŸ³é¢‘æ··åˆæˆåŠŸ: {output_path}")
                print(f"è¾“å‡ºæ–‡ä»¶å¤§å°: {output_file.stat().st_size / 1024:.1f} KB")
                return True
            else:
                print("éŸ³é¢‘æ··åˆå¤±è´¥ï¼šè¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ")
                return False
            
        except subprocess.CalledProcessError as e:
            print(f"FFmpegæ‰§è¡Œå¤±è´¥: {e}")
            print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            return False
        except Exception as e:
            print(f"éŸ³é¢‘æ··åˆå¤±è´¥: {str(e)}")
            return False

    def start_tts_generation_task(task_id, subtitles):
        """å¯åŠ¨TTSéŸ³é¢‘ç”Ÿæˆä»»åŠ¡çš„åå°å¤„ç†å‡½æ•°"""
        try:
            from videotrans import tts
            from videotrans.util import tools
            import subprocess
            
            print(f"å¼€å§‹TTSç”Ÿæˆä»»åŠ¡: {task_id}")
            
            # åˆ›å»ºä»»åŠ¡ç›®å½•
            task_dir = Path(TARGET_DIR) / task_id
            cache_dir = Path(config.TEMP_DIR) / task_id
            task_dir.mkdir(parents=True, exist_ok=True)
            cache_dir.mkdir(parents=True, exist_ok=True)
            
            # å‡†å¤‡TTSé˜Ÿåˆ—æ•°æ®
            queue_tts = []
            for i, subtitle in enumerate(subtitles):
                if not subtitle.get('text', '').strip():
                    continue
                    
                # è®¡ç®—æ—¶é•¿
                start_time = int(subtitle.get('start_time', 0))
                end_time = int(subtitle.get('end_time', 0))
                duration = end_time - start_time
                
                if duration <= 0:
                    continue
                
                # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
                filename_md5 = tools.get_md5(
                    f"edgetts-{start_time}-{end_time}-zh-CN-XiaoxiaoNeural-+0%-+0%-+0Hz-{len(subtitle['text'])}-{i}")
                
                tts_item = {
                    "line": subtitle.get('line', i + 1),
                    "text": subtitle['text'],
                    "role": "zh-CN-XiaoxiaoNeural",  # é»˜è®¤ä½¿ç”¨EdgeTTSä¸­æ–‡å¥³å£°
                    "start_time": start_time,
                    "end_time": end_time,
                    "startraw": subtitle.get('startraw', ''),
                    "endraw": subtitle.get('endraw', ''),
                    "rate": "+20%",  # æé«˜è¯­é€Ÿ20%
                    "volume": "+0%",
                    "pitch": "+0Hz",
                    "tts_type": 0,  # EdgeTTS
                    "filename": config.TEMP_DIR + f"/dubbing_cache/{filename_md5}.wav"
                }
                queue_tts.append(tts_item)
            
            if not queue_tts:
                print("æ²¡æœ‰æœ‰æ•ˆçš„å­—å¹•æ•°æ®")
                return
            
            # åˆ›å»ºç¼“å­˜ç›®å½•
            Path(config.TEMP_DIR + "/dubbing_cache").mkdir(parents=True, exist_ok=True)
            
            print(f"å¼€å§‹ç”ŸæˆTTSéŸ³é¢‘ï¼Œå…±{len(queue_tts)}æ¡å­—å¹•")
            
            # è®¾ç½®TTSçŠ¶æ€
            config.box_tts = 'ing'
            
            # è°ƒç”¨TTSå¼•æ“ç”ŸæˆéŸ³é¢‘
            try:
                tts.run(queue_tts=queue_tts, language="zh-cn", 
                       inst=None, uuid=task_id, play=False, is_test=False)
                print("TTSå¼•æ“è°ƒç”¨å®Œæˆ")
            except Exception as e:
                print(f"TTSå¼•æ“è°ƒç”¨å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()
                config.box_tts = 'stop'
                return
            
            # æ£€æŸ¥ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
            audio_files = []
            print(f"æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶ï¼Œå…±{len(queue_tts)}ä¸ªä»»åŠ¡...")
            for i, item in enumerate(queue_tts):
                audio_path = Path(item['filename'])
                print(f"æ£€æŸ¥æ–‡ä»¶ {i+1}: {audio_path} - å­˜åœ¨: {audio_path.exists()}")
                if audio_path.exists():
                    audio_files.append({
                        'path': str(audio_path),
                        'start_time': item['start_time'],
                        'end_time': item['end_time'],
                        'text': item['text']
                    })
                    print(f"  âœ“ æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_path}")
                else:
                    print(f"  âœ— éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            
            if not audio_files:
                print("æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘æ–‡ä»¶")
                print("æ£€æŸ¥ç¼“å­˜ç›®å½•ä¸­çš„æ–‡ä»¶:")
                cache_dir = Path(config.TEMP_DIR + "/dubbing_cache")
                if cache_dir.exists():
                        print(f"  ç¼“å­˜æ–‡ä»¶: {f}")
                else:
                    print("  ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
                return
            
            print(f"æˆåŠŸç”Ÿæˆ{len(audio_files)}ä¸ªéŸ³é¢‘ç‰‡æ®µ")
            
            # æŒ‰æ—¶é—´é¡ºåºæ’åºéŸ³é¢‘æ–‡ä»¶
            audio_files.sort(key=lambda x: x['start_time'])
            
            # ä½¿ç”¨ffmpegè¿æ¥éŸ³é¢‘æ–‡ä»¶
            output_audio = task_dir / f"tts_audio_{int(time.time())}.wav"
            success = concatenate_audio_files(audio_files, str(output_audio))
            
            if success:
                print(f"TTSéŸ³é¢‘ç”Ÿæˆå®Œæˆ: {output_audio}")
                
                # åˆ›å»ºä¸‹è½½é“¾æ¥
                download_url = f'/{API_RESOURCE}/{task_id}/{output_audio.name}'
                
                # ä¿å­˜ä»»åŠ¡ç»“æœä¿¡æ¯
                result_info = {
                    "task_id": task_id,
                    "status": "completed",
                    "output_file": str(output_audio),
                    "download_url": download_url,
                    "audio_count": len(audio_files),
                    "total_duration": audio_files[-1]['end_time'] if audio_files else 0
                }
                
                # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                result_file = task_dir / "result.json"
                with open(result_file, 'w', encoding='utf-8') as f:
                    json.dump(result_info, f, ensure_ascii=False, indent=2)
                
            else:
                print("éŸ³é¢‘è¿æ¥å¤±è´¥")
            
            # é‡ç½®TTSçŠ¶æ€
            config.box_tts = 'stop'
                
        except Exception as e:
            print(f"TTSç”Ÿæˆä»»åŠ¡å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()

    def concatenate_audio_files(audio_files, output_path):
        """æŒ‰ç…§SRTæ—¶é—´è½´ç²¾ç¡®è¿æ¥éŸ³é¢‘æ–‡ä»¶"""
        try:
            import subprocess
            from pathlib import Path as _Path
            
            if not audio_files:
                print("æ²¡æœ‰éŸ³é¢‘æ–‡ä»¶éœ€è¦è¿æ¥")
                return False
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = Path(output_path).parent / "temp_audio"
            temp_dir.mkdir(exist_ok=True)
            
            print(f"å¼€å§‹è¿æ¥éŸ³é¢‘ï¼Œå…±{len(audio_files)}ä¸ªç‰‡æ®µ")
            
            # è®¡ç®—æ€»æ—¶é•¿
            total_duration_ms = audio_files[-1]['end_time']
            total_duration_sec = total_duration_ms / 1000.0
            
            print(f"æ€»æ—¶é•¿: {total_duration_sec:.2f}ç§’")
            
            # ä¸ºæ¯ä¸ªéŸ³é¢‘ç‰‡æ®µæ·»åŠ é™éŸ³å‰ç¼€ï¼Œç¡®ä¿æ—¶é—´å¯¹é½
            processed_files = []
            for i, audio_file in enumerate(audio_files):
                start_sec = audio_file['start_time'] / 1000.0
                end_sec = audio_file['end_time'] / 1000.0
                duration_sec = max(0.01, end_sec - start_sec)
                
                print(f"å¤„ç†ç‰‡æ®µ {i+1}: {start_sec:.2f}s - {end_sec:.2f}s (æ—¶é•¿: {duration_sec:.2f}s)")
                
                processed_file = temp_dir / f"processed_{i:04d}.wav"
                # åœ¨æ‹¼æ¥å‰ï¼Œå…ˆå°†ç‰‡æ®µæœ¬ä½“å¼ºåˆ¶æ‹‰ä¼¸/å‹ç¼©åˆ°ç›®æ ‡æ—¶é•¿ï¼Œå¹¶æå‡éŸ³é‡
                try:
                    adj_path = _Path(audio_file['path'])
                    target_ms = int(round(duration_sec * 1000))
                    adjust_audio_length_and_volume(adj_path, target_ms, volume_boost=1.8)
                except Exception as _e:
                    print(f"  âš ï¸ ç‰‡æ®µæ—¶é•¿è°ƒæ•´å¤±è´¥ï¼Œä½¿ç”¨åŸç‰‡æ®µ: {audio_file['path']} -> {_e}")
                
                # è®¡ç®—éœ€è¦æ·»åŠ çš„é™éŸ³æ—¶é•¿
                if i == 0:
                    # ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼Œæ·»åŠ å¼€å§‹é™éŸ³
                    silence_duration = start_sec
                else:
                    # åç»­æ–‡ä»¶ï¼Œæ·»åŠ ä¸å‰ä¸€ä¸ªæ–‡ä»¶çš„é—´éš”
                    prev_end = audio_files[i-1]['end_time'] / 1000.0
                    silence_duration = start_sec - prev_end
                
                print(f"  é™éŸ³æ—¶é•¿: {silence_duration:.2f}ç§’")
                
                if silence_duration > 0:
                    # æ·»åŠ é™éŸ³å‰ç¼€
                    cmd = [
                        'ffmpeg', '-y',
                        '-f', 'lavfi', '-i', 'anullsrc',
                        '-t', str(silence_duration),
                        '-i', audio_file['path'],
                        '-filter_complex', '[0][1]concat=n=2:v=0:a=1[out]',
                        '-map', '[out]',
                        '-ar', '44100',
                        '-ac', '2',
                        str(processed_file)
                    ]
                else:
                    # ç›´æ¥å¤åˆ¶æ–‡ä»¶
                    cmd = [
                        'ffmpeg', '-y',
                        '-i', audio_file['path'],
                        '-ar', '44100',
                        '-ac', '2',
                        str(processed_file)
                    ]
                
                print(f"  æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
                result = subprocess.run(cmd, check=True, capture_output=True, text=True)
                
                if result.returncode == 0:
                    processed_files.append(str(processed_file))
                    print(f"  âœ… å¤„ç†æˆåŠŸ")
                else:
                    print(f"  âŒ å¤„ç†å¤±è´¥: {result.stderr}")
                    return False
            
            # è¿æ¥æ‰€æœ‰å¤„ç†åçš„éŸ³é¢‘æ–‡ä»¶
            if len(processed_files) == 1:
                # åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥å¤åˆ¶
                cmd = ['ffmpeg', '-y', '-i', processed_files[0], str(output_path)]
            else:
                # å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨concat filterè¿æ¥
                concat_filter = f'concat=n={len(processed_files)}:v=0:a=1[out]'
                cmd = ['ffmpeg', '-y']
                for file_path in processed_files:
                    cmd.extend(['-i', file_path])
                cmd.extend(['-filter_complex', concat_filter, '-map', '[out]', str(output_path)])
            
            print(f"è¿æ¥éŸ³é¢‘æ–‡ä»¶: {' '.join(cmd)}")
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"âœ… éŸ³é¢‘è¿æ¥å®Œæˆ: {output_path}")
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                import shutil
                shutil.rmtree(temp_dir)
                return True
            else:
                print(f"âŒ éŸ³é¢‘è¿æ¥å¤±è´¥: {result.stderr}")
                return False
            
        except Exception as e:
            print(f"éŸ³é¢‘è¿æ¥å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def start_voice_dubbing_task(task_id, video_path, srt_path, subtitles):
        """å¯åŠ¨æ™ºèƒ½é…éŸ³ä»»åŠ¡çš„åå°å¤„ç†å‡½æ•°"""
        try:
            from videotrans.task._dubbing import DubbingSrt
            from videotrans import tts
            from videotrans.util import tools
            
            # åˆ†æè¯´è¯äººï¼Œä¸ºæ¯ä¸ªè¯´è¯äººåˆ†é…ä¸åŒçš„éŸ³è‰²
            speakers = list(set([s.get('speaker', '') for s in subtitles if s.get('speaker')]))
            speaker_roles = {}
            
            # ä¸ºæ¯ä¸ªè¯´è¯äººåˆ†é…EdgeTTSéŸ³è‰²
            edgetts_roles = ['zh-CN-XiaoxiaoNeural', 'zh-CN-YunxiNeural', 'zh-CN-YunyangNeural', 'zh-CN-XiaochenNeural']
            for i, speaker in enumerate(speakers):
                if i < len(edgetts_roles):
                    speaker_roles[speaker] = edgetts_roles[i]
                else:
                    # å¦‚æœè¯´è¯äººå¤ªå¤šï¼Œå¾ªç¯ä½¿ç”¨éŸ³è‰²
                    speaker_roles[speaker] = edgetts_roles[i % len(edgetts_roles)]
            
            # è®¾ç½®å…¨å±€é…ç½®
            config.dubbing_role = {}
            for subtitle in subtitles:
                speaker = subtitle.get('speaker', '')
                if speaker in speaker_roles:
                    config.dubbing_role[subtitle.get('line', 1)] = speaker_roles[speaker]
            
            # åˆ›å»ºä»»åŠ¡ç›®å½•
            task_dir = Path(TARGET_DIR) / task_id
            cache_dir = Path(config.TEMP_DIR) / task_id
            task_dir.mkdir(parents=True, exist_ok=True)
            cache_dir.mkdir(parents=True, exist_ok=True)
            
            # 1. ä»è§†é¢‘ä¸­æå–éŸ³é¢‘
            audio_path = cache_dir / "extracted_audio.wav"
            tools.conver_to_16k(video_path, str(audio_path))
            
            # 2. äººå£°åˆ†ç¦» - ä½¿ç”¨Demucsåˆ†ç¦»äººå£°å’ŒèƒŒæ™¯éŸ³ä¹
            bgm_path = cache_dir / "background.wav"  # èƒŒæ™¯éŸ³ä¹
            vocal_path = cache_dir / "vocal.wav"     # åŸäººå£°
            
            try:
                print(f"å¼€å§‹äººå£°åˆ†ç¦»ï¼ˆä½¿ç”¨Demucsï¼‰...")
                success = separate_voice_background_demucs(str(audio_path), str(cache_dir))
                
                if success and bgm_path.exists():
                    print("Demucsäººå£°åˆ†ç¦»æˆåŠŸ")
                else:
                    print("Demucsäººå£°åˆ†ç¦»å¤±è´¥ï¼Œä½¿ç”¨åŸéŸ³é¢‘ä½œä¸ºèƒŒæ™¯éŸ³ä¹")
                    bgm_path = audio_path
                    
            except Exception as e:
                print(f"äººå£°åˆ†ç¦»å¤±è´¥: {str(e)}")
                print("ä½¿ç”¨åŸéŸ³é¢‘ä½œä¸ºèƒŒæ™¯éŸ³ä¹ï¼ˆæ— åˆ†ç¦»ï¼‰")
                bgm_path = audio_path
            
            # 3. åˆ›å»ºé…éŸ³ä»»åŠ¡é…ç½®
            obj = tools.format_video(video_path, None)
            obj['target_dir'] = str(task_dir)
            obj['cache_folder'] = str(cache_dir)
            
            cfg = {
                "name": srt_path,  # ä½¿ç”¨SRTæ–‡ä»¶è·¯å¾„ï¼Œä¸æ˜¯è§†é¢‘è·¯å¾„
                "voice_role": "zh-CN-XiaoxiaoNeural",  # é»˜è®¤è§’è‰²
                "target_language_code": "zh-cn",
                "tts_type": tts.EDGE_TTS,  # ä½¿ç”¨EdgeTTS
                "voice_rate": "+0%",
                "volume": "+0%",
                "pitch": "+0Hz",
                "out_ext": "wav",
                "voice_autorate": True,
                "is_multi_role": True,  # å¯ç”¨å¤šè§’è‰²æ¨¡å¼
                "bgm_path": str(bgm_path),  # èƒŒæ™¯éŸ³ä¹è·¯å¾„
                "original_video": video_path,  # åŸå§‹è§†é¢‘è·¯å¾„
            }
            cfg.update(obj)
            
            # 4. å¯åŠ¨é…éŸ³ä»»åŠ¡
            config.box_tts = 'ing'
            
            # ç¡®ä¿SRTæ–‡ä»¶å¯ä»¥è¢«æ­£ç¡®è¯»å–
            srt_file = Path(srt_path)
            try:
                # æµ‹è¯•è¯»å–SRTæ–‡ä»¶
                with open(srt_file, 'r', encoding='utf-8') as f:
                    test_read = f.read()
                print(f"SRTæ–‡ä»¶è¯»å–æµ‹è¯•æˆåŠŸï¼Œé•¿åº¦: {len(test_read)}")
            except UnicodeDecodeError:
                print("UTF-8è¯»å–å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç ")
                # å°è¯•ç”¨å…¶ä»–ç¼–ç é‡æ–°ä¿å­˜
                try:
                    with open(srt_file, 'r', encoding='gbk') as f:
                        content = f.read()
                    srt_file.write_text(content, encoding='utf-8', errors='replace')
                    print("å·²é‡æ–°ä¿å­˜ä¸ºUTF-8ç¼–ç ")
                except:
                    # å¦‚æœGBKä¹Ÿå¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨é”™è¯¯æ›¿æ¢æ¨¡å¼
                    with open(srt_file, 'r', encoding='utf-8', errors='replace') as f:
                        content = f.read()
                    srt_file.write_text(content, encoding='utf-8', errors='replace')
                    print("å·²ä½¿ç”¨é”™è¯¯æ›¿æ¢æ¨¡å¼é‡æ–°ä¿å­˜")
            except Exception as e:
                print(f"SRTæ–‡ä»¶è¯»å–æµ‹è¯•å¤±è´¥: {str(e)}")
                # æœ€åå°è¯•ï¼Œä½¿ç”¨é”™è¯¯æ›¿æ¢æ¨¡å¼
                try:
                    with open(srt_file, 'r', encoding='utf-8', errors='replace') as f:
                        content = f.read()
                    srt_file.write_text(content, encoding='utf-8', errors='replace')
                    print("å·²ä½¿ç”¨é”™è¯¯æ›¿æ¢æ¨¡å¼é‡æ–°ä¿å­˜")
                except:
                    print("æ— æ³•ä¿®å¤SRTæ–‡ä»¶ç¼–ç é—®é¢˜")
            
            # åˆ›å»ºä¸€ä¸ªå®‰å…¨çš„DubbingSrtå­ç±»æ¥å¤„ç†ç¼–ç é—®é¢˜
            class SafeDubbingSrt(DubbingSrt):
                def dubbing(self):
                    try:
                        # å®‰å…¨è¯»å–SRTæ–‡ä»¶
                        srt_path = Path(self.cfg['target_sub'])
                        srt_content = self._safe_read_srt(srt_path)
                        self._signal(text=srt_content, type="replace")
                        self._tts()
                    except Exception as e:
                        self.hasend = True
                        tools.send_notification(str(e), f'{self.cfg["basename"]}')
                        raise
                
                def _safe_read_srt(self, srt_path):
                    """å®‰å…¨è¯»å–SRTæ–‡ä»¶ï¼Œå¤„ç†ç¼–ç é—®é¢˜"""
                    encodings = ['utf-8', 'gbk', 'gb2312', 'utf-16', 'latin-1']
                    
                    for encoding in encodings:
                        try:
                            with open(srt_path, 'r', encoding=encoding) as f:
                                content = f.read()
                            print(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–SRTæ–‡ä»¶")
                            return content
                        except UnicodeDecodeError:
                            continue
                        except Exception as e:
                            print(f"ä½¿ç”¨ {encoding} ç¼–ç è¯»å–å¤±è´¥: {str(e)}")
                            continue
                    
                    # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨é”™è¯¯æ›¿æ¢æ¨¡å¼
                    try:
                        with open(srt_path, 'r', encoding='utf-8', errors='replace') as f:
                            content = f.read()
                        print("ä½¿ç”¨UTF-8é”™è¯¯æ›¿æ¢æ¨¡å¼è¯»å–SRTæ–‡ä»¶")
                        return content
                    except Exception as e:
                        print(f"æ‰€æœ‰ç¼–ç æ–¹å¼éƒ½å¤±è´¥: {str(e)}")
                        return ""
                
                def _tts(self):
                    """é‡å†™_ttsæ–¹æ³•ï¼Œç›´æ¥ä½¿ç”¨å‰ç«¯æä¾›çš„å­—å¹•æ•°æ®"""
                    queue_tts = []
                    # è·å–å­—å¹•
                    try:
                        rate = int(str(self.cfg['voice_rate']).replace('%', ''))
                    except:
                        rate = 0
                    if rate >= 0:
                        rate = f"+{rate}%"
                    else:
                        rate = f"{rate}%"
                    
                    # ç›´æ¥ä½¿ç”¨å‰ç«¯æä¾›çš„å­—å¹•æ•°æ®ï¼Œè€Œä¸æ˜¯ä»SRTæ–‡ä»¶è§£æ
                    subs = subtitles  # ä½¿ç”¨ä¼ å…¥çš„å­—å¹•æ•°æ®
                    
                    # å–å‡ºæ¯ä¸€æ¡å­—å¹•ï¼Œè¡Œå·\nå¼€å§‹æ—¶é—´ --> ç»“æŸæ—¶é—´\nå†…å®¹
                    for i, it in enumerate(subs):
                        if it.get('end_time', 0) <= it.get('start_time', 0):
                            continue
                        try:
                            spec_role = config.dubbing_role.get(int(it.get('line', 1))) if self.is_multi_role else None
                        except:
                            spec_role = None
                        voice_role = spec_role if spec_role else self.cfg['voice_role']

                        # è¦ä¿å­˜åˆ°çš„æ–‡ä»¶
                        filename_md5 = tools.get_md5(
                            f"{self.cfg['tts_type']}-{it['start_time']}-{it['end_time']}-{voice_role}-{rate}-{self.cfg['volume']}-{self.cfg['pitch']}-{len(it['text'])}-{i}")
                        tmp_dict = {
                            "line": it['line'],
                            "text": it['text'],
                            "role": voice_role,
                            "start_time": it['start_time'],
                            "end_time": it['end_time'],
                            "rate": rate,
                            "startraw": it.get('startraw', ''),
                            "endraw": it.get('endraw', ''),
                            "volume": self.cfg['volume'],
                            "pitch": self.cfg['pitch'],
                            "tts_type": int(self.cfg['tts_type']),
                            "filename": config.TEMP_DIR + f"/dubbing_cache/{filename_md5}.wav"}
                        queue_tts.append(tmp_dict)
                    
                    Path(config.TEMP_DIR + "/dubbing_cache").mkdir(parents=True, exist_ok=True)
                    if len(queue_tts) < 1:
                        return
                    
                    # è°ƒç”¨TTSå¼•æ“
                    tts.run(queue_tts=queue_tts, language=self.cfg['target_language_code'], 
                           inst=self, uuid=self.uuid, play=False, is_test=False)
            
            trk = SafeDubbingSrt(cfg=cfg)
            trk.dubbing()
            
            # 5. åˆæˆæœ€ç»ˆè§†é¢‘ï¼ˆé…éŸ³ + èƒŒæ™¯éŸ³ä¹ + åŸè§†é¢‘ç”»é¢ï¼‰
            final_video_path = task_dir / f"dubbed_{Path(video_path).stem}.mp4"
            
            # æ£€æŸ¥æ˜¯å¦æœ‰èƒŒæ™¯éŸ³ä¹åˆ†ç¦»
            if bgm_path == audio_path:
                # æ²¡æœ‰èƒŒæ™¯éŸ³ä¹åˆ†ç¦»ï¼Œç›´æ¥ä½¿ç”¨é…éŸ³éŸ³é¢‘
                print("æ— èƒŒæ™¯éŸ³ä¹åˆ†ç¦»ï¼Œç›´æ¥ä½¿ç”¨é…éŸ³éŸ³é¢‘")
                combine_audio_with_video_simple(
                    str(trk.cfg['target_wav']),  # é…éŸ³éŸ³é¢‘
                    video_path,  # åŸè§†é¢‘
                    str(final_video_path)  # è¾“å‡ºè§†é¢‘
                )
            else:
                # æœ‰èƒŒæ™¯éŸ³ä¹åˆ†ç¦»ï¼Œæ··åˆèƒŒæ™¯éŸ³ä¹å’Œé…éŸ³
                print("æ··åˆèƒŒæ™¯éŸ³ä¹å’Œé…éŸ³")
                combine_audio_with_video(
                    str(bgm_path),  # èƒŒæ™¯éŸ³ä¹
                    str(trk.cfg['target_wav']),  # é…éŸ³éŸ³é¢‘
                    video_path,  # åŸè§†é¢‘
                    str(final_video_path)  # è¾“å‡ºè§†é¢‘
                )
            
            print(f"é…éŸ³ä»»åŠ¡å®Œæˆ: {final_video_path}")
            
        except Exception as e:
            print(f"é…éŸ³ä»»åŠ¡å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()

    def separate_voice_background_demucs(audio_path, output_dir):
        """ä½¿ç”¨Demucsåˆ†ç¦»äººå£°å’ŒèƒŒæ™¯éŸ³ä¹"""
        try:
            import subprocess
            import shutil
            from pathlib import Path
            
            output_path = Path(output_dir)
            vocal_path = output_path / "vocal.wav"
            background_path = output_path / "background.wav"
            
            print(f"å¼€å§‹Demucsäººå£°åˆ†ç¦»...")
            print(f"è¾“å…¥éŸ³é¢‘: {audio_path}")
            print(f"è¾“å‡ºç›®å½•: {output_dir}")
            
            # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
            if not Path(audio_path).exists():
                print(f"è¾“å…¥éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                return False
            
            # å°è¯•å¤šç§æ–¹å¼è°ƒç”¨Demucs
            demucs_commands = [
                ['demucs'],
                ['python', '-m', 'demucs'],
                ['python3', '-m', 'demucs'],
                ['python3.11', '-m', 'demucs']
            ]
            
            demucs_cmd = None
            for cmd in demucs_commands:
                try:
                    result = subprocess.run(cmd + ['--help'], capture_output=True, text=True)
                    if result.returncode == 0:
                        demucs_cmd = cmd
                        print(f"æ‰¾åˆ°Demucs: {' '.join(cmd)}")
                        break
                except FileNotFoundError:
                    continue
            
            if not demucs_cmd:
                print("æ— æ³•æ‰¾åˆ°Demucsï¼Œè¯·å®‰è£…: pip install demucs")
                return False
            
            # ä½¿ç”¨Demucsåˆ†ç¦» - ä½¿ç”¨æ›´ç®€å•çš„å‚æ•°
            print("æ‰§è¡ŒDemucsåˆ†ç¦»...")
            demucs_args = [
                *demucs_cmd,
                '--two-stems', 'vocals',  # åˆ†ç¦»äººå£°å’ŒèƒŒæ™¯
                '--out', str(output_path),
                str(audio_path)
            ]
            
            print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(demucs_args)}")
            result = subprocess.run(demucs_args, capture_output=True, text=True, timeout=300)
            
            print(f"Demucsè¿”å›ç : {result.returncode}")
            if result.stdout:
                print(f"Demucsè¾“å‡º: {result.stdout}")
            if result.stderr:
                print(f"Demucsé”™è¯¯: {result.stderr}")
            
            if result.returncode != 0:
                print(f"Demucsåˆ†ç¦»å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                return False
            
            # Demucsè¾“å‡ºç›®å½•ç»“æ„ - æ£€æŸ¥å¤šç§å¯èƒ½çš„è¾“å‡ºç»“æ„
            audio_name = Path(audio_path).stem
            possible_output_dirs = [
                output_path / "htdemucs" / audio_name,
                output_path / "htdemucs",
                output_path / audio_name,
                output_path
            ]
            
            vocals_file = None
            no_vocals_file = None
            
            for demucs_output_dir in possible_output_dirs:
                if demucs_output_dir.exists():
                    print(f"æ£€æŸ¥è¾“å‡ºç›®å½•: {demucs_output_dir}")
                    
                    # æŸ¥æ‰¾åˆ†ç¦»åçš„æ–‡ä»¶
                    vocals_candidate = demucs_output_dir / "vocals.wav"
                    no_vocals_candidate = demucs_output_dir / "no_vocals.wav"
                    
                    if vocals_candidate.exists() and no_vocals_candidate.exists():
                        vocals_file = vocals_candidate
                        no_vocals_file = no_vocals_candidate
                        print(f"æ‰¾åˆ°åˆ†ç¦»æ–‡ä»¶: {vocals_file}, {no_vocals_file}")
                        break
                    else:
                        # åˆ—å‡ºç›®å½•å†…å®¹ç”¨äºè°ƒè¯•
                        print(f"ç›®å½•å†…å®¹: {list(demucs_output_dir.iterdir())}")
            
            if vocals_file and no_vocals_file:
                # å¤åˆ¶åˆ°æŒ‡å®šä½ç½®
                shutil.copy2(vocals_file, vocal_path)
                shutil.copy2(no_vocals_file, background_path)
                
                print(f"äººå£°åˆ†ç¦»æˆåŠŸ: {vocal_path} (å¤§å°: {vocal_path.stat().st_size / 1024:.1f} KB)")
                print(f"èƒŒæ™¯éŸ³åˆ†ç¦»æˆåŠŸ: {background_path} (å¤§å°: {background_path.stat().st_size / 1024:.1f} KB)")
                
                # æ¸…ç†Demucsä¸´æ—¶æ–‡ä»¶
                for demucs_output_dir in possible_output_dirs:
                    if demucs_output_dir.exists() and demucs_output_dir != output_path:
                        try:
                            shutil.rmtree(demucs_output_dir)
                            print(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {demucs_output_dir}")
                        except:
                            pass
                
                return True
            else:
                print("Demucsè¾“å‡ºæ–‡ä»¶æœªæ‰¾åˆ°")
                print(f"æ£€æŸ¥çš„è·¯å¾„: {possible_output_dirs}")
                return False
                
        except subprocess.TimeoutExpired:
            print("Demucsåˆ†ç¦»è¶…æ—¶")
            return False
        except Exception as e:
            print(f"Demucsåˆ†ç¦»å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def combine_audio_with_video(bgm_path, dubbing_path, video_path, output_path):
        """å°†èƒŒæ™¯éŸ³ä¹ã€é…éŸ³å’ŒåŸè§†é¢‘ç”»é¢åˆæˆæœ€ç»ˆè§†é¢‘"""
        try:
            import subprocess
            
            # ä½¿ç”¨ffmpegåˆæˆéŸ³é¢‘å’Œè§†é¢‘
            # 1. å°†èƒŒæ™¯éŸ³ä¹å’Œé…éŸ³æ··åˆ
            mixed_audio = Path(output_path).parent / "mixed_audio.wav"
            cmd1 = [
                'ffmpeg', '-y',
                '-i', bgm_path,
                '-i', dubbing_path,
                '-filter_complex',
                '[0:a]volume=0.5[bgm];[1:a]volume=1.4[tts];' \
                '[bgm][tts]amix=inputs=2:duration=longest:normalize=0[mixed]',
                '-map', '[mixed]',
                '-c:a', 'aac',
                '-b:a', '128k',
                str(mixed_audio)
            ]
            subprocess.run(cmd1, check=True, capture_output=True)
            
            # 2. å°†æ··åˆéŸ³é¢‘ä¸åŸè§†é¢‘ç”»é¢åˆæˆ
            cmd2 = [
                'ffmpeg', '-y',
                '-i', video_path,
                '-i', str(mixed_audio),
                '-c:v', 'copy',  # å¤åˆ¶è§†é¢‘æµï¼Œä¸é‡æ–°ç¼–ç 
                '-c:a', 'aac',
                '-b:a', '128k',
                '-map', '0:v:0',  # ä½¿ç”¨åŸè§†é¢‘çš„ç”»é¢
                '-map', '1:a:0',  # ä½¿ç”¨æ··åˆåçš„éŸ³é¢‘
                '-shortest',  # ä»¥è¾ƒçŸ­çš„æµä¸ºå‡†
                str(output_path)
            ]
            subprocess.run(cmd2, check=True, capture_output=True)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if mixed_audio.exists():
                mixed_audio.unlink()
                
        except Exception as e:
            print(f"è§†é¢‘åˆæˆå¤±è´¥: {str(e)}")
            # å¦‚æœåˆæˆå¤±è´¥ï¼Œè‡³å°‘ä¿ç•™é…éŸ³éŸ³é¢‘æ–‡ä»¶

    def combine_audio_with_video_simple(dubbing_path, video_path, output_path):
        """å°†é…éŸ³éŸ³é¢‘ä¸åŸè§†é¢‘ç”»é¢åˆæˆï¼ˆæ— èƒŒæ™¯éŸ³ä¹æ··åˆï¼‰"""
        try:
            import subprocess
            
            # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
            dubbing_file = Path(dubbing_path)
            video_file = Path(video_path)
            
            if not dubbing_file.exists():
                print(f"é…éŸ³éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {dubbing_path}")
                return False
                
            if not video_file.exists():
                print(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                return False
            
            print(f"é…éŸ³éŸ³é¢‘æ–‡ä»¶å¤§å°: {dubbing_file.stat().st_size / 1024:.1f} KB")
            print(f"è§†é¢‘æ–‡ä»¶å¤§å°: {video_file.stat().st_size / 1024:.1f} KB")
            
            # ç›´æ¥å°†é…éŸ³éŸ³é¢‘ä¸åŸè§†é¢‘ç”»é¢åˆæˆ
            cmd = [
                'ffmpeg', '-y',
                '-i', str(video_path),
                '-i', str(dubbing_path),
                '-c:v', 'copy',  # å¤åˆ¶è§†é¢‘æµï¼Œä¸é‡æ–°ç¼–ç 
                '-c:a', 'aac',
                '-b:a', '128k',
                '-map', '0:v:0',  # ä½¿ç”¨åŸè§†é¢‘çš„ç”»é¢
                '-map', '1:a:0',  # ä½¿ç”¨é…éŸ³éŸ³é¢‘
                '-shortest',  # ä»¥è¾ƒçŸ­çš„æµä¸ºå‡†
                str(output_path)
            ]
            
            print(f"æ‰§è¡ŒFFmpegè§†é¢‘åˆæˆå‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            
            output_file = Path(output_path)
            if output_file.exists():
                print(f"è§†é¢‘åˆæˆå®Œæˆ: {output_path}")
                print(f"è¾“å‡ºè§†é¢‘æ–‡ä»¶å¤§å°: {output_file.stat().st_size / 1024:.1f} KB")
                return True
            else:
                print("è§†é¢‘åˆæˆå¤±è´¥ï¼šè¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ")
                return False
                
        except subprocess.CalledProcessError as e:
            print(f"FFmpegè§†é¢‘åˆæˆæ‰§è¡Œå¤±è´¥: {e}")
            print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            return False
        except Exception as e:
            print(f"è§†é¢‘åˆæˆå¤±è´¥: {str(e)}")
            return False

    @app.route('/synthesis_result/<task_id>')
    def synthesis_result(task_id):
        """è§†é¢‘åˆæˆç»“æœé¡µé¢"""
        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return "ä»»åŠ¡ä¸å­˜åœ¨", 404
        
        # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
        files = [f for f in task_dir.iterdir() if f.is_file()]
        output_files = []
        for f in files:
            if f.suffix.lower() in ['.mp4', '.avi', '.mov', '.mkv', '.wav', '.mp3', '.m4a']:
                output_files.append(f)
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <title>è§†é¢‘åˆæˆç»“æœ - {task_id}</title>
            <style>
                body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 20px; background: #f5f5f5; }}
                .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                h1 {{ color: #333; margin-bottom: 20px; }}
                .file-list {{ list-style: none; padding: 0; }}
                .file-item {{ padding: 10px; border: 1px solid #ddd; margin: 10px 0; border-radius: 4px; background: #f9f9f9; }}
                .file-item a {{ color: #007AFF; text-decoration: none; font-weight: bold; }}
                .file-item a:hover {{ text-decoration: underline; }}
                .status {{ padding: 10px; border-radius: 4px; margin: 10px 0; }}
                .status.processing {{ background: #fff3cd; border: 1px solid #ffeaa7; color: #856404; }}
                .status.completed {{ background: #d4edda; border: 1px solid #c3e6cb; color: #155724; }}
                .status.error {{ background: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; }}
                .video-player {{ width: 100%; margin: 10px 0; }}
                .audio-player {{ width: 100%; margin: 10px 0; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>è§†é¢‘åˆæˆç»“æœ</h1>
                <div class="task-info">
                    <p><strong>ä»»åŠ¡ID:</strong> {task_id}</p>
                    <p><strong>çŠ¶æ€:</strong> <span id="status">æ£€æŸ¥ä¸­...</span></p>
                </div>
                <div id="fileList">
                    <p>æ­£åœ¨æ£€æŸ¥è¾“å‡ºæ–‡ä»¶...</p>
                </div>
            </div>
            
            <script>
                const taskId = '{task_id}';
                
                async function checkStatus() {{
                    try {{
                        const res = await fetch(`/task_status?task_id=${{taskId}}`);
                        const data = await res.json();
                        
                        if (data.code === 0) {{
                            document.getElementById('status').textContent = 'å·²å®Œæˆ';
                            document.getElementById('status').className = 'status completed';
                            
                            const files = data.data?.url || [];
                            const fileList = document.getElementById('fileList');
                            if (files.length > 0) {{
                                fileList.innerHTML = '<h3>è¾“å‡ºæ–‡ä»¶:</h3><ul class="file-list">';
                                files.forEach(url => {{
                                    const fileName = url.split('/').pop();
                                    const isVideo = fileName.match(/\\.(mp4|avi|mov|mkv)$/i);
                                    const isAudio = fileName.match(/\\.(wav|mp3|m4a)$/i);
                                    fileList.innerHTML += `<li class="file-item">
                                        <a href="${{url}}" target="_blank">${{fileName}}</a>
                                        ${{isVideo ? '<br><video controls class="video-player"><source src="' + url + '" type="video/mp4">æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè§†é¢‘æ’­æ”¾</video>' : ''}}
                                        ${{isAudio ? '<br><audio controls class="audio-player"><source src="' + url + '" type="audio/wav">æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘æ’­æ”¾</audio>' : ''}}
                                    </li>`;
                                }});
                                fileList.innerHTML += '</ul>';
                            }} else {{
                                fileList.innerHTML = '<p>æš‚æ— è¾“å‡ºæ–‡ä»¶</p>';
                            }}
                        }} else if (data.code === -1) {{
                            document.getElementById('status').textContent = data.msg || 'å¤„ç†ä¸­...';
                            document.getElementById('status').className = 'status processing';
                            setTimeout(checkStatus, 2000);
                        }} else {{
                            document.getElementById('status').textContent = data.msg || 'å¤„ç†å¤±è´¥';
                            document.getElementById('status').className = 'status error';
                        }}
                    }} catch (e) {{
                        document.getElementById('status').textContent = 'æ£€æŸ¥çŠ¶æ€å¤±è´¥';
                        document.getElementById('status').className = 'status error';
                    }}
                }}
                
                checkStatus();
            </script>
        </body>
        </html>
        """
        return html

    @app.route('/tts_result/<task_id>')
    def tts_result(task_id):
        """TTSç»“æœé¡µé¢"""
        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return "ä»»åŠ¡ä¸å­˜åœ¨", 404
        
        # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
        files = [f for f in task_dir.iterdir() if f.is_file()]
        output_files = []
        for f in files:
            if f.suffix.lower() in ['.wav', '.mp3', '.m4a']:
                output_files.append(f)
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <title>TTSç»“æœ - {task_id}</title>
            <style>
                body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 20px; background: #f5f5f5; }}
                .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                h1 {{ color: #333; margin-bottom: 20px; }}
                .file-list {{ list-style: none; padding: 0; }}
                .file-item {{ padding: 10px; border: 1px solid #ddd; margin: 10px 0; border-radius: 4px; background: #f9f9f9; }}
                .file-item a {{ color: #007AFF; text-decoration: none; font-weight: bold; }}
                .file-item a:hover {{ text-decoration: underline; }}
                .status {{ padding: 10px; border-radius: 4px; margin: 10px 0; }}
                .status.processing {{ background: #fff3cd; border: 1px solid #ffeaa7; color: #856404; }}
                .status.completed {{ background: #d4edda; border: 1px solid #c3e6cb; color: #155724; }}
                .status.error {{ background: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; }}
                .audio-player {{ width: 100%; margin: 10px 0; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>TTSéŸ³é¢‘ç”Ÿæˆç»“æœ</h1>
                <div class="task-info">
                    <p><strong>ä»»åŠ¡ID:</strong> {task_id}</p>
                    <p><strong>çŠ¶æ€:</strong> <span id="status">æ£€æŸ¥ä¸­...</span></p>
                </div>
                <div id="fileList">
                    <p>æ­£åœ¨æ£€æŸ¥è¾“å‡ºæ–‡ä»¶...</p>
                </div>
            </div>
            
            <script>
                const taskId = '{task_id}';
                
                async function checkStatus() {{
                    try {{
                        const res = await fetch(`/task_status?task_id=${{taskId}}`);
                        const data = await res.json();
                        
                        if (data.code === 0) {{
                            document.getElementById('status').textContent = 'å·²å®Œæˆ';
                            document.getElementById('status').className = 'status completed';
                            
                            const files = data.data?.url || [];
                            const fileList = document.getElementById('fileList');
                            if (files.length > 0) {{
                                fileList.innerHTML = '<h3>è¾“å‡ºæ–‡ä»¶:</h3><ul class="file-list">';
                                files.forEach(url => {{
                                    const fileName = url.split('/').pop();
                                    const isAudio = fileName.match(/\\.(wav|mp3|m4a)$/i);
                                    fileList.innerHTML += `<li class="file-item">
                                        <a href="${{url}}" target="_blank">${{fileName}}</a>
                                        ${{isAudio ? '<br><audio controls class="audio-player"><source src="' + url + '" type="audio/wav">æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘æ’­æ”¾</audio>' : ''}}
                                    </li>`;
                                }});
                                fileList.innerHTML += '</ul>';
                            }} else {{
                                fileList.innerHTML = '<p>æš‚æ— è¾“å‡ºæ–‡ä»¶</p>';
                            }}
                        }} else if (data.code === -1) {{
                            document.getElementById('status').textContent = data.msg || 'å¤„ç†ä¸­...';
                            document.getElementById('status').className = 'status processing';
                            setTimeout(checkStatus, 2000);
                        }} else {{
                            document.getElementById('status').textContent = data.msg || 'å¤„ç†å¤±è´¥';
                            document.getElementById('status').className = 'status error';
                        }}
                    }} catch (e) {{
                        document.getElementById('status').textContent = 'æ£€æŸ¥çŠ¶æ€å¤±è´¥';
                        document.getElementById('status').className = 'status error';
                    }}
                }}
                
                checkStatus();
            </script>
        </body>
        </html>
        """
        return html

    @app.route('/dubbing_result/<task_id>')
    def dubbing_result(task_id):
        """é…éŸ³ç»“æœé¡µé¢"""
        task_dir = Path(TARGET_DIR) / task_id
        if not task_dir.exists():
            return "ä»»åŠ¡ä¸å­˜åœ¨", 404
        
        # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
        files = [f for f in task_dir.iterdir() if f.is_file()]
        output_files = []
        for f in files:
            if f.suffix.lower() in ['.wav', '.mp3', '.m4a', '.mp4']:
                output_files.append(f)
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <title>é…éŸ³ç»“æœ - {task_id}</title>
            <style>
                body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 20px; background: #f5f5f5; }}
                .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                h1 {{ color: #333; margin-bottom: 20px; }}
                .file-list {{ list-style: none; padding: 0; }}
                .file-item {{ padding: 10px; border: 1px solid #ddd; margin: 10px 0; border-radius: 4px; background: #f9f9f9; }}
                .file-item a {{ color: #007AFF; text-decoration: none; font-weight: bold; }}
                .file-item a:hover {{ text-decoration: underline; }}
                .status {{ padding: 10px; border-radius: 4px; margin: 10px 0; }}
                .status.processing {{ background: #fff3cd; border: 1px solid #ffeaa7; color: #856404; }}
                .status.completed {{ background: #d4edda; border: 1px solid #c3e6cb; color: #155724; }}
                .status.error {{ background: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>é…éŸ³ç»“æœ</h1>
                <div class="task-info">
                    <p><strong>ä»»åŠ¡ID:</strong> {task_id}</p>
                    <p><strong>çŠ¶æ€:</strong> <span id="status">æ£€æŸ¥ä¸­...</span></p>
                </div>
                <div id="fileList">
                    <p>æ­£åœ¨æ£€æŸ¥è¾“å‡ºæ–‡ä»¶...</p>
                </div>
            </div>
            
            <script>
                const taskId = '{task_id}';
                
                async function checkStatus() {{
                    try {{
                        const res = await fetch(`/task_status?task_id=${{taskId}}`);
                        const data = await res.json();
                        
                        if (data.code === 0) {{
                            document.getElementById('status').textContent = 'å·²å®Œæˆ';
                            document.getElementById('status').className = 'status completed';
                            
                            const files = data.data?.url || [];
                            const fileList = document.getElementById('fileList');
                            if (files.length > 0) {{
                                fileList.innerHTML = '<h3>è¾“å‡ºæ–‡ä»¶:</h3><ul class="file-list">';
                                files.forEach(url => {{
                                    const fileName = url.split('/').pop();
                                    fileList.innerHTML += `<li class="file-item"><a href="${{url}}" target="_blank">${{fileName}}</a></li>`;
                                }});
                                fileList.innerHTML += '</ul>';
                            }} else {{
                                fileList.innerHTML = '<p>æš‚æ— è¾“å‡ºæ–‡ä»¶</p>';
                            }}
                        }} else if (data.code === -1) {{
                            document.getElementById('status').textContent = data.msg || 'å¤„ç†ä¸­...';
                            document.getElementById('status').className = 'status processing';
                            setTimeout(checkStatus, 2000);
                        }} else {{
                            document.getElementById('status').textContent = data.msg || 'å¤„ç†å¤±è´¥';
                            document.getElementById('status').className = 'status error';
                        }}
                    }} catch (e) {{
                        document.getElementById('status').textContent = 'æ£€æŸ¥çŠ¶æ€å¤±è´¥';
                        document.getElementById('status').className = 'status error';
                    }}
                }}
                
                checkStatus();
            </script>
        </body>
        </html>
        """
        return html


    # è·å–ä»»åŠ¡è¿›åº¦
    """
    æ ¹æ®ä»»åŠ¡idï¼Œè·å–å½“å‰ä»»åŠ¡çš„çŠ¶æ€
    
    è¯·æ±‚æ•°æ®ç±»å‹ï¼šä¼˜å…ˆGETä¸­è·å–ï¼Œä¸å­˜åœ¨åˆ™ä»POSTä¸­è·å–ï¼Œéƒ½ä¸å­˜åœ¨åˆ™ä» jsonæ•°æ®ä¸­è·å–
    
    è¯·æ±‚å‚æ•°: 
    task_id:å¿…é¡»ï¼Œå­—ç¬¦ä¸²ç±»å‹
    
    è¿”å›:jsonæ ¼å¼æ•°æ®
    code:-1=è¿›è¡Œä¸­ï¼Œ0=æˆåŠŸç»“æŸï¼Œ>0=å‡ºé”™äº†
    msg:codeä¸º-1æ—¶ä¸ºè¿›åº¦ä¿¡æ¯ï¼Œcode>0æ—¶ä¸ºå‡ºé”™ä¿¡æ¯ï¼ŒæˆåŠŸæ—¶ä¸ºok
    data:ä»…å½“code==0æˆåŠŸæ—¶å­˜åœ¨ï¼Œæ˜¯ä¸€ä¸ªdictå¯¹è±¡
        absolute_pathæ˜¯ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨listï¼Œæ¯é¡¹å‡æ˜¯ä¸€ä¸ªæ–‡ä»¶çš„ç»å¯¹è·¯å¾„
        url æ˜¯ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨listï¼Œæ¯é¡¹å‡æ˜¯ä¸€ä¸ªå¯è®¿é—®çš„url
    
    
    å¤±è´¥ï¼š{"code":1,"msg":"ä¸å­˜åœ¨è¯¥ä»»åŠ¡"}
    è¿›è¡Œä¸­ï¼š{"code":-1,"msg":"æ­£åœ¨åˆæˆå£°éŸ³"} 
    æˆåŠŸ: {"code":0,"msg":"ok","data":{"absolute_path":["/data/1.srt","/data/1.mp4"],"url":["http://127.0.0.1:9011/task_id/1.srt"]}}
    
    
    ç¤ºä¾‹
    def test_task_status():
        res=requests.post("http://127.0.0.1:9011/task_status",json={
            "task_id":"06c238d250f0b51248563c405f1d7294"
        })
        print(res.json())
    
    {
      "code": 0,
      "data": {
        "absolute_path": [
          "F:/python/pyvideo/apidata/daa33fee2537b47a0b12e12b926a4b01/10ass.mp4",
          "F:/python/pyvideo/apidata/daa33fee2537b47a0b12e12b926a4b01/en.m4a",
          "F:/python/pyvideo/apidata/daa33fee2537b47a0b12e12b926a4b01/en.srt",
          "F:/python/pyvideo/apidata/daa33fee2537b47a0b12e12b926a4b01/end.srt.ass",
          "F:/python/pyvideo/apidata/daa33fee2537b47a0b12e12b926a4b01/zh-cn.m4a",
          "F:/python/pyvideo/apidata/daa33fee2537b47a0b12e12b926a4b01/zh-cn.srt",
          "F:/python/pyvideo/apidata/daa33fee2537b47a0b12e12b926a4b01/æ–‡ä»¶è¯´æ˜.txt"
        ],
        "url": [
          "http://127.0.0.1:9011/apidata/daa33fee2537b47a0b12e12b926a4b01/10ass.mp4",
          "http://127.0.0.1:9011/apidata/daa33fee2537b47a0b12e12b926a4b01/en.m4a",
          "http://127.0.0.1:9011/apidata/daa33fee2537b47a0b12e12b926a4b01/en.srt",
          "http://127.0.0.1:9011/apidata/daa33fee2537b47a0b12e12b926a4b01/end.srt.ass",
          "http://127.0.0.1:9011/apidata/daa33fee2537b47a0b12e12b926a4b01/zh-cn.m4a",
          "http://127.0.0.1:9011/apidata/daa33fee2537b47a0b12e12b926a4b01/zh-cn.srt",
          "http://127.0.0.1:9011/apidata/daa33fee2537b47a0b12e12b926a4b01/æ–‡ä»¶è¯´æ˜.txt"
        ]
      },
      "msg": "ok"
    }
    
    """
    @app.route('/task_status', methods=['POST', 'GET'])
    def task_status():
        # 1. ä¼˜å…ˆä» GET è¯·æ±‚å‚æ•°ä¸­è·å– task_id
        task_id = request.args.get('task_id')

        # 2. å¦‚æœ GET å‚æ•°ä¸­æ²¡æœ‰ task_idï¼Œå†ä» POST è¡¨å•ä¸­è·å–
        if task_id is None:
            task_id = request.form.get('task_id')

        # 3. å¦‚æœ POST è¡¨å•ä¸­ä¹Ÿæ²¡æœ‰ task_idï¼Œå†ä» JSON è¯·æ±‚ä½“ä¸­è·å–
        if task_id is None and request.is_json:
            task_id = request.json.get('task_id')
        if not task_id:
            return jsonify({"code": 1, "msg": "The parem  task_id is not set"})
        return _get_task_data(task_id)
        

    
    # è·å–å¤šä¸ªä»»åŠ¡ å‰å° content-type:application/json, æ•°æ® {task_id_list:[id1,id2,....]}
    @app.route('/task_status_list', methods=['POST', 'GET'])
    def task_status_list():
        # 1. ä¼˜å…ˆä» GET è¯·æ±‚å‚æ•°ä¸­è·å– task_id
        task_ids= request.json.get('task_id_list',[])
        if not task_ids or len(task_ids)<1:
            return jsonify({"code": 1, "msg": "ç¼ºå°‘ä»»åŠ¡id"})
        
        return_data={}
        for task_id in task_ids:
            return_data[task_id]=_get_task_data(task_id)
        return jsonify({"code": 0, "msg": "ok","data":return_data})
    
    def _get_task_data(task_id):
        file = PROCESS_INFO + f'/{task_id}.json'
        if not Path(file).is_file():
            if task_id in config.uuid_logs_queue:
                return {"code": -1, "msg": _get_order(task_id)}

            return {"code": 1, "msg": f"è¯¥ä»»åŠ¡ {task_id} ä¸å­˜åœ¨"}

        try:
            data = json.loads(Path(file).read_text(encoding='utf-8'))
        except Exception as e:
            return {"code": -1, "msg": Path(file).read_text(encoding='utf-8')}

        if data['type'] == 'error':
            return {"code": 3, "msg": data["text"]}
        if data['type'] in logs_status_list:
            text=data.get('text','').strip()
            return {"code": -1, "msg": text if text else 'ç­‰å¾…å¤„ç†ä¸­'}
        # å®Œæˆï¼Œè¾“å‡ºæ‰€æœ‰æ–‡ä»¶
        file_list = _get_files_in_directory(f'{TARGET_DIR}/{task_id}')
        if len(file_list) < 1:
            return {"code": 4, "msg": 'æœªç”Ÿæˆä»»ä½•ç»“æœæ–‡ä»¶ï¼Œå¯èƒ½å‡ºé”™äº†'}

        return {
            "code": 0,
            "msg": "ok",
            "data": {
                "absolute_path": [f'{TARGET_DIR}/{task_id}/{name}' for name in file_list],
                "url": [f'{request.scheme}://{request.host}/{API_RESOURCE}/{task_id}/{name}' for name in file_list],
            }
        }

    # æ’é˜Ÿ
    def _get_order(task_id):
        order_num=0
        for it in config.prepare_queue:
            order_num+=1
            if it.uuid == task_id:
                return f'å½“å‰å¤„äºé¢„å¤„ç†é˜Ÿåˆ—ç¬¬{order_num}ä½' if config.defaulelang=='zh' else f"No.{order_num} on perpare queue"
        
        order_num=0
        for it in config.regcon_queue:
            order_num+=1
            if it.uuid == task_id:
                return f'å½“å‰å¤„äºè¯­éŸ³è¯†åˆ«é˜Ÿåˆ—ç¬¬{order_num}ä½' if config.defaulelang=='zh' else f"No.{order_num} on perpare queue"
        order_num=0
        for it in config.trans_queue:
            order_num+=1
            if it.uuid == task_id:
                return f'å½“å‰å¤„äºå­—å¹•ç¿»è¯‘é˜Ÿåˆ—ç¬¬{order_num}ä½' if config.defaulelang=='zh' else f"No.{order_num} on perpare queue"
        order_num=0
        for it in config.dubb_queue:
            order_num+=1
            if it.uuid == task_id:
                return f'å½“å‰å¤„äºé…éŸ³é˜Ÿåˆ—ç¬¬{order_num}ä½' if config.defaulelang=='zh' else f"No.{order_num} on perpare queue"
        order_num=0
        for it in config.align_queue:
            order_num+=1
            if it.uuid == task_id:
                return f'å½“å‰å¤„äºå£°ç”»å¯¹é½é˜Ÿåˆ—ç¬¬{order_num}ä½' if config.defaulelang=='zh' else f"No.{order_num} on perpare queue"
        order_num=0
        for it in config.assemb_queue:
            order_num+=1
            if it.uuid == task_id:
                return f'å½“å‰å¤„äºè¾“å‡ºæ•´ç†é˜Ÿåˆ—ç¬¬{order_num}ä½' if config.defaulelang=='zh' else f"No.{order_num} on perpare queue"
        return 'æ­£åœ¨æ’é˜Ÿç­‰å¾…æ‰§è¡Œä¸­ï¼Œè¯·ç¨å' if config.defaulelang=='zh' else f"Waiting in queue"
    
    def _get_files_in_directory(dirname):
        """
        ä½¿ç”¨ pathlib åº“è·å–æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶åï¼Œå¹¶è¿”å›ä¸€ä¸ªæ–‡ä»¶ååˆ—è¡¨ã€‚

        å‚æ•°:
        dirname (str): è¦è·å–æ–‡ä»¶çš„ç›®å½•è·¯å¾„

        è¿”å›:
        list: åŒ…å«ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶åçš„åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨ Path å¯¹è±¡è·å–ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
            path = Path(dirname)
            files = [f.name for f in path.iterdir() if f.is_file()]
            return files
        except Exception as e:
            print(f"Error while accessing directory {dirname}: {e}")
            return []


    def _listen_queue():
        # ç›‘å¬é˜Ÿåˆ—æ—¥å¿— uuid_logs_queue ä¸åœ¨åœæ­¢ä¸­çš„ stoped_uuid_set
        Path(TARGET_DIR + f'/processinfo').mkdir(parents=True, exist_ok=True)
        while 1:
            # æ‰¾å‡ºæœªåœæ­¢çš„
            uuid_list = list(config.uuid_logs_queue.keys())
            uuid_list = [uuid for uuid in uuid_list if uuid not in config.stoped_uuid_set]
            # å…¨éƒ¨ç»“æŸ
            if len(uuid_list) < 1:
                time.sleep(1)
                continue
            while len(uuid_list) > 0:
                uuid = uuid_list.pop(0)
                if uuid in config.stoped_uuid_set:
                    continue
                try:
                    q = config.uuid_logs_queue.get(uuid)
                    if not q:
                        continue
                    data = q.get(block=False)
                    if not data:
                        continue

                    if data['type'] not in end_status_list + logs_status_list:
                        continue
                    with open(PROCESS_INFO + f'/{uuid}.json', 'w', encoding='utf-8') as f:
                        f.write(json.dumps(data))
                    if data['type'] in end_status_list:
                        config.stoped_uuid_set.add(uuid)
                        del config.uuid_logs_queue[uuid]
                except Exception:
                    pass
            time.sleep(0.1)

    multiprocessing.freeze_support()  # Windows ä¸Šéœ€è¦è¿™ä¸ªæ¥é¿å…å­è¿›ç¨‹çš„é€’å½’æ‰§è¡Œé—®é¢˜
    print(f'Starting... API URL is   http://{HOST}:{PORT}')
    print(f'Document at https://pyvideotrans.com/api-cn')
    start_thread()
    threading.Thread(target=_listen_queue).start()
    try:
        print(f'\nAPI URL is   http://{HOST}:{PORT}')
        serve(app, host=HOST, port=int(PORT))
    except Exception as e:
        import traceback
        traceback.print_exc()
